```{r include=FALSE}
library(tidyverse)
library(mfstylr)
```

# Discrete Analysis {#discrete_anal}


## Goodness-of-Fit Test

These notes rely heavily upon PSU STATS 504 [course notes](https://online.stat.psu.edu/stat504/node/60/).

The **chi-square goodness-of-fit test**, tests whether observed frequency counts $O_j$ of the $j \in k$ levels of a categorical variable differ from expected frequency counts $E_j$ ($H_0$ is $O_j = E_j, \hspace{5mm} \forall j \in k$.

There are two test statistics for this test, Pearson $X^2$ and deviance $G^2$.  The sampling distribution of each test statistic approach the chi-squared distribution as $n$ becomes large.  Calculate both test statistic.  If the resulting p-values are close, then you can be confident that the large-sample approximation is working well.

The Pearson goodness-of-fit statistic is

$$X^2 = \sum \frac{(O_j - E_j)^2}{E_j}$$

where $O_j = p_j n$ and $E_j = \pi_j n$.  The deviance statistic is 

$$G^2 = 2 \sum O_j \log \left( \frac{O_j}{E_j} \right)$$

If the saturated model (the observed data represent the fit of the saturated model, the most complex model possible with the data) proportions $p_j$ equal equal the expected proportions $\pi_j$, $X^2$ and $G^2$ are zero.  Large values indicate the data do not agree well with the proposed model.

As $n \rightarrow \infty$, $G^2$ and $X^2$ approach $\chi_{k-1}^2$ where $k$ is the number of categorical variable levels.  You can therefore run a chi-square test of significance using the $G^2$ and $X^2$ test statistics.  The chi-square test provides reliable results when at least 80% of $E_j >= 5$.  


### One-Way Tables

A one-way frequency table is a frequency table for a single categorical table.

Here is a simple chi-square test.  A researcher crosses tall cut-leaf tomatoes with dwarf potato-leaf tomatoes, then classifies the ($n = 1611$) offspring phenotypes.

```{r}
o <- c(926, 288, 293, 104)
cell_names <- c("tall cut-leaf", "tall potato-leaf", "dwarf cut-leaf", "dwarf potato-leaf")
names(o) <- cell_names
print(o)
```

The genetic theory is the four phenotypes should occur with relative frequencies 9 : 3 : 3 : 1.

```{r}
pi <- c(9, 3, 3, 1) / (9 + 3 + 3 + 1)
e <- 1611 * pi
names(e) <- cell_names
print(e)
```

```{r fig.width=6, fig.height=3.5}
data.frame(o, e) %>%
  rownames_to_column() %>%
  pivot_longer(cols = -rowname) %>%
  ggplot(aes(x = as.factor(rowname), y = value, fill = name)) +
  geom_col(position = position_dodge()) +
  geom_text(aes(label = round(value, 0)), position = position_dodge(width = 0.9)) +
  theme_mf() +
  scale_fill_mf() +
  labs(title = "Observed vs Expected", fill = "", x = "", y = "")
```

```{r echo=FALSE}
x2 <- sum((o - e)^2 / e)
g2 <- 2 * sum(o * log(o / e))
```

The $X^2$ statistic is `x2 <- sum((o - e)^2 / e) = ` `r  x2` and the $G^2$ statistic is `g2 <- 2 * sum(o * log(o / e)) = ` `r g2`, so nearly identical. The chi-sq test p-values are also nearly identical.

```{r}
pchisq(q = x2, df = length(o) - 1, lower.tail = FALSE)
pchisq(q = g2, df = length(o) - 1, lower.tail = FALSE)
```

```{r warning=FALSE, message=FALSE}
alpha <- 0.05
df <- length(e) - 1
lrr = -Inf
urr = qchisq(p = alpha, df = df, lower.tail = FALSE)
# data.frame(chi2 = 0:2500 / 100) %>%
#   mutate(density = dchisq(x = chi2, df = df)) %>%
#   mutate(rr = ifelse(chi2 < lrr | chi2 > urr, density, 0)) %>%
# ggplot() +
#   geom_line(aes(x = chi2, y = density)) +
#   geom_area(aes(x = chi2, y = rr), fill = "red", alpha = 0.3) +
# #  geom_vline(aes(xintercept = pi_0), color = "black") +
#   geom_vline(aes(xintercept = chisq), color = "red") +
#   labs(title = bquote("Chi-Squared Goodness-of-Fit Test"),
#        subtitle = bquote("Chisq ="~.(round(chisq,2))~", n ="~.(n)~", alpha ="~.(alpha)~", chisq_crit ="~.(round(urr,2))~", p-value ="~.(round(p_value,3))),
#        x = "chisq",
#        y = "Density") +
#   theme(legend.position="none")
```

Replace the summation with a square root in the test statistic formulas to get the Pearson and deviance residuals.

```{r}
e2_res <- sqrt((o - e)^2 / e)
g2_res <- sign(o - e) * sqrt(abs(2 * o * log(o / e)))
```

Here is a summary of the analysis.

```{r}
data.frame(o, e, e2_res, g2_res)
```

You can perform the chi-square test of the Pearson test statistic with `chisq.test()`.

```{r}
chisq.test(o, p = pi)
```

