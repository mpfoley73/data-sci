<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>10.2 Regression Trees | My Data Science Notes</title>
  <meta name="description" content="This is a compendium of notes from classes, tutorials, etc. that I reference from time to time." />
  <meta name="generator" content="bookdown 0.18 and GitBook 2.6.7" />

  <meta property="og:title" content="10.2 Regression Trees | My Data Science Notes" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="This is a compendium of notes from classes, tutorials, etc. that I reference from time to time." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="10.2 Regression Trees | My Data Science Notes" />
  
  <meta name="twitter:description" content="This is a compendium of notes from classes, tutorials, etc. that I reference from time to time." />
  

<meta name="author" content="Michael Foley" />


<meta name="date" content="2020-06-03" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="classification-tree.html"/>
<link rel="next" href="bagging.html"/>
<script src="assets/jquery-2.2.3/jquery.min.js"></script>
<link href="assets/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="assets/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="assets/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="assets/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="assets/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="assets/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="assets/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />











<style type="text/css">
code.sourceCode > span { display: inline-block; line-height: 1.25; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">My Data Science Notes</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Intro</a></li>
<li class="chapter" data-level="1" data-path="probability.html"><a href="probability.html"><i class="fa fa-check"></i><b>1</b> Probability</a><ul>
<li class="chapter" data-level="1.1" data-path="principles.html"><a href="principles.html"><i class="fa fa-check"></i><b>1.1</b> Principles</a></li>
<li class="chapter" data-level="1.2" data-path="disc-dist.html"><a href="disc-dist.html"><i class="fa fa-check"></i><b>1.2</b> Discrete Distributions</a><ul>
<li class="chapter" data-level="1.2.1" data-path="disc-dist.html"><a href="disc-dist.html#bernoulli"><i class="fa fa-check"></i><b>1.2.1</b> Bernoulli</a></li>
<li class="chapter" data-level="1.2.2" data-path="disc-dist.html"><a href="disc-dist.html#binomial"><i class="fa fa-check"></i><b>1.2.2</b> Binomial</a></li>
<li class="chapter" data-level="1.2.3" data-path="disc-dist.html"><a href="disc-dist.html#poission"><i class="fa fa-check"></i><b>1.2.3</b> Poission</a></li>
<li class="chapter" data-level="1.2.4" data-path="disc-dist.html"><a href="disc-dist.html#multinomial"><i class="fa fa-check"></i><b>1.2.4</b> Multinomial</a></li>
<li class="chapter" data-level="1.2.5" data-path="disc-dist.html"><a href="disc-dist.html#negative-binomial"><i class="fa fa-check"></i><b>1.2.5</b> Negative-Binomial</a></li>
<li class="chapter" data-level="1.2.6" data-path="disc-dist.html"><a href="disc-dist.html#geometric"><i class="fa fa-check"></i><b>1.2.6</b> Geometric</a></li>
<li class="chapter" data-level="1.2.7" data-path="disc-dist.html"><a href="disc-dist.html#hypergeometric"><i class="fa fa-check"></i><b>1.2.7</b> Hypergeometric</a></li>
<li class="chapter" data-level="1.2.8" data-path="disc-dist.html"><a href="disc-dist.html#gamma"><i class="fa fa-check"></i><b>1.2.8</b> Gamma</a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="cont-dist.html"><a href="cont-dist.html"><i class="fa fa-check"></i><b>1.3</b> Continuous Distributions</a><ul>
<li class="chapter" data-level="1.3.1" data-path="cont-dist.html"><a href="cont-dist.html#normal"><i class="fa fa-check"></i><b>1.3.1</b> Normal</a></li>
</ul></li>
<li class="chapter" data-level="1.4" data-path="join-distributions.html"><a href="join-distributions.html"><i class="fa fa-check"></i><b>1.4</b> Join Distributions</a></li>
<li class="chapter" data-level="1.5" data-path="likelihood.html"><a href="likelihood.html"><i class="fa fa-check"></i><b>1.5</b> Likelihood</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="discrete-analysis.html"><a href="discrete-analysis.html"><i class="fa fa-check"></i><b>2</b> Categorical Analysis - Nonmodel</a><ul>
<li class="chapter" data-level="2.1" data-path="chi-square-test.html"><a href="chi-square-test.html"><i class="fa fa-check"></i><b>2.1</b> Chi-Square Test</a></li>
<li class="chapter" data-level="2.2" data-path="one-way-tables.html"><a href="one-way-tables.html"><i class="fa fa-check"></i><b>2.2</b> One-Way Tables</a><ul>
<li class="chapter" data-level="2.2.1" data-path="one-way-tables.html"><a href="one-way-tables.html#chi-square-goodness-of-fit-test"><i class="fa fa-check"></i><b>2.2.1</b> Chi-Square Goodness-of-Fit Test</a></li>
<li class="chapter" data-level="2.2.2" data-path="one-way-tables.html"><a href="one-way-tables.html#proportion-test"><i class="fa fa-check"></i><b>2.2.2</b> Proportion Test</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="two-way-tables.html"><a href="two-way-tables.html"><i class="fa fa-check"></i><b>2.3</b> Two-Way Tables</a><ul>
<li class="chapter" data-level="2.3.1" data-path="two-way-tables.html"><a href="two-way-tables.html#chi-square-independence-test"><i class="fa fa-check"></i><b>2.3.1</b> Chi-Square Independence Test</a></li>
<li class="chapter" data-level="2.3.2" data-path="two-way-tables.html"><a href="two-way-tables.html#residuals-analysis"><i class="fa fa-check"></i><b>2.3.2</b> Residuals Analysis</a></li>
<li class="chapter" data-level="2.3.3" data-path="two-way-tables.html"><a href="two-way-tables.html#difference-in-proportions"><i class="fa fa-check"></i><b>2.3.3</b> Difference in Proportions</a></li>
<li class="chapter" data-level="2.3.4" data-path="two-way-tables.html"><a href="two-way-tables.html#relative-risk"><i class="fa fa-check"></i><b>2.3.4</b> Relative Risk</a></li>
<li class="chapter" data-level="2.3.5" data-path="two-way-tables.html"><a href="two-way-tables.html#odds-ratio"><i class="fa fa-check"></i><b>2.3.5</b> Odds Ratio</a></li>
<li class="chapter" data-level="2.3.6" data-path="two-way-tables.html"><a href="two-way-tables.html#partitioning-chi-square"><i class="fa fa-check"></i><b>2.3.6</b> Partitioning Chi-Square</a></li>
<li class="chapter" data-level="2.3.7" data-path="two-way-tables.html"><a href="two-way-tables.html#correlation"><i class="fa fa-check"></i><b>2.3.7</b> Correlation</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="k-way-tables.html"><a href="k-way-tables.html"><i class="fa fa-check"></i><b>2.4</b> K-Way Tables</a><ul>
<li class="chapter" data-level="2.4.1" data-path="k-way-tables.html"><a href="k-way-tables.html#odds-ratio-1"><i class="fa fa-check"></i><b>2.4.1</b> Odds Ratio</a></li>
<li class="chapter" data-level="2.4.2" data-path="k-way-tables.html"><a href="k-way-tables.html#chi-square-independence-test-1"><i class="fa fa-check"></i><b>2.4.2</b> Chi-Square Independence Test</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="continuous-analysis.html"><a href="continuous-analysis.html"><i class="fa fa-check"></i><b>3</b> Continuous Variable Analysis</a><ul>
<li class="chapter" data-level="3.0.1" data-path="continuous-analysis.html"><a href="continuous-analysis.html#correlation-1"><i class="fa fa-check"></i><b>3.0.1</b> Correlation</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="experiment-design.html"><a href="experiment-design.html"><i class="fa fa-check"></i><b>4</b> Experiment Design</a><ul>
<li class="chapter" data-level="4.1" data-path="single-factor.html"><a href="single-factor.html"><i class="fa fa-check"></i><b>4.1</b> Single Factor</a></li>
<li class="chapter" data-level="4.2" data-path="blocking.html"><a href="blocking.html"><i class="fa fa-check"></i><b>4.2</b> Blocking</a></li>
<li class="chapter" data-level="4.3" data-path="nested.html"><a href="nested.html"><i class="fa fa-check"></i><b>4.3</b> Nested</a></li>
<li class="chapter" data-level="4.4" data-path="split-plot.html"><a href="split-plot.html"><i class="fa fa-check"></i><b>4.4</b> Split Plot</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="part-2-supervised-machine-learning.html"><a href="part-2-supervised-machine-learning.html"><i class="fa fa-check"></i>PART 2: Supervised Machine Learning</a></li>
<li class="chapter" data-level="5" data-path="ordinary-least-squares.html"><a href="ordinary-least-squares.html"><i class="fa fa-check"></i><b>5</b> Ordinary Least Squares</a><ul>
<li class="chapter" data-level="5.1" data-path="linear-regression-model.html"><a href="linear-regression-model.html"><i class="fa fa-check"></i><b>5.1</b> Linear Regression Model</a></li>
<li class="chapter" data-level="5.2" data-path="parameter-estimation.html"><a href="parameter-estimation.html"><i class="fa fa-check"></i><b>5.2</b> Parameter Estimation</a></li>
<li class="chapter" data-level="5.3" data-path="model-assumptions.html"><a href="model-assumptions.html"><i class="fa fa-check"></i><b>5.3</b> Model Assumptions</a><ul>
<li class="chapter" data-level="5.3.1" data-path="model-assumptions.html"><a href="model-assumptions.html#linearity"><i class="fa fa-check"></i><b>5.3.1</b> Linearity</a></li>
<li class="chapter" data-level="5.3.2" data-path="model-assumptions.html"><a href="model-assumptions.html#multicollinearity"><i class="fa fa-check"></i><b>5.3.2</b> Multicollinearity</a></li>
<li class="chapter" data-level="5.3.3" data-path="model-assumptions.html"><a href="model-assumptions.html#normality"><i class="fa fa-check"></i><b>5.3.3</b> Normality</a></li>
<li class="chapter" data-level="5.3.4" data-path="model-assumptions.html"><a href="model-assumptions.html#equal-variances"><i class="fa fa-check"></i><b>5.3.4</b> Equal Variances</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="prediction.html"><a href="prediction.html"><i class="fa fa-check"></i><b>5.4</b> Prediction</a></li>
<li class="chapter" data-level="5.5" data-path="inference.html"><a href="inference.html"><i class="fa fa-check"></i><b>5.5</b> Inference</a><ul>
<li class="chapter" data-level="5.5.1" data-path="inference.html"><a href="inference.html#t-test"><i class="fa fa-check"></i><b>5.5.1</b> <em>t</em>-Test</a></li>
<li class="chapter" data-level="5.5.2" data-path="inference.html"><a href="inference.html#f-test"><i class="fa fa-check"></i><b>5.5.2</b> <em>F</em>-Test</a></li>
</ul></li>
<li class="chapter" data-level="5.6" data-path="interpretation.html"><a href="interpretation.html"><i class="fa fa-check"></i><b>5.6</b> Interpretation</a></li>
<li class="chapter" data-level="5.7" data-path="model-validation.html"><a href="model-validation.html"><i class="fa fa-check"></i><b>5.7</b> Model Validation</a><ul>
<li class="chapter" data-level="5.7.1" data-path="model-validation.html"><a href="model-validation.html#accuracy-metrics"><i class="fa fa-check"></i><b>5.7.1</b> Accuracy Metrics</a></li>
<li class="chapter" data-level="5.7.2" data-path="model-validation.html"><a href="model-validation.html#cross-validation"><i class="fa fa-check"></i><b>5.7.2</b> Cross-Validation</a></li>
<li class="chapter" data-level="5.7.3" data-path="model-validation.html"><a href="model-validation.html#gain-curve"><i class="fa fa-check"></i><b>5.7.3</b> Gain Curve</a></li>
</ul></li>
<li class="chapter" data-level="5.8" data-path="reference.html"><a href="reference.html"><i class="fa fa-check"></i><b>5.8</b> Reference</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="generalized-linear-models.html"><a href="generalized-linear-models.html"><i class="fa fa-check"></i><b>6</b> Generalized Linear Models</a><ul>
<li class="chapter" data-level="6.1" data-path="logistic-regression.html"><a href="logistic-regression.html"><i class="fa fa-check"></i><b>6.1</b> Logistic Regression</a></li>
<li class="chapter" data-level="6.2" data-path="multinomial-logistic-regression.html"><a href="multinomial-logistic-regression.html"><i class="fa fa-check"></i><b>6.2</b> Multinomial Logistic Regression</a></li>
<li class="chapter" data-level="6.3" data-path="ordinal-logistic-regression.html"><a href="ordinal-logistic-regression.html"><i class="fa fa-check"></i><b>6.3</b> Ordinal Logistic Regression</a><ul>
<li class="chapter" data-level="6.3.1" data-path="ordinal-logistic-regression.html"><a href="ordinal-logistic-regression.html#assumptions"><i class="fa fa-check"></i><b>6.3.1</b> Assumptions</a></li>
<li class="chapter" data-level="6.3.2" data-path="ordinal-logistic-regression.html"><a href="ordinal-logistic-regression.html#modeling"><i class="fa fa-check"></i><b>6.3.2</b> Modeling</a></li>
<li class="chapter" data-level="6.3.3" data-path="ordinal-logistic-regression.html"><a href="ordinal-logistic-regression.html#case-study"><i class="fa fa-check"></i><b>6.3.3</b> Case Study</a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="poisson-regression.html"><a href="poisson-regression.html"><i class="fa fa-check"></i><b>6.4</b> Poisson Regression</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="multivariate-statistical-analysis.html"><a href="multivariate-statistical-analysis.html"><i class="fa fa-check"></i><b>7</b> Multivariate Statistical Analysis</a><ul>
<li class="chapter" data-level="7.1" data-path="background.html"><a href="background.html"><i class="fa fa-check"></i><b>7.1</b> Background</a></li>
<li class="chapter" data-level="7.2" data-path="manova.html"><a href="manova.html"><i class="fa fa-check"></i><b>7.2</b> MANOVA</a></li>
<li class="chapter" data-level="7.3" data-path="repeated-measures.html"><a href="repeated-measures.html"><i class="fa fa-check"></i><b>7.3</b> Repeated Measures</a></li>
<li class="chapter" data-level="7.4" data-path="lda.html"><a href="lda.html"><i class="fa fa-check"></i><b>7.4</b> LDA</a></li>
<li class="chapter" data-level="7.5" data-path="pca.html"><a href="pca.html"><i class="fa fa-check"></i><b>7.5</b> PCA</a></li>
<li class="chapter" data-level="7.6" data-path="factor-analysis.html"><a href="factor-analysis.html"><i class="fa fa-check"></i><b>7.6</b> Factor Analysis</a></li>
<li class="chapter" data-level="7.7" data-path="canonical-correlation.html"><a href="canonical-correlation.html"><i class="fa fa-check"></i><b>7.7</b> Canonical Correlation</a></li>
<li class="chapter" data-level="7.8" data-path="cluster-analysis.html"><a href="cluster-analysis.html"><i class="fa fa-check"></i><b>7.8</b> Cluster Analysis</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="classification.html"><a href="classification.html"><i class="fa fa-check"></i><b>8</b> Classification</a></li>
<li class="chapter" data-level="9" data-path="regularization.html"><a href="regularization.html"><i class="fa fa-check"></i><b>9</b> Regularization</a></li>
<li class="chapter" data-level="10" data-path="decision-trees.html"><a href="decision-trees.html"><i class="fa fa-check"></i><b>10</b> Decision Trees</a><ul>
<li class="chapter" data-level="10.1" data-path="classification-tree.html"><a href="classification-tree.html"><i class="fa fa-check"></i><b>10.1</b> Classification Tree</a><ul>
<li class="chapter" data-level="10.1.1" data-path="classification-tree.html"><a href="classification-tree.html#confusion-matrix"><i class="fa fa-check"></i><b>10.1.1</b> Confusion Matrix</a></li>
<li class="chapter" data-level="10.1.2" data-path="classification-tree.html"><a href="classification-tree.html#roc-curve"><i class="fa fa-check"></i><b>10.1.2</b> ROC Curve</a></li>
<li class="chapter" data-level="10.1.3" data-path="classification-tree.html"><a href="classification-tree.html#caret-approach"><i class="fa fa-check"></i><b>10.1.3</b> Caret Approach</a></li>
</ul></li>
<li class="chapter" data-level="10.2" data-path="regression-trees.html"><a href="regression-trees.html"><i class="fa fa-check"></i><b>10.2</b> Regression Trees</a><ul>
<li class="chapter" data-level="10.2.1" data-path="regression-trees.html"><a href="regression-trees.html#caret-approach-1"><i class="fa fa-check"></i><b>10.2.1</b> Caret Approach</a></li>
</ul></li>
<li class="chapter" data-level="10.3" data-path="bagging.html"><a href="bagging.html"><i class="fa fa-check"></i><b>10.3</b> Bagging</a></li>
<li class="chapter" data-level="10.4" data-path="random-forests.html"><a href="random-forests.html"><i class="fa fa-check"></i><b>10.4</b> Random Forests</a></li>
<li class="chapter" data-level="10.5" data-path="gradient-boosting.html"><a href="gradient-boosting.html"><i class="fa fa-check"></i><b>10.5</b> Gradient Boosting</a></li>
<li class="chapter" data-level="10.6" data-path="summary.html"><a href="summary.html"><i class="fa fa-check"></i><b>10.6</b> Summary</a></li>
<li class="chapter" data-level="10.7" data-path="reference-1.html"><a href="reference-1.html"><i class="fa fa-check"></i><b>10.7</b> Reference</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="non-linear-models.html"><a href="non-linear-models.html"><i class="fa fa-check"></i><b>11</b> Non-linear Models</a><ul>
<li class="chapter" data-level="11.1" data-path="splines.html"><a href="splines.html"><i class="fa fa-check"></i><b>11.1</b> Splines</a></li>
<li class="chapter" data-level="11.2" data-path="mars.html"><a href="mars.html"><i class="fa fa-check"></i><b>11.2</b> MARS</a></li>
<li class="chapter" data-level="11.3" data-path="gam.html"><a href="gam.html"><i class="fa fa-check"></i><b>11.3</b> GAM</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="support-vector-machines.html"><a href="support-vector-machines.html"><i class="fa fa-check"></i><b>12</b> Support Vector Machines</a><ul>
<li class="chapter" data-level="12.1" data-path="maximal-margin-classifier.html"><a href="maximal-margin-classifier.html"><i class="fa fa-check"></i><b>12.1</b> Maximal Margin Classifier</a></li>
<li class="chapter" data-level="12.2" data-path="support-vector-classifier.html"><a href="support-vector-classifier.html"><i class="fa fa-check"></i><b>12.2</b> Support Vector Classifier</a></li>
<li class="chapter" data-level="12.3" data-path="support-vector-machines-1.html"><a href="support-vector-machines-1.html"><i class="fa fa-check"></i><b>12.3</b> Support Vector Machines</a></li>
<li class="chapter" data-level="12.4" data-path="example-16.html"><a href="example-16.html"><i class="fa fa-check"></i><b>12.4</b> Example</a></li>
<li class="chapter" data-level="12.5" data-path="using-caret.html"><a href="using-caret.html"><i class="fa fa-check"></i><b>12.5</b> Using Caret</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="principal-components-analysis.html"><a href="principal-components-analysis.html"><i class="fa fa-check"></i><b>13</b> Principal Components Analysis</a></li>
<li class="chapter" data-level="14" data-path="text-mining.html"><a href="text-mining.html"><i class="fa fa-check"></i><b>14</b> Text Mining</a></li>
<li class="chapter" data-level="15" data-path="survival-analysis.html"><a href="survival-analysis.html"><i class="fa fa-check"></i><b>15</b> Survival Analysis</a><ul>
<li class="chapter" data-level="15.1" data-path="basic-concepts.html"><a href="basic-concepts.html"><i class="fa fa-check"></i><b>15.1</b> Basic Concepts</a></li>
<li class="chapter" data-level="15.2" data-path="survival-curve-estimation.html"><a href="survival-curve-estimation.html"><i class="fa fa-check"></i><b>15.2</b> Survival Curve Estimation</a><ul>
<li class="chapter" data-level="15.2.1" data-path="survival-curve-estimation.html"><a href="survival-curve-estimation.html#kaplan-meier"><i class="fa fa-check"></i><b>15.2.1</b> Kaplan-Meier</a></li>
<li class="chapter" data-level="15.2.2" data-path="survival-curve-estimation.html"><a href="survival-curve-estimation.html#weibull"><i class="fa fa-check"></i><b>15.2.2</b> Weibull</a></li>
<li class="chapter" data-level="15.2.3" data-path="survival-curve-estimation.html"><a href="survival-curve-estimation.html#cox"><i class="fa fa-check"></i><b>15.2.3</b> Cox</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="" data-path="appendix.html"><a href="appendix.html"><i class="fa fa-check"></i>Appendix</a><ul>
<li class="chapter" data-level="" data-path="publishing-to-bookdown.html"><a href="publishing-to-bookdown.html"><i class="fa fa-check"></i>Publishing to BookDown</a></li>
<li class="chapter" data-level="" data-path="shiny-apps.html"><a href="shiny-apps.html"><i class="fa fa-check"></i>Shiny Apps</a></li>
<li class="chapter" data-level="" data-path="packages.html"><a href="packages.html"><i class="fa fa-check"></i>Packages</a><ul>
<li class="chapter" data-level="" data-path="packages.html"><a href="packages.html#create-a-package"><i class="fa fa-check"></i>Create a package</a></li>
<li class="chapter" data-level="15.2.4" data-path="packages.html"><a href="packages.html#document-functions-with-roxygen"><i class="fa fa-check"></i><b>15.2.4</b> Document Functions with roxygen</a></li>
<li class="chapter" data-level="" data-path="packages.html"><a href="packages.html#create-data"><i class="fa fa-check"></i>Create Data</a></li>
<li class="chapter" data-level="" data-path="packages.html"><a href="packages.html#create-vignette"><i class="fa fa-check"></i>Create Vignette</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">My Data Science Notes</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="regression-trees" class="section level2">
<h2><span class="header-section-number">10.2</span> Regression Trees</h2>
<p>A simple regression tree is built in a manner similar to a simple classificatioon tree, and like the simple classification tree, it is rarely invoked on its own; the bagged, random forest, and gradient boosting methods build on this logic. I’ll learn by example again. Using the <code>ISLR::Carseats</code> data set, I will predict <code>Sales</code> using from the 10 feature variables. Load the data.</p>
<div class="sourceCode" id="cb628"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb628-1"><a href="regression-trees.html#cb628-1"></a>carseats_dat &lt;-<span class="st"> </span>Carseats</span>
<span id="cb628-2"><a href="regression-trees.html#cb628-2"></a><span class="co">#skim_with(numeric = list(p0 = NULL, p25 = NULL, p50 = NULL, p75 = NULL, </span></span>
<span id="cb628-3"><a href="regression-trees.html#cb628-3"></a><span class="co">#                                p100 = NULL, hist = NULL))</span></span>
<span id="cb628-4"><a href="regression-trees.html#cb628-4"></a><span class="co">#skim(carseats_dat)</span></span></code></pre></div>
<p>I’ll split <code>careseats_dat</code> (n = 400) into <code>carseats_train</code> (80%, n = 321) and <code>carseats_test</code> (20%, n = 79). I’ll fit a simple decision tree with <code>carseats_train</code>, then later a bagged tree, a random forest, and a gradient boosting tree. I’ll compare their predictive performance with <code>carseats_test</code>.</p>
<div class="sourceCode" id="cb629"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb629-1"><a href="regression-trees.html#cb629-1"></a><span class="kw">set.seed</span>(<span class="dv">12345</span>)</span>
<span id="cb629-2"><a href="regression-trees.html#cb629-2"></a>partition &lt;-<span class="st"> </span><span class="kw">createDataPartition</span>(<span class="dt">y =</span> carseats_dat<span class="op">$</span>Sales, <span class="dt">p =</span> <span class="fl">0.8</span>, <span class="dt">list =</span> <span class="ot">FALSE</span>)</span>
<span id="cb629-3"><a href="regression-trees.html#cb629-3"></a>carseats_train &lt;-<span class="st"> </span>carseats_dat[partition, ]</span>
<span id="cb629-4"><a href="regression-trees.html#cb629-4"></a>carseats_test &lt;-<span class="st"> </span>carseats_dat[<span class="op">-</span>partition, ]</span></code></pre></div>
<p>The first step is to build a full tree, then perform k-fold cross-validation to help select the optimal cost complexity (cp). The only difference here is the <code>rpart()</code> parameter <code>method = "anova"</code> to produce a regression tree.</p>
<div class="sourceCode" id="cb630"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb630-1"><a href="regression-trees.html#cb630-1"></a><span class="kw">set.seed</span>(<span class="dv">1234</span>)</span>
<span id="cb630-2"><a href="regression-trees.html#cb630-2"></a>carseats_model_<span class="dv">1</span> &lt;-<span class="st"> </span><span class="kw">rpart</span>(</span>
<span id="cb630-3"><a href="regression-trees.html#cb630-3"></a>   <span class="dt">formula =</span> Sales <span class="op">~</span><span class="st"> </span>.,</span>
<span id="cb630-4"><a href="regression-trees.html#cb630-4"></a>   <span class="dt">data =</span> carseats_train,</span>
<span id="cb630-5"><a href="regression-trees.html#cb630-5"></a>   <span class="dt">method =</span> <span class="st">&quot;anova&quot;</span>, </span>
<span id="cb630-6"><a href="regression-trees.html#cb630-6"></a>   <span class="dt">xval =</span> <span class="dv">10</span>,</span>
<span id="cb630-7"><a href="regression-trees.html#cb630-7"></a>   <span class="dt">model =</span> <span class="ot">TRUE</span>  <span class="co"># to plot splits with factor variables.</span></span>
<span id="cb630-8"><a href="regression-trees.html#cb630-8"></a>)</span>
<span id="cb630-9"><a href="regression-trees.html#cb630-9"></a><span class="kw">print</span>(carseats_model_<span class="dv">1</span>)</span></code></pre></div>
<pre><code>## n= 321 
## 
## node), split, n, deviance, yval
##       * denotes terminal node
## 
##  1) root 321 2600  7.5  
##    2) ShelveLoc=Bad,Medium 251 1500  6.8  
##      4) Price&gt;=1.1e+02 168  720  6.0  
##        8) ShelveLoc=Bad 50  170  4.7  
##         16) Population&lt; 2e+02 20   48  3.6 *
##         17) Population&gt;=2e+02 30   81  5.4 *
##        9) ShelveLoc=Medium 118  430  6.5  
##         18) Advertising&lt; 12 88  290  6.1  
##           36) CompPrice&lt; 1.4e+02 69  190  5.8  
##             72) Price&gt;=1.3e+02 16   51  4.5 *
##             73) Price&lt; 1.3e+02 53  110  6.2 *
##           37) CompPrice&gt;=1.4e+02 19   58  7.4 *
##         19) Advertising&gt;=12 30   83  7.8 *
##      5) Price&lt; 1.1e+02 83  440  8.4  
##       10) Age&gt;=64 32  150  6.9  
##         20) Price&gt;=85 25   67  6.2  
##           40) ShelveLoc=Bad 9   18  4.8 *
##           41) ShelveLoc=Medium 16   21  6.9 *
##         21) Price&lt; 85 7   20  9.6 *
##       11) Age&lt; 64 51  180  9.3  
##         22) Income&lt; 58 12   28  7.7 *
##         23) Income&gt;=58 39  120  9.7  
##           46) Age&gt;=50 14   21  8.5 *
##           47) Age&lt; 50 25   60 10.0 *
##    3) ShelveLoc=Good 70  420 10.0  
##      6) Price&gt;=1.1e+02 49  240  9.4  
##       12) Advertising&lt; 14 41  160  8.9  
##         24) Age&gt;=61 17   53  7.8 *
##         25) Age&lt; 61 24   69  9.8 *
##       13) Advertising&gt;=14 8   13 12.0 *
##      7) Price&lt; 1.1e+02 21   61 12.0 *</code></pre>
<p>The output starts with the root node. The predicted <code>Sales</code> at the root is the mean <code>Sales</code> for the training data set, 7.535950 (values are $000s). The deviance at the root is the SSE, 2567.768. The child nodes of node “x” are labeled 2x) and 2x+1), so the child nodes of 1) are 2) and 3), and the child nodes of 2) are 4) and 5). Terminal nodes are labeled with an asterisk (*).</p>
<p>The first split is at <code>ShelveLoc</code> = [Bad, Medium] vs Good. Here is what the full (unpruned) tree looks like.</p>
<div class="sourceCode" id="cb632"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb632-1"><a href="regression-trees.html#cb632-1"></a><span class="kw">rpart.plot</span>(carseats_model_<span class="dv">1</span>, <span class="dt">yesno =</span> <span class="ot">TRUE</span>)</span></code></pre></div>
<p><img src="data-sci_files/figure-html/unnamed-chunk-298-1.png" width="672" /></p>
<p>The boxes show the node predicted value (mean) and the proportion of observations that are in the node (or child nodes).</p>
<p><code>rpart()</code> not only grew the full tree, it also used cross-validation to test the performance of the possible complexity hyperparameters. <code>printcp()</code> displays the candidate cp values. You can use this table to decide how to prune the tree.</p>
<div class="sourceCode" id="cb633"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb633-1"><a href="regression-trees.html#cb633-1"></a><span class="kw">printcp</span>(carseats_model_<span class="dv">1</span>)</span></code></pre></div>
<pre><code>## 
## Regression tree:
## rpart(formula = Sales ~ ., data = carseats_train, method = &quot;anova&quot;, 
##     model = TRUE, xval = 10)
## 
## Variables actually used in tree construction:
## [1] Advertising Age         CompPrice   Income      Population  Price      
## [7] ShelveLoc  
## 
## Root node error: 2568/321 = 8
## 
## n= 321 
## 
##    CP nsplit rel error xerror xstd
## 1   0      0         1      1    0
## 2   0      1         1      1    0
## 3   0      2         1      1    0
## 4   0      3         1      1    0
## 5   0      4         1      1    0
## 6   0      5         0      1    0
## 7   0      6         0      1    0
## 8   0      7         0      1    0
## 9   0      8         0      1    0
## 10  0      9         0      1    0
## 11  0     10         0      1    0
## 12  0     11         0      1    0
## 13  0     12         0      1    0
## 14  0     13         0      1    0
## 15  0     14         0      1    0
## 16  0     15         0      1    0</code></pre>
<p>There are 16 possible cp values in this model. The model with the smallest complexity parameter allows the most splits (<code>nsplit</code>). The highest complexity parameter corresponds to a tree with just a root node. <code>rel error</code> is the SSE relative to the root node. The root node SSE is 2567.76800, so its <code>rel error</code> is 2567.76800/2567.76800 = 1.0. That means the absolute error of the full tree (at CP = 0.01) is 0.30963 * 2567.76800 = 795.058. You can verify that by calculating the SSE of the model predicted values:</p>
<div class="sourceCode" id="cb635"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb635-1"><a href="regression-trees.html#cb635-1"></a><span class="kw">data.frame</span>(<span class="dt">pred =</span> <span class="kw">predict</span>(carseats_model_<span class="dv">1</span>, <span class="dt">newdata =</span> carseats_train)) <span class="op">%&gt;%</span></span>
<span id="cb635-2"><a href="regression-trees.html#cb635-2"></a><span class="st">   </span><span class="kw">mutate</span>(<span class="dt">obs =</span> carseats_train<span class="op">$</span>Sales,</span>
<span id="cb635-3"><a href="regression-trees.html#cb635-3"></a>          <span class="dt">sq_err =</span> (obs <span class="op">-</span><span class="st"> </span>pred)<span class="op">^</span><span class="dv">2</span>) <span class="op">%&gt;%</span></span>
<span id="cb635-4"><a href="regression-trees.html#cb635-4"></a><span class="st">   </span><span class="kw">summarize</span>(<span class="dt">sse =</span> <span class="kw">sum</span>(sq_err))</span></code></pre></div>
<pre><code>##   sse
## 1 795</code></pre>
<p>Finishing the CP table tour, <code>xerror</code> is the cross-validated SSE and <code>xstd</code> is its standard error. If you want the lowest possible error, then prune to the tree with the smallest relative SSE (<code>xerror</code>). If you want to balance predictive power with simplicity, prune to the smallest tree within 1 SE of the one with the smallest relative SSE. The CP table is not super-helpful for finding that tree. I’ll add a column to find it.</p>
<div class="sourceCode" id="cb637"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb637-1"><a href="regression-trees.html#cb637-1"></a>carseats_model_<span class="dv">1</span><span class="op">$</span>cptable <span class="op">%&gt;%</span></span>
<span id="cb637-2"><a href="regression-trees.html#cb637-2"></a><span class="st">   </span><span class="kw">data.frame</span>() <span class="op">%&gt;%</span></span>
<span id="cb637-3"><a href="regression-trees.html#cb637-3"></a><span class="st">   </span><span class="kw">mutate</span>(<span class="dt">min_xerror_idx =</span> <span class="kw">which.min</span>(carseats_model_<span class="dv">1</span><span class="op">$</span>cptable[, <span class="st">&quot;xerror&quot;</span>]),</span>
<span id="cb637-4"><a href="regression-trees.html#cb637-4"></a>          <span class="dt">rownum =</span> <span class="kw">row_number</span>(),</span>
<span id="cb637-5"><a href="regression-trees.html#cb637-5"></a>          <span class="dt">xerror_cap =</span> carseats_model_<span class="dv">1</span><span class="op">$</span>cptable[min_xerror_idx, <span class="st">&quot;xerror&quot;</span>] <span class="op">+</span><span class="st"> </span></span>
<span id="cb637-6"><a href="regression-trees.html#cb637-6"></a><span class="st">             </span>carseats_model_<span class="dv">1</span><span class="op">$</span>cptable[min_xerror_idx, <span class="st">&quot;xstd&quot;</span>],</span>
<span id="cb637-7"><a href="regression-trees.html#cb637-7"></a>          <span class="dt">eval =</span> <span class="kw">case_when</span>(rownum <span class="op">==</span><span class="st"> </span>min_xerror_idx <span class="op">~</span><span class="st"> &quot;min xerror&quot;</span>,</span>
<span id="cb637-8"><a href="regression-trees.html#cb637-8"></a>                           xerror <span class="op">&lt;</span><span class="st"> </span>xerror_cap <span class="op">~</span><span class="st"> &quot;under cap&quot;</span>,</span>
<span id="cb637-9"><a href="regression-trees.html#cb637-9"></a>                           <span class="ot">TRUE</span> <span class="op">~</span><span class="st"> &quot;&quot;</span>)) <span class="op">%&gt;%</span></span>
<span id="cb637-10"><a href="regression-trees.html#cb637-10"></a><span class="st">   </span><span class="kw">select</span>(<span class="op">-</span>rownum, <span class="op">-</span>min_xerror_idx) </span></code></pre></div>
<pre><code>##       CP nsplit rel.error xerror  xstd xerror_cap       eval
## 1  0.263      0      1.00   1.01 0.077       0.59           
## 2  0.121      1      0.74   0.75 0.059       0.59           
## 3  0.046      2      0.62   0.65 0.051       0.59           
## 4  0.045      3      0.57   0.67 0.052       0.59           
## 5  0.042      4      0.52   0.66 0.051       0.59           
## 6  0.026      5      0.48   0.62 0.049       0.59           
## 7  0.026      6      0.46   0.62 0.048       0.59           
## 8  0.024      7      0.43   0.62 0.048       0.59           
## 9  0.015      8      0.41   0.58 0.042       0.59  under cap
## 10 0.015      9      0.39   0.56 0.041       0.59  under cap
## 11 0.015     10      0.38   0.56 0.041       0.59  under cap
## 12 0.014     11      0.36   0.56 0.041       0.59  under cap
## 13 0.014     12      0.35   0.56 0.038       0.59 min xerror
## 14 0.014     13      0.33   0.56 0.038       0.59  under cap
## 15 0.011     14      0.32   0.57 0.039       0.59  under cap
## 16 0.010     15      0.31   0.57 0.038       0.59  under cap</code></pre>
<p>Okay, so the simplest tree is the one with CP = 0.01544139 (8 splits). Fortunately, <code>plotcp()</code> presents a nice graphical representation of the relationship between <code>xerror</code> and <code>cp</code>.</p>
<div class="sourceCode" id="cb639"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb639-1"><a href="regression-trees.html#cb639-1"></a><span class="kw">plotcp</span>(carseats_model_<span class="dv">1</span>, <span class="dt">upper =</span> <span class="st">&quot;splits&quot;</span>)</span></code></pre></div>
<p><img src="data-sci_files/figure-html/unnamed-chunk-302-1.png" width="672" /></p>
<p>The dashed line is set at the minimum <code>xerror</code> + <code>xstd</code>. The top axis shows the number of splits in the tree. I’m not sure why the CP values are not the same as in the table (they are close, but not the same). The smallest relative error is at 0.01, but the maximum CP below the dashed line (one standard deviation above the mimimum error) is at CP = .019 (8 splits). Use the <code>prune()</code> function to prune the tree by specifying the associated cost-complexity <code>cp</code>.</p>
<div class="sourceCode" id="cb640"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb640-1"><a href="regression-trees.html#cb640-1"></a>carseats_model_<span class="dv">1</span>_pruned &lt;-<span class="st"> </span><span class="kw">prune</span>(</span>
<span id="cb640-2"><a href="regression-trees.html#cb640-2"></a>   carseats_model_<span class="dv">1</span>,</span>
<span id="cb640-3"><a href="regression-trees.html#cb640-3"></a>   <span class="dt">cp =</span> carseats_model_<span class="dv">1</span><span class="op">$</span>cptable[carseats_model_<span class="dv">1</span><span class="op">$</span>cptable[, <span class="dv">2</span>] <span class="op">==</span><span class="st"> </span><span class="dv">8</span>, <span class="st">&quot;CP&quot;</span>]</span>
<span id="cb640-4"><a href="regression-trees.html#cb640-4"></a>)</span>
<span id="cb640-5"><a href="regression-trees.html#cb640-5"></a><span class="kw">rpart.plot</span>(carseats_model_<span class="dv">1</span>_pruned, <span class="dt">yesno =</span> <span class="ot">TRUE</span>)</span></code></pre></div>
<p><img src="data-sci_files/figure-html/unnamed-chunk-303-1.png" width="672" /></p>
<p>The most “important” indicator of <code>Sales</code> is <code>ShelveLoc</code>. Here are the importance values from the model.</p>
<div class="sourceCode" id="cb641"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb641-1"><a href="regression-trees.html#cb641-1"></a>carseats_model_<span class="dv">1</span>_pruned<span class="op">$</span>variable.importance <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb641-2"><a href="regression-trees.html#cb641-2"></a><span class="st">   </span><span class="kw">data.frame</span>() <span class="op">%&gt;%</span></span>
<span id="cb641-3"><a href="regression-trees.html#cb641-3"></a><span class="st">   </span><span class="kw">rownames_to_column</span>(<span class="dt">var =</span> <span class="st">&quot;Feature&quot;</span>) <span class="op">%&gt;%</span></span>
<span id="cb641-4"><a href="regression-trees.html#cb641-4"></a><span class="st">   </span><span class="kw">rename</span>(<span class="dt">Overall =</span> <span class="st">&#39;.&#39;</span>) <span class="op">%&gt;%</span></span>
<span id="cb641-5"><a href="regression-trees.html#cb641-5"></a><span class="st">   </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> <span class="kw">fct_reorder</span>(Feature, Overall), <span class="dt">y =</span> Overall)) <span class="op">+</span></span>
<span id="cb641-6"><a href="regression-trees.html#cb641-6"></a><span class="st">   </span><span class="kw">geom_pointrange</span>(<span class="kw">aes</span>(<span class="dt">ymin =</span> <span class="dv">0</span>, <span class="dt">ymax =</span> Overall), <span class="dt">color =</span> <span class="st">&quot;cadetblue&quot;</span>, <span class="dt">size =</span> <span class="fl">.3</span>) <span class="op">+</span></span>
<span id="cb641-7"><a href="regression-trees.html#cb641-7"></a><span class="st">   </span><span class="kw">theme_minimal</span>() <span class="op">+</span></span>
<span id="cb641-8"><a href="regression-trees.html#cb641-8"></a><span class="st">   </span><span class="kw">coord_flip</span>() <span class="op">+</span></span>
<span id="cb641-9"><a href="regression-trees.html#cb641-9"></a><span class="st">   </span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="st">&quot;&quot;</span>, <span class="dt">y =</span> <span class="st">&quot;&quot;</span>, <span class="dt">title =</span> <span class="st">&quot;Variable Importance with Simple Regression&quot;</span>)</span></code></pre></div>
<p><img src="data-sci_files/figure-html/unnamed-chunk-304-1.png" width="672" /></p>
<p>The most important indicator of <code>Sales</code> is <code>ShelveLoc</code>, then <code>Price</code>, then <code>Age</code>, all of which appear in the final model. <code>CompPrice</code> was also important.</p>
<p>The last step is to make predictions on the validation data set. The root mean squared error (<span class="math inline">\(RMSE = \sqrt{(1/2) \sum{(actual - pred)^2}})\)</span> and mean absolute error (<span class="math inline">\(MAE = (1/n) \sum{|actual - pred|}\)</span>) are the two most common measures of predictive accuracy. The key difference is that RMSE punishes large errors more harshly. For a regression tree, set argument <code>type = "vector"</code> (or do not specify at all).</p>
<div class="sourceCode" id="cb642"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb642-1"><a href="regression-trees.html#cb642-1"></a>carseats_model_<span class="dv">1</span>_preds &lt;-<span class="st"> </span><span class="kw">predict</span>(</span>
<span id="cb642-2"><a href="regression-trees.html#cb642-2"></a>   carseats_model_<span class="dv">1</span>_pruned, </span>
<span id="cb642-3"><a href="regression-trees.html#cb642-3"></a>   carseats_test, </span>
<span id="cb642-4"><a href="regression-trees.html#cb642-4"></a>   <span class="dt">type =</span> <span class="st">&quot;vector&quot;</span></span>
<span id="cb642-5"><a href="regression-trees.html#cb642-5"></a>)</span>
<span id="cb642-6"><a href="regression-trees.html#cb642-6"></a></span>
<span id="cb642-7"><a href="regression-trees.html#cb642-7"></a>carseats_model_<span class="dv">1</span>_pruned_rmse &lt;-<span class="st"> </span><span class="kw">RMSE</span>(</span>
<span id="cb642-8"><a href="regression-trees.html#cb642-8"></a>   <span class="dt">pred =</span> carseats_model_<span class="dv">1</span>_preds,</span>
<span id="cb642-9"><a href="regression-trees.html#cb642-9"></a>   <span class="dt">obs =</span> carseats_test<span class="op">$</span>Sales</span>
<span id="cb642-10"><a href="regression-trees.html#cb642-10"></a>)</span>
<span id="cb642-11"><a href="regression-trees.html#cb642-11"></a>carseats_model_<span class="dv">1</span>_pruned_rmse</span></code></pre></div>
<pre><code>## [1] 2.4</code></pre>
<p>The pruning process leads to an average prediction error of 2.39 in the test data set. Not too bad considering the standard deviation of <code>Sales</code> is 2.8. Here is a predicted vs actual plot.</p>
<div class="sourceCode" id="cb644"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb644-1"><a href="regression-trees.html#cb644-1"></a><span class="kw">plot</span>(carseats_test<span class="op">$</span>Sales, carseats_model_<span class="dv">1</span>_preds, </span>
<span id="cb644-2"><a href="regression-trees.html#cb644-2"></a>     <span class="dt">main =</span> <span class="st">&quot;Simple Regression: Predicted vs. Actual&quot;</span>,</span>
<span id="cb644-3"><a href="regression-trees.html#cb644-3"></a>     <span class="dt">xlab =</span> <span class="st">&quot;Actual&quot;</span>,</span>
<span id="cb644-4"><a href="regression-trees.html#cb644-4"></a>     <span class="dt">ylab =</span> <span class="st">&quot;Predicted&quot;</span>)</span>
<span id="cb644-5"><a href="regression-trees.html#cb644-5"></a><span class="kw">abline</span>(<span class="dv">0</span>, <span class="dv">1</span>)</span></code></pre></div>
<p><img src="data-sci_files/figure-html/unnamed-chunk-306-1.png" width="672" /></p>
<p>The 6 possible predicted values do a decent job of binning the observations.</p>
<div id="caret-approach-1" class="section level3">
<h3><span class="header-section-number">10.2.1</span> Caret Approach</h3>
<p>I can also fit the model with <code>caret::train()</code>, specifying <code>method = "rpart"</code>.</p>
<p>I’ll build the model using 10-fold cross-validation to optimize the hyperparameter CP.</p>
<div class="sourceCode" id="cb645"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb645-1"><a href="regression-trees.html#cb645-1"></a>carseats_trControl =<span class="st"> </span><span class="kw">trainControl</span>(</span>
<span id="cb645-2"><a href="regression-trees.html#cb645-2"></a>   <span class="dt">method =</span> <span class="st">&quot;cv&quot;</span>,  <span class="co"># k-fold cross validation</span></span>
<span id="cb645-3"><a href="regression-trees.html#cb645-3"></a>   <span class="dt">number =</span> <span class="dv">10</span>,  <span class="co"># 10 folds</span></span>
<span id="cb645-4"><a href="regression-trees.html#cb645-4"></a>   <span class="dt">savePredictions =</span> <span class="st">&quot;final&quot;</span>       <span class="co"># save predictions for the optimal tuning parameter</span></span>
<span id="cb645-5"><a href="regression-trees.html#cb645-5"></a>)</span></code></pre></div>
<p>I’ll let the model look for the best CP tuning parameter with <code>tuneLength</code> to get close, then fine-tune with <code>tuneGrid</code>.</p>
<div class="sourceCode" id="cb646"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb646-1"><a href="regression-trees.html#cb646-1"></a><span class="kw">set.seed</span>(<span class="dv">1234</span>)</span>
<span id="cb646-2"><a href="regression-trees.html#cb646-2"></a>carseats_model_<span class="dv">2</span> =<span class="st"> </span><span class="kw">train</span>(</span>
<span id="cb646-3"><a href="regression-trees.html#cb646-3"></a>   Sales <span class="op">~</span><span class="st"> </span>., </span>
<span id="cb646-4"><a href="regression-trees.html#cb646-4"></a>   <span class="dt">data =</span> carseats_train, </span>
<span id="cb646-5"><a href="regression-trees.html#cb646-5"></a>   <span class="dt">method =</span> <span class="st">&quot;rpart&quot;</span>,  <span class="co"># for classification tree</span></span>
<span id="cb646-6"><a href="regression-trees.html#cb646-6"></a>   <span class="dt">tuneLength =</span> <span class="dv">5</span>,  <span class="co"># choose up to 5 combinations of tuning parameters (cp)</span></span>
<span id="cb646-7"><a href="regression-trees.html#cb646-7"></a>   <span class="dt">metric =</span> <span class="st">&quot;RMSE&quot;</span>,  <span class="co"># evaluate hyperparamter combinations with RMSE</span></span>
<span id="cb646-8"><a href="regression-trees.html#cb646-8"></a>   <span class="dt">trControl =</span> carseats_trControl</span>
<span id="cb646-9"><a href="regression-trees.html#cb646-9"></a>)</span></code></pre></div>
<pre><code>## Warning in nominalTrainWorkflow(x = x, y = y, wts = weights, info = trainInfo, :
## There were missing values in resampled performance measures.</code></pre>
<div class="sourceCode" id="cb648"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb648-1"><a href="regression-trees.html#cb648-1"></a><span class="kw">print</span>(carseats_model_<span class="dv">2</span>)</span></code></pre></div>
<pre><code>## CART 
## 
## 321 samples
##  10 predictor
## 
## No pre-processing
## Resampling: Cross-Validated (10 fold) 
## Summary of sample sizes: 289, 289, 289, 289, 289, 289, ... 
## Resampling results across tuning parameters:
## 
##   cp     RMSE  Rsquared  MAE
##   0.042  2.2   0.41      1.8
##   0.045  2.2   0.38      1.8
##   0.046  2.3   0.37      1.8
##   0.121  2.4   0.29      1.9
##   0.263  2.7   0.19      2.2
## 
## RMSE was used to select the optimal model using the smallest value.
## The final value used for the model was cp = 0.042.</code></pre>
<p>The first <code>cp</code> (0.04167149) produced the smallest RMSE. I can drill into the best value of <code>cp</code> using a tuning grid. I’ll try that now.</p>
<div class="sourceCode" id="cb650"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb650-1"><a href="regression-trees.html#cb650-1"></a>myGrid &lt;-<span class="st">  </span><span class="kw">expand.grid</span>(<span class="dt">cp =</span> <span class="kw">seq</span>(<span class="dt">from =</span> <span class="dv">0</span>, <span class="dt">to =</span> <span class="fl">0.1</span>, <span class="dt">by =</span> <span class="fl">0.01</span>))</span>
<span id="cb650-2"><a href="regression-trees.html#cb650-2"></a>carseats_model_<span class="dv">3</span> =<span class="st"> </span><span class="kw">train</span>(</span>
<span id="cb650-3"><a href="regression-trees.html#cb650-3"></a>   Sales <span class="op">~</span><span class="st"> </span>., </span>
<span id="cb650-4"><a href="regression-trees.html#cb650-4"></a>   <span class="dt">data =</span> carseats_train, </span>
<span id="cb650-5"><a href="regression-trees.html#cb650-5"></a>   <span class="dt">method =</span> <span class="st">&quot;rpart&quot;</span>,  <span class="co"># for classification tree</span></span>
<span id="cb650-6"><a href="regression-trees.html#cb650-6"></a>   <span class="dt">tuneGrid =</span> myGrid,  <span class="co"># choose up to 5 combinations of tuning parameters (cp)</span></span>
<span id="cb650-7"><a href="regression-trees.html#cb650-7"></a>   <span class="dt">metric =</span> <span class="st">&quot;RMSE&quot;</span>,  <span class="co"># evaluate hyperparamter combinations with RMSE</span></span>
<span id="cb650-8"><a href="regression-trees.html#cb650-8"></a>   <span class="dt">trControl =</span> carseats_trControl</span>
<span id="cb650-9"><a href="regression-trees.html#cb650-9"></a>)</span>
<span id="cb650-10"><a href="regression-trees.html#cb650-10"></a><span class="kw">print</span>(carseats_model_<span class="dv">3</span>)</span></code></pre></div>
<pre><code>## CART 
## 
## 321 samples
##  10 predictor
## 
## No pre-processing
## Resampling: Cross-Validated (10 fold) 
## Summary of sample sizes: 289, 289, 289, 289, 288, 289, ... 
## Resampling results across tuning parameters:
## 
##   cp    RMSE  Rsquared  MAE
##   0.00  2.1   0.46      1.7
##   0.01  2.2   0.43      1.8
##   0.02  2.2   0.39      1.8
##   0.03  2.2   0.41      1.8
##   0.04  2.3   0.37      1.8
##   0.05  2.3   0.34      1.8
##   0.06  2.2   0.37      1.8
##   0.07  2.3   0.37      1.8
##   0.08  2.3   0.37      1.8
##   0.09  2.3   0.37      1.8
##   0.10  2.3   0.37      1.8
## 
## RMSE was used to select the optimal model using the smallest value.
## The final value used for the model was cp = 0.</code></pre>
<p>It looks like the best performing tree is the unpruned one.</p>
<div class="sourceCode" id="cb652"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb652-1"><a href="regression-trees.html#cb652-1"></a><span class="kw">plot</span>(carseats_model_<span class="dv">3</span>)</span></code></pre></div>
<p><img src="data-sci_files/figure-html/unnamed-chunk-310-1.png" width="672" /></p>
<p>Lets’s see the final model.</p>
<div class="sourceCode" id="cb653"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb653-1"><a href="regression-trees.html#cb653-1"></a><span class="kw">rpart.plot</span>(carseats_model_<span class="dv">3</span><span class="op">$</span>finalModel)</span></code></pre></div>
<p><img src="data-sci_files/figure-html/unnamed-chunk-311-1.png" width="672" /></p>
<p>What were the most important variables?</p>
<div class="sourceCode" id="cb654"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb654-1"><a href="regression-trees.html#cb654-1"></a><span class="kw">plot</span>(<span class="kw">varImp</span>(carseats_model_<span class="dv">3</span>), <span class="dt">main=</span><span class="st">&quot;Variable Importance with Simple Regression&quot;</span>)</span></code></pre></div>
<p><img src="data-sci_files/figure-html/unnamed-chunk-312-1.png" width="672" /></p>
<p>Evaluate the model by making predictions with the test data set.</p>
<div class="sourceCode" id="cb655"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb655-1"><a href="regression-trees.html#cb655-1"></a>carseats_model_<span class="dv">3</span>_preds &lt;-<span class="st"> </span><span class="kw">predict</span>(carseats_model_<span class="dv">3</span>, carseats_test, <span class="dt">type =</span> <span class="st">&quot;raw&quot;</span>)</span>
<span id="cb655-2"><a href="regression-trees.html#cb655-2"></a><span class="kw">data.frame</span>(<span class="dt">Actual =</span> carseats_test<span class="op">$</span>Sales, <span class="dt">Predicted =</span> carseats_model_<span class="dv">3</span>_preds) <span class="op">%&gt;%</span></span>
<span id="cb655-3"><a href="regression-trees.html#cb655-3"></a><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> Actual, <span class="dt">y =</span> Predicted)) <span class="op">+</span></span>
<span id="cb655-4"><a href="regression-trees.html#cb655-4"></a><span class="st">   </span><span class="kw">geom_point</span>() <span class="op">+</span></span>
<span id="cb655-5"><a href="regression-trees.html#cb655-5"></a><span class="st">   </span><span class="kw">geom_smooth</span>() <span class="op">+</span></span>
<span id="cb655-6"><a href="regression-trees.html#cb655-6"></a><span class="st">   </span><span class="kw">geom_abline</span>(<span class="dt">slope =</span> <span class="dv">1</span>, <span class="dt">intercept =</span> <span class="dv">0</span>) <span class="op">+</span><span class="st"> </span></span>
<span id="cb655-7"><a href="regression-trees.html#cb655-7"></a><span class="st">   </span><span class="kw">scale_y_continuous</span>(<span class="dt">limits =</span> <span class="kw">c</span>(<span class="dv">0</span>, <span class="dv">15</span>)) <span class="op">+</span></span>
<span id="cb655-8"><a href="regression-trees.html#cb655-8"></a><span class="st">   </span><span class="kw">labs</span>(<span class="dt">title =</span> <span class="st">&quot;Simple Regression: Predicted vs. Actual&quot;</span>)</span></code></pre></div>
<pre><code>## `geom_smooth()` using method = &#39;loess&#39; and formula &#39;y ~ x&#39;</code></pre>
<p><img src="data-sci_files/figure-html/unnamed-chunk-313-1.png" width="672" /></p>
<p>Looks like the model over-estimates at the low end and undestimates at the high end. Calculate the test data set RMSE.</p>
<div class="sourceCode" id="cb657"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb657-1"><a href="regression-trees.html#cb657-1"></a>carseats_model_<span class="dv">3</span>_pruned_rmse &lt;-<span class="st"> </span><span class="kw">RMSE</span>(</span>
<span id="cb657-2"><a href="regression-trees.html#cb657-2"></a>   <span class="dt">pred =</span> carseats_model_<span class="dv">3</span>_preds,</span>
<span id="cb657-3"><a href="regression-trees.html#cb657-3"></a>   <span class="dt">obs =</span> carseats_test<span class="op">$</span>Sales</span>
<span id="cb657-4"><a href="regression-trees.html#cb657-4"></a>)</span>
<span id="cb657-5"><a href="regression-trees.html#cb657-5"></a>carseats_model_<span class="dv">3</span>_pruned_rmse</span></code></pre></div>
<pre><code>## [1] 2.3</code></pre>
<p>Caret faired better in this model. Here is a summary the RMSE values of the two models.</p>
<div class="sourceCode" id="cb659"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb659-1"><a href="regression-trees.html#cb659-1"></a><span class="kw">rbind</span>(<span class="kw">data.frame</span>(<span class="dt">model =</span> <span class="st">&quot;Manual ANOVA&quot;</span>, </span>
<span id="cb659-2"><a href="regression-trees.html#cb659-2"></a>                 <span class="dt">RMSE =</span> <span class="kw">round</span>(carseats_model_<span class="dv">1</span>_pruned_rmse, <span class="dv">5</span>)), </span>
<span id="cb659-3"><a href="regression-trees.html#cb659-3"></a>      <span class="kw">data.frame</span>(<span class="dt">model =</span> <span class="st">&quot;Caret&quot;</span>, </span>
<span id="cb659-4"><a href="regression-trees.html#cb659-4"></a>                 <span class="dt">RMSE =</span> <span class="kw">round</span>(carseats_model_<span class="dv">3</span>_pruned_rmse, <span class="dv">5</span>))</span>
<span id="cb659-5"><a href="regression-trees.html#cb659-5"></a>)</span></code></pre></div>
<pre><code>##          model RMSE
## 1 Manual ANOVA  2.4
## 2        Caret  2.3</code></pre>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="classification-tree.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="bagging.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="assets/gitbook-2.6.7/js/app.min.js"></script>
<script src="assets/gitbook-2.6.7/js/lunr.js"></script>
<script src="assets/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="assets/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="assets/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="assets/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="assets/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="assets/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="assets/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["data-sci.pdf", "data-sci.epub"],
"toc": {
"collapse": "subsection"
},
"toolbar": {
"position": "static"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
