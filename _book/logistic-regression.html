<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>7.1 Logistic Regression | My Data Science Notes</title>
  <meta name="description" content="This is a compendium of notes from classes, tutorials, etc. that I reference from time to time." />
  <meta name="generator" content="bookdown 0.17 and GitBook 2.6.7" />

  <meta property="og:title" content="7.1 Logistic Regression | My Data Science Notes" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="This is a compendium of notes from classes, tutorials, etc. that I reference from time to time." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="7.1 Logistic Regression | My Data Science Notes" />
  
  <meta name="twitter:description" content="This is a compendium of notes from classes, tutorials, etc. that I reference from time to time." />
  

<meta name="author" content="Michael Foley" />


<meta name="date" content="2020-03-26" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="generalized-linear-models.html"/>
<link rel="next" href="multinomial-logistic-regression.html"/>
<script src="assets/jquery-2.2.3/jquery.min.js"></script>
<link href="assets/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="assets/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="assets/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="assets/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="assets/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="assets/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="assets/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />











<style type="text/css">
code.sourceCode > span { display: inline-block; line-height: 1.25; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">My Data Science Notes</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Intro</a></li>
<li class="chapter" data-level="1" data-path="probability.html"><a href="probability.html"><i class="fa fa-check"></i><b>1</b> Probability</a><ul>
<li class="chapter" data-level="1.1" data-path="principles.html"><a href="principles.html"><i class="fa fa-check"></i><b>1.1</b> Principles</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="disc-dist.html"><a href="disc-dist.html"><i class="fa fa-check"></i><b>2</b> Discrete Distributions</a><ul>
<li class="chapter" data-level="2.1" data-path="bernoulli.html"><a href="bernoulli.html"><i class="fa fa-check"></i><b>2.1</b> Bernoulli</a></li>
<li class="chapter" data-level="2.2" data-path="binomial.html"><a href="binomial.html"><i class="fa fa-check"></i><b>2.2</b> Binomial</a></li>
<li class="chapter" data-level="2.3" data-path="poission.html"><a href="poission.html"><i class="fa fa-check"></i><b>2.3</b> Poission</a></li>
<li class="chapter" data-level="2.4" data-path="multinomial.html"><a href="multinomial.html"><i class="fa fa-check"></i><b>2.4</b> Multinomial</a></li>
<li class="chapter" data-level="2.5" data-path="negative-binomial.html"><a href="negative-binomial.html"><i class="fa fa-check"></i><b>2.5</b> Negative-Binomial</a></li>
<li class="chapter" data-level="2.6" data-path="geometric.html"><a href="geometric.html"><i class="fa fa-check"></i><b>2.6</b> Geometric</a></li>
<li class="chapter" data-level="2.7" data-path="hypergeometric.html"><a href="hypergeometric.html"><i class="fa fa-check"></i><b>2.7</b> Hypergeometric</a></li>
<li class="chapter" data-level="2.8" data-path="gamma.html"><a href="gamma.html"><i class="fa fa-check"></i><b>2.8</b> Gamma</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="cont-dist.html"><a href="cont-dist.html"><i class="fa fa-check"></i><b>3</b> Continuous Distributions</a><ul>
<li class="chapter" data-level="3.1" data-path="normal.html"><a href="normal.html"><i class="fa fa-check"></i><b>3.1</b> Normal</a><ul>
<li class="chapter" data-level="3.1.1" data-path="normal.html"><a href="normal.html#example-2"><i class="fa fa-check"></i><b>3.1.1</b> Example</a></li>
<li class="chapter" data-level="3.1.2" data-path="normal.html"><a href="normal.html#example-3"><i class="fa fa-check"></i><b>3.1.2</b> Example</a></li>
<li class="chapter" data-level="3.1.3" data-path="normal.html"><a href="normal.html#example-4"><i class="fa fa-check"></i><b>3.1.3</b> Example</a></li>
<li class="chapter" data-level="3.1.4" data-path="normal.html"><a href="normal.html#normal-approximation-to-binomial"><i class="fa fa-check"></i><b>3.1.4</b> Normal Approximation to Binomial</a></li>
<li class="chapter" data-level="3.1.5" data-path="normal.html"><a href="normal.html#example-5"><i class="fa fa-check"></i><b>3.1.5</b> Example</a></li>
<li class="chapter" data-level="3.1.6" data-path="normal.html"><a href="normal.html#example-6"><i class="fa fa-check"></i><b>3.1.6</b> Example</a></li>
<li class="chapter" data-level="3.1.7" data-path="normal.html"><a href="normal.html#from-sample-to-population"><i class="fa fa-check"></i><b>3.1.7</b> From Sample to Population</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="join-distributions.html"><a href="join-distributions.html"><i class="fa fa-check"></i><b>3.2</b> Join Distributions</a></li>
<li class="chapter" data-level="3.3" data-path="likelihood.html"><a href="likelihood.html"><i class="fa fa-check"></i><b>3.3</b> Likelihood</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="discrete-analysis.html"><a href="discrete-analysis.html"><i class="fa fa-check"></i><b>4</b> Categorical Analysis - Nonmodel</a><ul>
<li class="chapter" data-level="4.1" data-path="chi-square-test.html"><a href="chi-square-test.html"><i class="fa fa-check"></i><b>4.1</b> Chi-Square Test</a></li>
<li class="chapter" data-level="4.2" data-path="one-way-tables.html"><a href="one-way-tables.html"><i class="fa fa-check"></i><b>4.2</b> One-Way Tables</a><ul>
<li class="chapter" data-level="4.2.1" data-path="one-way-tables.html"><a href="one-way-tables.html#chi-square-goodness-of-fit-test"><i class="fa fa-check"></i><b>4.2.1</b> Chi-Square Goodness-of-Fit Test</a></li>
<li class="chapter" data-level="4.2.2" data-path="one-way-tables.html"><a href="one-way-tables.html#proportion-test"><i class="fa fa-check"></i><b>4.2.2</b> Proportion Test</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="two-way-tables.html"><a href="two-way-tables.html"><i class="fa fa-check"></i><b>4.3</b> Two-Way Tables</a><ul>
<li class="chapter" data-level="4.3.1" data-path="two-way-tables.html"><a href="two-way-tables.html#chi-square-independence-test"><i class="fa fa-check"></i><b>4.3.1</b> Chi-Square Independence Test</a></li>
<li class="chapter" data-level="4.3.2" data-path="two-way-tables.html"><a href="two-way-tables.html#residuals-analysis"><i class="fa fa-check"></i><b>4.3.2</b> Residuals Analysis</a></li>
<li class="chapter" data-level="4.3.3" data-path="two-way-tables.html"><a href="two-way-tables.html#difference-in-proportions"><i class="fa fa-check"></i><b>4.3.3</b> Difference in Proportions</a></li>
<li class="chapter" data-level="4.3.4" data-path="two-way-tables.html"><a href="two-way-tables.html#relative-risk"><i class="fa fa-check"></i><b>4.3.4</b> Relative Risk</a></li>
<li class="chapter" data-level="4.3.5" data-path="two-way-tables.html"><a href="two-way-tables.html#odds-ratio"><i class="fa fa-check"></i><b>4.3.5</b> Odds Ratio</a></li>
<li class="chapter" data-level="4.3.6" data-path="two-way-tables.html"><a href="two-way-tables.html#partitioning-chi-square"><i class="fa fa-check"></i><b>4.3.6</b> Partitioning Chi-Square</a></li>
<li class="chapter" data-level="4.3.7" data-path="two-way-tables.html"><a href="two-way-tables.html#correlation"><i class="fa fa-check"></i><b>4.3.7</b> Correlation</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="k-way-tables.html"><a href="k-way-tables.html"><i class="fa fa-check"></i><b>4.4</b> K-Way Tables</a><ul>
<li class="chapter" data-level="4.4.1" data-path="k-way-tables.html"><a href="k-way-tables.html#odds-ratio-1"><i class="fa fa-check"></i><b>4.4.1</b> Odds Ratio</a></li>
<li class="chapter" data-level="4.4.2" data-path="k-way-tables.html"><a href="k-way-tables.html#chi-square-independence-test-1"><i class="fa fa-check"></i><b>4.4.2</b> Chi-Square Independence Test</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="continuous-analysis.html"><a href="continuous-analysis.html"><i class="fa fa-check"></i><b>5</b> Continuous Variable Analysis</a><ul>
<li class="chapter" data-level="5.0.1" data-path="continuous-analysis.html"><a href="continuous-analysis.html#correlation-1"><i class="fa fa-check"></i><b>5.0.1</b> Correlation</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="regression.html"><a href="regression.html"><i class="fa fa-check"></i><b>6</b> Regression</a></li>
<li class="chapter" data-level="7" data-path="generalized-linear-models.html"><a href="generalized-linear-models.html"><i class="fa fa-check"></i><b>7</b> Generalized Linear Models</a><ul>
<li class="chapter" data-level="7.1" data-path="logistic-regression.html"><a href="logistic-regression.html"><i class="fa fa-check"></i><b>7.1</b> Logistic Regression</a><ul>
<li class="chapter" data-level="7.1.1" data-path="logistic-regression.html"><a href="logistic-regression.html#case-study"><i class="fa fa-check"></i><b>7.1.1</b> Case Study</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="multinomial-logistic-regression.html"><a href="multinomial-logistic-regression.html"><i class="fa fa-check"></i><b>7.2</b> Multinomial Logistic Regression</a></li>
<li class="chapter" data-level="7.3" data-path="ordinal-logistic-regression.html"><a href="ordinal-logistic-regression.html"><i class="fa fa-check"></i><b>7.3</b> Ordinal Logistic Regression</a></li>
<li class="chapter" data-level="7.4" data-path="poisson-regression.html"><a href="poisson-regression.html"><i class="fa fa-check"></i><b>7.4</b> Poisson Regression</a><ul>
<li class="chapter" data-level="" data-path="poisson-regression.html"><a href="poisson-regression.html#example-7"><i class="fa fa-check"></i>Example</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="classification.html"><a href="classification.html"><i class="fa fa-check"></i><b>8</b> Classification</a></li>
<li class="chapter" data-level="9" data-path="classification-1.html"><a href="classification-1.html"><i class="fa fa-check"></i><b>9</b> Classification</a></li>
<li class="chapter" data-level="10" data-path="decision-trees.html"><a href="decision-trees.html"><i class="fa fa-check"></i><b>10</b> Decision Trees</a><ul>
<li class="chapter" data-level="10.1" data-path="classification-tree.html"><a href="classification-tree.html"><i class="fa fa-check"></i><b>10.1</b> Classification Tree</a><ul>
<li class="chapter" data-level="10.1.1" data-path="classification-tree.html"><a href="classification-tree.html#confusion-matrix"><i class="fa fa-check"></i><b>10.1.1</b> Confusion Matrix</a></li>
<li class="chapter" data-level="10.1.2" data-path="classification-tree.html"><a href="classification-tree.html#roc-curve"><i class="fa fa-check"></i><b>10.1.2</b> ROC Curve</a></li>
<li class="chapter" data-level="10.1.3" data-path="classification-tree.html"><a href="classification-tree.html#caret-approach"><i class="fa fa-check"></i><b>10.1.3</b> Caret Approach</a></li>
</ul></li>
<li class="chapter" data-level="10.2" data-path="regression-trees.html"><a href="regression-trees.html"><i class="fa fa-check"></i><b>10.2</b> Regression Trees</a><ul>
<li class="chapter" data-level="10.2.1" data-path="regression-trees.html"><a href="regression-trees.html#caret-approach-1"><i class="fa fa-check"></i><b>10.2.1</b> Caret Approach</a></li>
</ul></li>
<li class="chapter" data-level="10.3" data-path="bagging.html"><a href="bagging.html"><i class="fa fa-check"></i><b>10.3</b> Bagging</a></li>
<li class="chapter" data-level="10.4" data-path="random-forests.html"><a href="random-forests.html"><i class="fa fa-check"></i><b>10.4</b> Random Forests</a></li>
<li class="chapter" data-level="10.5" data-path="gradient-boosting.html"><a href="gradient-boosting.html"><i class="fa fa-check"></i><b>10.5</b> Gradient Boosting</a></li>
<li class="chapter" data-level="10.6" data-path="summary.html"><a href="summary.html"><i class="fa fa-check"></i><b>10.6</b> Summary</a></li>
<li class="chapter" data-level="10.7" data-path="reference.html"><a href="reference.html"><i class="fa fa-check"></i><b>10.7</b> Reference</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="regularization.html"><a href="regularization.html"><i class="fa fa-check"></i><b>11</b> Regularization</a></li>
<li class="chapter" data-level="12" data-path="non-linear-models.html"><a href="non-linear-models.html"><i class="fa fa-check"></i><b>12</b> Non-linear Models</a><ul>
<li class="chapter" data-level="12.1" data-path="splines.html"><a href="splines.html"><i class="fa fa-check"></i><b>12.1</b> Splines</a></li>
<li class="chapter" data-level="12.2" data-path="mars.html"><a href="mars.html"><i class="fa fa-check"></i><b>12.2</b> MARS</a></li>
<li class="chapter" data-level="12.3" data-path="gam.html"><a href="gam.html"><i class="fa fa-check"></i><b>12.3</b> GAM</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="support-vector-machines.html"><a href="support-vector-machines.html"><i class="fa fa-check"></i><b>13</b> Support Vector Machines</a><ul>
<li class="chapter" data-level="13.1" data-path="maximal-margin-classifier.html"><a href="maximal-margin-classifier.html"><i class="fa fa-check"></i><b>13.1</b> Maximal Margin Classifier</a></li>
<li class="chapter" data-level="13.2" data-path="support-vector-classifier.html"><a href="support-vector-classifier.html"><i class="fa fa-check"></i><b>13.2</b> Support Vector Classifier</a></li>
<li class="chapter" data-level="13.3" data-path="support-vector-machines-1.html"><a href="support-vector-machines-1.html"><i class="fa fa-check"></i><b>13.3</b> Support Vector Machines</a></li>
<li class="chapter" data-level="13.4" data-path="example-8.html"><a href="example-8.html"><i class="fa fa-check"></i><b>13.4</b> Example</a></li>
<li class="chapter" data-level="13.5" data-path="using-caret.html"><a href="using-caret.html"><i class="fa fa-check"></i><b>13.5</b> Using Caret</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="principal-components-analysis.html"><a href="principal-components-analysis.html"><i class="fa fa-check"></i><b>14</b> Principal Components Analysis</a></li>
<li class="chapter" data-level="15" data-path="clustering.html"><a href="clustering.html"><i class="fa fa-check"></i><b>15</b> Clustering</a></li>
<li class="chapter" data-level="16" data-path="text-mining.html"><a href="text-mining.html"><i class="fa fa-check"></i><b>16</b> Text Mining</a></li>
<li class="chapter" data-level="" data-path="appendix.html"><a href="appendix.html"><i class="fa fa-check"></i>Appendix</a><ul>
<li class="chapter" data-level="" data-path="publishing-to-bookdown.html"><a href="publishing-to-bookdown.html"><i class="fa fa-check"></i>Publishing to BookDown</a></li>
<li class="chapter" data-level="" data-path="shiny-apps.html"><a href="shiny-apps.html"><i class="fa fa-check"></i>Shiny Apps</a></li>
<li class="chapter" data-level="" data-path="packages.html"><a href="packages.html"><i class="fa fa-check"></i>Packages</a><ul>
<li class="chapter" data-level="" data-path="packages.html"><a href="packages.html#create-a-package"><i class="fa fa-check"></i>Create a package</a></li>
<li class="chapter" data-level="16.0.1" data-path="packages.html"><a href="packages.html#document-functions-with-roxygen"><i class="fa fa-check"></i><b>16.0.1</b> Document Functions with roxygen</a></li>
<li class="chapter" data-level="" data-path="packages.html"><a href="packages.html#create-data"><i class="fa fa-check"></i>Create Data</a></li>
<li class="chapter" data-level="" data-path="packages.html"><a href="packages.html#create-vignette"><i class="fa fa-check"></i>Create Vignette</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">My Data Science Notes</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="logistic-regression" class="section level2">
<h2><span class="header-section-number">7.1</span> Logistic Regression</h2>
<p>Logistic regression estimates the probability of a particular level of a categorical response variable given a set of predictors. The response levels can be binary, nominal (multiple categories), or ordinal (multiple levels).</p>
<p>The <strong>binary</strong> logistic regression model is</p>
<p><span class="math display">\[y = logit(\pi) = \ln \left( \frac{\pi}{1 - \pi} \right) = X \beta\]</span></p>
<p>where <span class="math inline">\(\pi\)</span> is the event probability. The model predicts the <em>log odds</em> of the response variable. The maximum likelihood estimator maximizes the likelihood function</p>
<p><span class="math display">\[L(\beta; y, X) = \prod_{i=1}^n \pi_i^{y_i}(1 - \pi_i)^{(1-y_i)} = \prod_{i=1}^n\frac{\exp(y_i X_i \beta)}{1 + \exp(X_i \beta)}.\]</span></p>
<p>There is no closed-form solution, so GLM estimates coefficients with interatively reweighted least squares.</p>
<p>Here is a case study to illustrate the points. Dataset <code>leuk</code> contains response variable <code>REMISS</code> indicating whether leukemia remission occurred (1|0) and several explanatory variables.</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1-1"><a href="logistic-regression.html#cb1-1"></a><span class="kw">glimpse</span>(leuk)</span></code></pre></div>
<pre><code>## Observations: 27
## Variables: 7
## $ REMISS &lt;dbl&gt; 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, ...
## $ CELL   &lt;dbl&gt; 0.80, 0.90, 0.80, 1.00, 0.90, 1.00, 0.95, 0.95, 1.00, 0.95, ...
## $ SMEAR  &lt;dbl&gt; 0.83, 0.36, 0.88, 0.87, 0.75, 0.65, 0.97, 0.87, 0.45, 0.36, ...
## $ INFIL  &lt;dbl&gt; 0.66, 0.32, 0.70, 0.87, 0.68, 0.65, 0.92, 0.83, 0.45, 0.34, ...
## $ LI     &lt;dbl&gt; 1.9, 1.4, 0.8, 0.7, 1.3, 0.6, 1.0, 1.9, 0.8, 0.5, 0.7, 1.2, ...
## $ BLAST  &lt;dbl&gt; 1.10, 0.74, 0.18, 1.05, 0.52, 0.52, 1.23, 1.35, 0.32, 0.00, ...
## $ TEMP   &lt;dbl&gt; 1.00, 0.99, 0.98, 0.99, 0.98, 0.98, 0.99, 1.02, 1.00, 1.04, ...</code></pre>
<p>Fit a logistic regression.</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb3-1"><a href="logistic-regression.html#cb3-1"></a>m1 &lt;-<span class="st"> </span><span class="kw">glm</span>(REMISS <span class="op">~</span><span class="st"> </span>., <span class="dt">family =</span> <span class="kw">binomial</span>(<span class="dt">link =</span> logit), <span class="dt">data =</span> leuk)</span>
<span id="cb3-2"><a href="logistic-regression.html#cb3-2"></a><span class="kw">summary</span>(m1)</span></code></pre></div>
<pre><code>## 
## Call:
## glm(formula = REMISS ~ ., family = binomial(link = logit), data = leuk)
## 
## Deviance Residuals: 
##      Min        1Q    Median        3Q       Max  
## -1.95404  -0.66259  -0.02516   0.78184   1.57465  
## 
## Coefficients:
##               Estimate Std. Error z value Pr(&gt;|z|)
## (Intercept)   64.25808   74.96480   0.857    0.391
## CELL          30.83006   52.13520   0.591    0.554
## SMEAR         24.68632   61.52601   0.401    0.688
## INFIL        -24.97447   65.28088  -0.383    0.702
## LI             4.36045    2.65798   1.641    0.101
## BLAST         -0.01153    2.26634  -0.005    0.996
## TEMP        -100.17340   77.75289  -1.288    0.198
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 34.372  on 26  degrees of freedom
## Residual deviance: 21.594  on 20  degrees of freedom
## AIC: 35.594
## 
## Number of Fisher Scoring iterations: 8</code></pre>
<p>“z value” is the Wald z statistic, <span class="math inline">\(z = \hat{\beta} / SE(\hat{\beta})\)</span>, which if squared is the Wald chi-squared statistic, <span class="math inline">\(z^2 = \left(\hat{\beta} / SE(\hat{\beta}) \right)^2\)</span>. The p.value is the area to the right of <span class="math inline">\(z^2\)</span> in the <span class="math inline">\(\chi_1^2\)</span> density curve.</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb5-1"><a href="logistic-regression.html#cb5-1"></a>m1 <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">tidy</span>() <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb5-2"><a href="logistic-regression.html#cb5-2"></a><span class="st">  </span><span class="kw">mutate</span>(</span>
<span id="cb5-3"><a href="logistic-regression.html#cb5-3"></a>    <span class="dt">z =</span> estimate <span class="op">/</span><span class="st"> </span>std.error, </span>
<span id="cb5-4"><a href="logistic-regression.html#cb5-4"></a>    <span class="dt">p_z2 =</span> <span class="kw">pchisq</span>(z<span class="op">^</span><span class="dv">2</span>, <span class="dt">df =</span> <span class="dv">1</span>, <span class="dt">lower.tail =</span> <span class="ot">FALSE</span>)</span>
<span id="cb5-5"><a href="logistic-regression.html#cb5-5"></a>  ) <span class="op">%&gt;%</span></span>
<span id="cb5-6"><a href="logistic-regression.html#cb5-6"></a><span class="st">  </span><span class="kw">select</span>(term, p.value, p_z2)</span></code></pre></div>
<pre><code>## # A tibble: 7 x 3
##   term        p.value  p_z2
##   &lt;chr&gt;         &lt;dbl&gt; &lt;dbl&gt;
## 1 (Intercept)   0.391 0.391
## 2 CELL          0.554 0.554
## 3 SMEAR         0.688 0.688
## 4 INFIL         0.702 0.702
## 5 LI            0.101 0.101
## 6 BLAST         0.996 0.996
## 7 TEMP          0.198 0.198</code></pre>
<p>The “dispersion parameter” refers to overdispersion, a common issues with GLM. For a logistic regression, the response variable should be distributed <span class="math inline">\(y_i \sim Bin(n_i, \pi_i)\)</span> with <span class="math inline">\(\mu_i = n_i \pi_i\)</span> and <span class="math inline">\(\sigma^2 = \pi (1 - \pi)\)</span>. Overdispersion means the data shows evidence of variance greater than <span class="math inline">\(\sigma^2\)</span>.</p>
<p>“Fisher scoring” is a method for ML estimation. Logistic regression uses an iterative procedure to fit the model, so this section indicates whether the algorithm converged.</p>
<p>The log odds of having achieved remission when each predictor equals its mean value is <span class="math inline">\(\hat{y} = -2.68\)</span>.</p>
<div class="sourceCode" id="cb7"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb7-1"><a href="logistic-regression.html#cb7-1"></a>(pred &lt;-<span class="st"> </span><span class="kw">predict</span>(m1, <span class="dt">newdata =</span> <span class="kw">data.frame</span>(<span class="kw">t</span>(<span class="kw">colMeans</span>(leuk)))))</span></code></pre></div>
<pre><code>##         1 
## -2.684382</code></pre>
<p>Log odds are not easy to interpet, but are convenient for <a href="https://www.statisticshowto.datasciencecentral.com/log-odds/">updating prior probabilities in Bayesian analyses</a>. Exponentiate the log odds to get the more intuitive <strong>odds</strong>.</p>
<p><span class="math display">\[\exp (\hat{y}) = \exp (X \hat{\beta}) = \frac{\pi}{1 - \pi}.\]</span></p>
<p>The odds of having achieved remission when each predictor equals its mean value is <span class="math inline">\(\exp(\hat{y}) = 0.068\)</span>.</p>
<div class="sourceCode" id="cb9"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb9-1"><a href="logistic-regression.html#cb9-1"></a><span class="kw">exp</span>(pred)</span></code></pre></div>
<pre><code>##          1 
## 0.06826334</code></pre>
<p>A common way to express this is with the inverse, 1 / 0.068 = 15:1. The odds of having achieved remission when each predictor equals its mean value is “15 to 1”.</p>
<div class="sourceCode" id="cb11"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb11-1"><a href="logistic-regression.html#cb11-1"></a><span class="kw">round</span>(<span class="dv">1</span><span class="op">/</span><span class="kw">exp</span>(pred), <span class="dv">0</span>)</span></code></pre></div>
<pre><code>##  1 
## 15</code></pre>
<p>Or, solve for <span class="math inline">\(\pi\)</span> to get the <strong>probability</strong>.</p>
<p><span class="math display">\[\pi = \frac{\exp (X \beta)}{1 + \exp (X \beta)}\]</span></p>
<p>The probability of having achieved remission when each predictor equals its mean value is <span class="math inline">\(\pi = 0.064\)</span>. The <code>predict()</code> function for a logistic model returns log-odds, but can also return <span class="math inline">\(\pi\)</span> by specifying parameter <code>type = "response"</code>.</p>
<div class="sourceCode" id="cb13"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb13-1"><a href="logistic-regression.html#cb13-1"></a><span class="kw">predict</span>(m1, <span class="dt">newdata =</span> <span class="kw">data.frame</span>(<span class="kw">t</span>(<span class="kw">colMeans</span>(leuk))), <span class="dt">type =</span> <span class="st">&quot;response&quot;</span>)</span></code></pre></div>
<pre><code>##          1 
## 0.06390123</code></pre>
<p>Interpret the coefficient estimates using the <strong>odds ratio</strong>, the ratio of the odds before and after an increment to the predictors. The odds ratio is how much the odds would be multiplied after a <span class="math inline">\(X_1 - X_0\)</span> unit increase in <span class="math inline">\(X\)</span>.</p>
<p><span class="math display">\[\theta = \frac{\pi / (1 - \pi) |_{X = X_1}}{\pi / (1 - \pi) |_{X = X_0}} = \frac{\exp (X_1 \hat{\beta})}{\exp (X_0 \hat{\beta})} = \exp ((X_1-X_0) \hat{\beta}) = \exp (\delta \hat{\beta})\]</span></p>
<p>Increasing LI by .01 increases the odds of remission by a factor of <span class="math inline">\(\exp(0.1 \cdot 4.36) = 1.547\)</span> (from 15:1 to 23:1).</p>
<div class="sourceCode" id="cb15"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb15-1"><a href="logistic-regression.html#cb15-1"></a><span class="kw">exp</span>(.<span class="dv">1</span> <span class="op">*</span><span class="st"> </span>m1<span class="op">$</span>coefficients) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">round</span>(<span class="dv">3</span>)</span></code></pre></div>
<pre><code>## (Intercept)        CELL       SMEAR       INFIL          LI       BLAST 
##     617.580      21.824      11.806       0.082       1.547       0.999 
##        TEMP 
##       0.000</code></pre>
<p>You can calculate an odds ratio with specified increments using <code>oddsratio::or_glm()</code>.</p>
<div class="sourceCode" id="cb17"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb17-1"><a href="logistic-regression.html#cb17-1"></a>oddsratio<span class="op">::</span><span class="kw">or_glm</span>(<span class="dt">data =</span> leuk, <span class="dt">model =</span> m1, </span>
<span id="cb17-2"><a href="logistic-regression.html#cb17-2"></a>  <span class="dt">incr =</span> <span class="kw">list</span>(</span>
<span id="cb17-3"><a href="logistic-regression.html#cb17-3"></a>    <span class="dt">CELL =</span> <span class="fl">0.01</span>, <span class="dt">SMEAR =</span> <span class="fl">0.01</span>, <span class="dt">INFIL =</span> <span class="fl">0.05</span>, <span class="dt">LI =</span> <span class="fl">0.1</span>, <span class="dt">BLAST =</span> <span class="fl">1.0</span>, <span class="dt">TEMP =</span> <span class="fl">0.03</span></span>
<span id="cb17-4"><a href="logistic-regression.html#cb17-4"></a>  )</span>
<span id="cb17-5"><a href="logistic-regression.html#cb17-5"></a>)</span></code></pre></div>
<pre><code>## # A tibble: 6 x 5
##   predictor oddsratio `CI_low (2.5)` `CI_high (97.5)` increment
##   &lt;chr&gt;         &lt;dbl&gt;          &lt;dbl&gt;            &lt;dbl&gt; &lt;chr&gt;    
## 1 CELL          1.36           0.747             4.64 0.01     
## 2 SMEAR         1.28           0.537             5.15 0.01     
## 3 INFIL         0.287          0                33.1  0.05     
## 4 LI            1.55           1.04              2.99 0.1      
## 5 BLAST         0.989          0.009            91.0  1        
## 6 TEMP          0.05           0                 2.02 0.03</code></pre>
<p>The predicted values can also be expressed as the probabilities <span class="math inline">\(\pi\)</span>. This produces the familiar signmoidal shape of the binary relationship.</p>
<div class="sourceCode" id="cb19"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb19-1"><a href="logistic-regression.html#cb19-1"></a><span class="kw">augment</span>(m1, <span class="dt">type.predict =</span> <span class="st">&quot;response&quot;</span>) <span class="op">%&gt;%</span></span>
<span id="cb19-2"><a href="logistic-regression.html#cb19-2"></a><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> LI)) <span class="op">+</span></span>
<span id="cb19-3"><a href="logistic-regression.html#cb19-3"></a><span class="st">  </span><span class="kw">geom_point</span>(<span class="kw">aes</span>(<span class="dt">y =</span> REMISS)) <span class="op">+</span></span>
<span id="cb19-4"><a href="logistic-regression.html#cb19-4"></a><span class="st">  </span><span class="kw">geom_line</span>(<span class="kw">aes</span>(<span class="dt">y =</span> .fitted)) <span class="op">+</span></span>
<span id="cb19-5"><a href="logistic-regression.html#cb19-5"></a><span class="st">  </span><span class="kw">theme_mf</span>() <span class="op">+</span></span>
<span id="cb19-6"><a href="logistic-regression.html#cb19-6"></a><span class="st">  </span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="st">&quot;LI&quot;</span>,</span>
<span id="cb19-7"><a href="logistic-regression.html#cb19-7"></a>       <span class="dt">y =</span> <span class="st">&quot;Probability of REMISS&quot;</span>,</span>
<span id="cb19-8"><a href="logistic-regression.html#cb19-8"></a>       <span class="dt">title =</span> <span class="st">&quot;Binary Fitted Line Plot&quot;</span>)</span></code></pre></div>
<p><img src="data-sci_files/figure-html/unnamed-chunk-12-1.png" width="672" /></p>
<p>Evaluate a logistic model fit with an analysis of deviance. Deviance is defined as -2 times the log-likelihood <span class="math inline">\(-2l(\beta)\)</span>. The null deviance is the deviance of the null model and is analagous to SST in ANOVA. The residual deviance is the deviance of the full model and is analagous to SSE in ANOVA.</p>
<div class="sourceCode" id="cb20"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb20-1"><a href="logistic-regression.html#cb20-1"></a><span class="kw">logLik</span>(<span class="kw">glm</span>(REMISS <span class="op">~</span><span class="st"> </span>., <span class="dt">data =</span> leuk, <span class="dt">family =</span> <span class="st">&quot;binomial&quot;</span>)) <span class="op">*</span><span class="st"> </span>(<span class="op">-</span><span class="dv">2</span>)</span></code></pre></div>
<pre><code>## &#39;log Lik.&#39; 21.59385 (df=7)</code></pre>
<p><code>anova()</code> computes the analysis of deviance table for the model.</p>
<div class="sourceCode" id="cb22"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb22-1"><a href="logistic-regression.html#cb22-1"></a><span class="kw">anova</span>(m1)</span></code></pre></div>
<pre><code>## Analysis of Deviance Table
## 
## Model: binomial, link: logit
## 
## Response: REMISS
## 
## Terms added sequentially (first to last)
## 
## 
##       Df Deviance Resid. Df Resid. Dev
## NULL                     26     34.372
## CELL   1   2.5800        25     31.792
## SMEAR  1   0.5188        24     31.273
## INFIL  1   0.2927        23     30.980
## LI     1   6.7818        22     24.199
## BLAST  1   0.3271        21     23.871
## TEMP   1   2.2775        20     21.594</code></pre>
<p>The deviance of the null model (no regressors) is 34.372. The deviance of the full model is 21.594. <code>glance()</code> also returns the null and residual deviances.</p>
<div class="sourceCode" id="cb24"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb24-1"><a href="logistic-regression.html#cb24-1"></a><span class="kw">glance</span>(m1)</span></code></pre></div>
<pre><code>## # A tibble: 1 x 7
##   null.deviance df.null logLik   AIC   BIC deviance df.residual
##           &lt;dbl&gt;   &lt;int&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;       &lt;int&gt;
## 1          34.4      26  -10.8  35.6  44.7     21.6          20</code></pre>
<p>Use the <code>GainCurvePlot()</code> function to plot the gain curve (background on gain curve at <a href="https://www.datasciencecentral.com/profiles/blogs/understanding-and-interpreting-gain-and-lift-charts">Data Science Central</a> from the model predictions. The x-axis is the fraction of items seen when sorted by the predicted value, and the y-axis is the cumulative summed true outcome. The “wizard” curve is the gain curve when the data is sorted by the true outcome. If the model’s gain curve is close to the wizard gain curve, then the model sorted the response variable well. The grey area is the gain over a random sorting.</p>
<div class="sourceCode" id="cb26"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb26-1"><a href="logistic-regression.html#cb26-1"></a><span class="kw">augment</span>(m1) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">data.frame</span>() <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb26-2"><a href="logistic-regression.html#cb26-2"></a><span class="st">  </span><span class="kw">GainCurvePlot</span>(<span class="dt">xvar =</span> <span class="st">&quot;.fitted&quot;</span>, <span class="dt">truthVar =</span> <span class="st">&quot;REMISS&quot;</span>, <span class="dt">title =</span> <span class="st">&quot;Logistic Model&quot;</span>)</span></code></pre></div>
<p><img src="data-sci_files/figure-html/unnamed-chunk-16-1.png" width="672" /></p>
<p><code>REMISS</code> equals 1 in 9 of the 27 responses.</p>
<ul>
<li>The wizard curve shows that after sorting the responses it encounters all 9 1s (100%) after looking at 9 of the 27 response (33%).<br />
</li>
<li>The bottom of the grey diagonal shows that after making random predictions and sorting the predictions, it encounters only 3 1s (33%) after looking at 9 of the 27 responses (33%). It has to look at all 27 responses (100%) to encounter all 9 1s (100%).<br />
</li>
<li>The gain curve encounters 5 1s (55%) after looking at 9 of the 27 responses (33%). It has to look at 14 responses to encounter all 9 1s (100%).</li>
</ul>
<p>Another way to evaluate the predictive model is the ROC curve. It evaluates all possible thresholds for splitting predicted probabilities into predicted classes. This is often a much more useful metric than simply ranking models by their accuracy at a set threshold, as different models might require different calibration steps (looking at a confusion matrix at each step) to find the optimal classification threshold for that model.</p>
<div class="sourceCode" id="cb27"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb27-1"><a href="logistic-regression.html#cb27-1"></a><span class="kw">library</span>(caTools)</span></code></pre></div>
<pre><code>## Warning: package &#39;caTools&#39; was built under R version 3.6.2</code></pre>
<div class="sourceCode" id="cb29"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb29-1"><a href="logistic-regression.html#cb29-1"></a><span class="kw">colAUC</span>(m1<span class="op">$</span>fitted.values, m1<span class="op">$</span>data<span class="op">$</span>REMISS, <span class="dt">plotROC =</span> <span class="ot">TRUE</span>)</span></code></pre></div>
<p><img src="data-sci_files/figure-html/unnamed-chunk-17-1.png" width="672" /></p>
<pre><code>##              [,1]
## 0 vs. 1 0.8950617</code></pre>
<div id="case-study" class="section level3">
<h3><span class="header-section-number">7.1.1</span> Case Study</h3>
<p>This case study is from <a href="https://online.stat.psu.edu/stat504/node/197/">PSU STAT 504</a>. This study investigated the gender differences in <a href="https://online.stat.psu.edu/stat504/node/197/">Piaget’s water level test</a>. 166 subjects performed the test and other tests of knowledge and spatial ability.</p>
<p>Here are the pass/fail results of the study by sex.</p>
<div class="sourceCode" id="cb31"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb31-1"><a href="logistic-regression.html#cb31-1"></a><span class="kw">prop.table</span>(<span class="kw">table</span>(h2o<span class="op">$</span>sex, h2o<span class="op">$</span>y), <span class="dt">margin =</span> <span class="dv">1</span>) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">round</span>(<span class="dt">digits =</span> <span class="dv">4</span>)</span></code></pre></div>
<pre><code>##    
##       fail   pass
##   M 0.3559 0.6441
##   F 0.7009 0.2991</code></pre>
<p>The pass rates are very different. The Pearson Chi-squared test of equality of two proportions calculates a Chi-Square value of 18.562, p-value &lt; 0.0001, so reject the hypothesis that the pass rates are the same.</p>
<div class="sourceCode" id="cb33"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb33-1"><a href="logistic-regression.html#cb33-1"></a><span class="kw">chisq.test</span>(<span class="kw">table</span>(h2o<span class="op">$</span>sex, h2o<span class="op">$</span>y), <span class="dt">correct =</span> <span class="ot">FALSE</span>)</span></code></pre></div>
<pre><code>## 
##  Pearson&#39;s Chi-squared test
## 
## data:  table(h2o$sex, h2o$y)
## X-squared = 18.562, df = 1, p-value = 1.645e-05</code></pre>
<p>Fit a logistic regression.</p>
<div class="sourceCode" id="cb35"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb35-1"><a href="logistic-regression.html#cb35-1"></a>m &lt;-<span class="st"> </span><span class="kw">glm</span>(y <span class="op">~</span><span class="st"> </span>sex, <span class="dt">data =</span> h2o, <span class="dt">family =</span> <span class="kw">binomial</span>(<span class="dt">link =</span> logit))</span>
<span id="cb35-2"><a href="logistic-regression.html#cb35-2"></a><span class="kw">anova</span>(m)</span></code></pre></div>
<pre><code>## Analysis of Deviance Table
## 
## Model: binomial, link: logit
## 
## Response: y
## 
## Terms added sequentially (first to last)
## 
## 
##      Df Deviance Resid. Df Resid. Dev
## NULL                   165     226.04
## sex   1   18.658       164     207.38</code></pre>
<p>The likelihood ratio is <span class="math inline">\(G^2 = 18.658\)</span>, so reject the null hypothesis of no sex effect - there is statistically significant difference in pass rates. Here are the coefficient estimators.</p>
<div class="sourceCode" id="cb37"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb37-1"><a href="logistic-regression.html#cb37-1"></a><span class="kw">tidy</span>(m)</span></code></pre></div>
<pre><code>## # A tibble: 2 x 5
##   term        estimate std.error statistic   p.value
##   &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;
## 1 (Intercept)    0.593     0.272      2.18 0.0292   
## 2 sexF          -1.44      0.344     -4.20 0.0000271</code></pre>
<p>The odds ratio (females vs males) is</p>
<div class="sourceCode" id="cb39"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb39-1"><a href="logistic-regression.html#cb39-1"></a><span class="kw">exp</span>(<span class="kw">tidy</span>(m)[<span class="dv">2</span>, ]<span class="op">$</span>estimate)</span></code></pre></div>
<pre><code>## [1] 0.2357895</code></pre>
<p>meaning the odds of a female passing are 0.24 times that of a male. Or take the inverse to get the male vs female odds ratio,</p>
<div class="sourceCode" id="cb41"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb41-1"><a href="logistic-regression.html#cb41-1"></a><span class="dv">1</span> <span class="op">/</span><span class="st"> </span><span class="kw">exp</span>(<span class="kw">tidy</span>(m)[<span class="dv">2</span>, ]<span class="op">$</span>estimate)</span></code></pre></div>
<pre><code>## [1] 4.241071</code></pre>
<p>meaning the odds of a male passing are 4.24 times that of a female. <code>oddsratio::or_glm()</code> calculates the odds ratio from an increment in the predictor values, in this case, incrementing sex from male to female.</p>
<div class="sourceCode" id="cb43"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb43-1"><a href="logistic-regression.html#cb43-1"></a>oddsratio<span class="op">::</span><span class="kw">or_glm</span>(h2o, m, <span class="dv">1</span>)</span></code></pre></div>
<pre><code>## # A tibble: 1 x 5
##   predictor oddsratio `CI_low (2.5)` `CI_high (97.5)` increment         
##   &lt;chr&gt;         &lt;dbl&gt;          &lt;dbl&gt;            &lt;dbl&gt; &lt;chr&gt;             
## 1 sexF          0.236          0.118            0.458 Indicator variable</code></pre>
<p>What if we control for the results of the gravity test (gravity = number of correct answers on test)? Here is a logistic regression of pass ~ gravity.</p>
<div class="sourceCode" id="cb45"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb45-1"><a href="logistic-regression.html#cb45-1"></a>m &lt;-<span class="st"> </span><span class="kw">glm</span>(y <span class="op">~</span><span class="st"> </span>gravity, <span class="dt">data =</span> h2o, <span class="dt">family =</span> <span class="kw">binomial</span>(<span class="dt">link =</span> logit))</span>
<span id="cb45-2"><a href="logistic-regression.html#cb45-2"></a><span class="kw">anova</span>(m)</span></code></pre></div>
<pre><code>## Analysis of Deviance Table
## 
## Model: binomial, link: logit
## 
## Response: y
## 
## Terms added sequentially (first to last)
## 
## 
##         Df Deviance Resid. Df Resid. Dev
## NULL                      165     226.04
## gravity  1   42.176       164     183.86</code></pre>
<p>The likelihood ratio is <span class="math inline">\(G^2 = 42.2\)</span>, so reject H0 that there is no gravity effect - there is a statistically significant difference between the gravity score and the pass rate. The odds of passing the water level task increase by 2.225 for each additional right answer on gravity.</p>
<div class="sourceCode" id="cb47"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb47-1"><a href="logistic-regression.html#cb47-1"></a>oddsratio<span class="op">::</span><span class="kw">or_glm</span>(h2o, m, <span class="dt">incr =</span> <span class="kw">list</span>(<span class="dt">gravity =</span> <span class="dv">1</span>))</span></code></pre></div>
<pre><code>## # A tibble: 1 x 5
##   predictor oddsratio `CI_low (2.5)` `CI_high (97.5)` increment
##   &lt;chr&gt;         &lt;dbl&gt;          &lt;dbl&gt;            &lt;dbl&gt; &lt;chr&gt;    
## 1 gravity        2.22           1.71                3 1</code></pre>
<div class="sourceCode" id="cb49"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb49-1"><a href="logistic-regression.html#cb49-1"></a><span class="kw">augment</span>(m) <span class="op">%&gt;%</span></span>
<span id="cb49-2"><a href="logistic-regression.html#cb49-2"></a><span class="st">  </span><span class="kw">group_by</span>(gravity) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb49-3"><a href="logistic-regression.html#cb49-3"></a><span class="st">  </span><span class="kw">summarize</span>(</span>
<span id="cb49-4"><a href="logistic-regression.html#cb49-4"></a>    <span class="dt">observed =</span> <span class="kw">mean</span>(<span class="kw">as.numeric</span>(y) <span class="op">-</span><span class="st"> </span><span class="dv">1</span>),</span>
<span id="cb49-5"><a href="logistic-regression.html#cb49-5"></a>    <span class="dt">fitted =</span> <span class="kw">mean</span>(<span class="kw">exp</span>(.fitted) <span class="op">/</span><span class="st"> </span>(<span class="dv">1</span> <span class="op">+</span><span class="st"> </span><span class="kw">exp</span>(.fitted)))</span>
<span id="cb49-6"><a href="logistic-regression.html#cb49-6"></a>  ) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb49-7"><a href="logistic-regression.html#cb49-7"></a><span class="st">  </span><span class="kw">pivot_longer</span>(<span class="dt">cols =</span> <span class="op">-</span>gravity, <span class="dt">names_to =</span> <span class="st">&quot;model&quot;</span>, <span class="dt">values_to =</span> <span class="st">&quot;rate&quot;</span>) <span class="op">%&gt;%</span></span>
<span id="cb49-8"><a href="logistic-regression.html#cb49-8"></a><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> gravity, <span class="dt">y =</span> rate, <span class="dt">color =</span> model)) <span class="op">+</span></span>
<span id="cb49-9"><a href="logistic-regression.html#cb49-9"></a><span class="st">  </span><span class="kw">geom_point</span>() <span class="op">+</span></span>
<span id="cb49-10"><a href="logistic-regression.html#cb49-10"></a><span class="st">  </span><span class="kw">scale_color_mf</span>() <span class="op">+</span></span>
<span id="cb49-11"><a href="logistic-regression.html#cb49-11"></a><span class="st">  </span><span class="kw">theme_mf</span>() <span class="op">+</span></span>
<span id="cb49-12"><a href="logistic-regression.html#cb49-12"></a><span class="st">  </span><span class="kw">labs</span>(<span class="dt">title =</span> <span class="st">&quot;Water Test Pass Rate&quot;</span>, <span class="dt">color =</span> <span class="st">&quot;&quot;</span>)</span></code></pre></div>
<p><img src="data-sci_files/figure-html/unnamed-chunk-27-1.png" width="480" /></p>
<p>You can model sex and gravity with and without interaction effects. Here is the model without interaction effects. <span class="math inline">\(G^2 = 32.3\)</span> so</p>
<div class="sourceCode" id="cb50"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb50-1"><a href="logistic-regression.html#cb50-1"></a>m &lt;-<span class="st"> </span><span class="kw">glm</span>(y <span class="op">~</span><span class="st"> </span>sex <span class="op">+</span><span class="st"> </span>gravity, <span class="dt">data =</span> h2o, <span class="dt">family =</span> <span class="kw">binomial</span>(<span class="dt">link =</span> <span class="st">&quot;logit&quot;</span>))</span>
<span id="cb50-2"><a href="logistic-regression.html#cb50-2"></a><span class="kw">anova</span>(m)</span></code></pre></div>
<pre><code>## Analysis of Deviance Table
## 
## Model: binomial, link: logit
## 
## Response: y
## 
## Terms added sequentially (first to last)
## 
## 
##         Df Deviance Resid. Df Resid. Dev
## NULL                      165     226.04
## sex      1   18.658       164     207.38
## gravity  1   32.319       163     175.06</code></pre>
<div class="sourceCode" id="cb52"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb52-1"><a href="logistic-regression.html#cb52-1"></a><span class="kw">tidy</span>(m)</span></code></pre></div>
<pre><code>## # A tibble: 3 x 5
##   term        estimate std.error statistic     p.value
##   &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;       &lt;dbl&gt;
## 1 (Intercept)   -1.92      0.574     -3.35 0.000810   
## 2 sexF          -1.12      0.382     -2.93 0.00334    
## 3 gravity        0.740     0.147      5.05 0.000000443</code></pre>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="generalized-linear-models.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="multinomial-logistic-regression.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="assets/gitbook-2.6.7/js/app.min.js"></script>
<script src="assets/gitbook-2.6.7/js/lunr.js"></script>
<script src="assets/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="assets/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="assets/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="assets/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="assets/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="assets/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="assets/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["data-sci.pdf", "data-sci.epub"],
"toc": {
"collapse": "subsection"
},
"toolbar": {
"position": "static"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
