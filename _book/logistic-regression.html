<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>5.1 Logistic Regression | My Data Science Notes</title>
  <meta name="description" content="This is a compendium of notes from classes, tutorials, etc. that I reference from time to time." />
  <meta name="generator" content="bookdown 0.20 and GitBook 2.6.7" />

  <meta property="og:title" content="5.1 Logistic Regression | My Data Science Notes" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="This is a compendium of notes from classes, tutorials, etc. that I reference from time to time." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="5.1 Logistic Regression | My Data Science Notes" />
  
  <meta name="twitter:description" content="This is a compendium of notes from classes, tutorials, etc. that I reference from time to time." />
  

<meta name="author" content="Michael Foley" />


<meta name="date" content="2020-07-26" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="generalized-linear-models.html"/>
<link rel="next" href="multinomial-logistic-regression.html"/>
<script src="assets/jquery-2.2.3/jquery.min.js"></script>
<link href="assets/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="assets/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="assets/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="assets/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="assets/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="assets/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="assets/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<script src="assets/accessible-code-block-0.0.1/empty-anchor.js"></script>
<link href="assets/tabwid-1.0.0/tabwid.css" rel="stylesheet" />
<script src="assets/tabwid-1.0.0/tabwid.js"></script>
<script src="assets/htmlwidgets-1.5.1/htmlwidgets.js"></script>
<script src="assets/plotly-binding-4.9.2.1/plotly.js"></script>
<script src="assets/typedarray-0.1/typedarray.min.js"></script>
<link href="assets/crosstalk-1.1.0.1/css/crosstalk.css" rel="stylesheet" />
<script src="assets/crosstalk-1.1.0.1/js/crosstalk.min.js"></script>
<link href="assets/plotly-htmlwidgets-css-1.52.2/plotly-htmlwidgets.css" rel="stylesheet" />
<script src="assets/plotly-main-1.52.2/plotly-latest.min.js"></script>


<style type="text/css">
code.sourceCode > span { display: inline-block; line-height: 1.25; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">My Data Science Notes</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Intro</a></li>
<li class="chapter" data-level="1" data-path="probability.html"><a href="probability.html"><i class="fa fa-check"></i><b>1</b> Probability</a><ul>
<li class="chapter" data-level="1.1" data-path="principles.html"><a href="principles.html"><i class="fa fa-check"></i><b>1.1</b> Principles</a></li>
<li class="chapter" data-level="1.2" data-path="disc-dist.html"><a href="disc-dist.html"><i class="fa fa-check"></i><b>1.2</b> Discrete Distributions</a><ul>
<li class="chapter" data-level="1.2.1" data-path="disc-dist.html"><a href="disc-dist.html#bernoulli"><i class="fa fa-check"></i><b>1.2.1</b> Bernoulli</a></li>
<li class="chapter" data-level="1.2.2" data-path="disc-dist.html"><a href="disc-dist.html#binomial"><i class="fa fa-check"></i><b>1.2.2</b> Binomial</a></li>
<li class="chapter" data-level="1.2.3" data-path="disc-dist.html"><a href="disc-dist.html#poission"><i class="fa fa-check"></i><b>1.2.3</b> Poission</a></li>
<li class="chapter" data-level="1.2.4" data-path="disc-dist.html"><a href="disc-dist.html#multinomial"><i class="fa fa-check"></i><b>1.2.4</b> Multinomial</a></li>
<li class="chapter" data-level="1.2.5" data-path="disc-dist.html"><a href="disc-dist.html#negative-binomial"><i class="fa fa-check"></i><b>1.2.5</b> Negative-Binomial</a></li>
<li class="chapter" data-level="1.2.6" data-path="disc-dist.html"><a href="disc-dist.html#geometric"><i class="fa fa-check"></i><b>1.2.6</b> Geometric</a></li>
<li class="chapter" data-level="1.2.7" data-path="disc-dist.html"><a href="disc-dist.html#hypergeometric"><i class="fa fa-check"></i><b>1.2.7</b> Hypergeometric</a></li>
<li class="chapter" data-level="1.2.8" data-path="disc-dist.html"><a href="disc-dist.html#gamma"><i class="fa fa-check"></i><b>1.2.8</b> Gamma</a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="cont-dist.html"><a href="cont-dist.html"><i class="fa fa-check"></i><b>1.3</b> Continuous Distributions</a><ul>
<li class="chapter" data-level="1.3.1" data-path="cont-dist.html"><a href="cont-dist.html#normal"><i class="fa fa-check"></i><b>1.3.1</b> Normal</a></li>
</ul></li>
<li class="chapter" data-level="1.4" data-path="join-distributions.html"><a href="join-distributions.html"><i class="fa fa-check"></i><b>1.4</b> Join Distributions</a></li>
<li class="chapter" data-level="1.5" data-path="likelihood.html"><a href="likelihood.html"><i class="fa fa-check"></i><b>1.5</b> Likelihood</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="statistical-tests.html"><a href="statistical-tests.html"><i class="fa fa-check"></i><b>2</b> Statistical Tests</a><ul>
<li class="chapter" data-level="2.1" data-path="chi-square-test.html"><a href="chi-square-test.html"><i class="fa fa-check"></i><b>2.1</b> Chi-Square Test</a></li>
<li class="chapter" data-level="2.2" data-path="one-way-tables.html"><a href="one-way-tables.html"><i class="fa fa-check"></i><b>2.2</b> One-Way Tables</a><ul>
<li class="chapter" data-level="2.2.1" data-path="one-way-tables.html"><a href="one-way-tables.html#chi-square-goodness-of-fit-test"><i class="fa fa-check"></i><b>2.2.1</b> Chi-Square Goodness-of-Fit Test</a></li>
<li class="chapter" data-level="2.2.2" data-path="one-way-tables.html"><a href="one-way-tables.html#proportion-test"><i class="fa fa-check"></i><b>2.2.2</b> Proportion Test</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="two-way-tables.html"><a href="two-way-tables.html"><i class="fa fa-check"></i><b>2.3</b> Two-Way Tables</a><ul>
<li class="chapter" data-level="2.3.1" data-path="two-way-tables.html"><a href="two-way-tables.html#chi-square-independence-test"><i class="fa fa-check"></i><b>2.3.1</b> Chi-Square Independence Test</a></li>
<li class="chapter" data-level="2.3.2" data-path="two-way-tables.html"><a href="two-way-tables.html#residuals-analysis"><i class="fa fa-check"></i><b>2.3.2</b> Residuals Analysis</a></li>
<li class="chapter" data-level="2.3.3" data-path="two-way-tables.html"><a href="two-way-tables.html#difference-in-proportions"><i class="fa fa-check"></i><b>2.3.3</b> Difference in Proportions</a></li>
<li class="chapter" data-level="2.3.4" data-path="two-way-tables.html"><a href="two-way-tables.html#relative-risk"><i class="fa fa-check"></i><b>2.3.4</b> Relative Risk</a></li>
<li class="chapter" data-level="2.3.5" data-path="two-way-tables.html"><a href="two-way-tables.html#odds-ratio"><i class="fa fa-check"></i><b>2.3.5</b> Odds Ratio</a></li>
<li class="chapter" data-level="2.3.6" data-path="two-way-tables.html"><a href="two-way-tables.html#partitioning-chi-square"><i class="fa fa-check"></i><b>2.3.6</b> Partitioning Chi-Square</a></li>
<li class="chapter" data-level="2.3.7" data-path="two-way-tables.html"><a href="two-way-tables.html#correlation"><i class="fa fa-check"></i><b>2.3.7</b> Correlation</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="k-way-tables.html"><a href="k-way-tables.html"><i class="fa fa-check"></i><b>2.4</b> K-Way Tables</a><ul>
<li class="chapter" data-level="2.4.1" data-path="k-way-tables.html"><a href="k-way-tables.html#odds-ratio-1"><i class="fa fa-check"></i><b>2.4.1</b> Odds Ratio</a></li>
<li class="chapter" data-level="2.4.2" data-path="k-way-tables.html"><a href="k-way-tables.html#chi-square-independence-test-1"><i class="fa fa-check"></i><b>2.4.2</b> Chi-Square Independence Test</a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="continuous-analysis.html"><a href="continuous-analysis.html"><i class="fa fa-check"></i><b>2.5</b> Continuous Variable Analysis</a><ul>
<li class="chapter" data-level="2.5.1" data-path="continuous-analysis.html"><a href="continuous-analysis.html#correlation-1"><i class="fa fa-check"></i><b>2.5.1</b> Correlation</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="experiment-design.html"><a href="experiment-design.html"><i class="fa fa-check"></i><b>3</b> Experiment Design</a><ul>
<li class="chapter" data-level="3.1" data-path="single-factor.html"><a href="single-factor.html"><i class="fa fa-check"></i><b>3.1</b> Single Factor</a></li>
<li class="chapter" data-level="3.2" data-path="blocking.html"><a href="blocking.html"><i class="fa fa-check"></i><b>3.2</b> Blocking</a></li>
<li class="chapter" data-level="3.3" data-path="nested.html"><a href="nested.html"><i class="fa fa-check"></i><b>3.3</b> Nested</a></li>
<li class="chapter" data-level="3.4" data-path="split-plot.html"><a href="split-plot.html"><i class="fa fa-check"></i><b>3.4</b> Split Plot</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="part-2-supervised-machine-learning.html"><a href="part-2-supervised-machine-learning.html"><i class="fa fa-check"></i>PART 2: Supervised Machine Learning</a></li>
<li class="chapter" data-level="4" data-path="ordinary-least-squares.html"><a href="ordinary-least-squares.html"><i class="fa fa-check"></i><b>4</b> Ordinary Least Squares</a><ul>
<li class="chapter" data-level="4.1" data-path="linear-regression-model.html"><a href="linear-regression-model.html"><i class="fa fa-check"></i><b>4.1</b> Linear Regression Model</a></li>
<li class="chapter" data-level="4.2" data-path="parameter-estimation.html"><a href="parameter-estimation.html"><i class="fa fa-check"></i><b>4.2</b> Parameter Estimation</a></li>
<li class="chapter" data-level="4.3" data-path="model-assumptions.html"><a href="model-assumptions.html"><i class="fa fa-check"></i><b>4.3</b> Model Assumptions</a><ul>
<li class="chapter" data-level="4.3.1" data-path="model-assumptions.html"><a href="model-assumptions.html#linearity"><i class="fa fa-check"></i><b>4.3.1</b> Linearity</a></li>
<li class="chapter" data-level="4.3.2" data-path="model-assumptions.html"><a href="model-assumptions.html#multicollinearity"><i class="fa fa-check"></i><b>4.3.2</b> Multicollinearity</a></li>
<li class="chapter" data-level="4.3.3" data-path="model-assumptions.html"><a href="model-assumptions.html#normality"><i class="fa fa-check"></i><b>4.3.3</b> Normality</a></li>
<li class="chapter" data-level="4.3.4" data-path="model-assumptions.html"><a href="model-assumptions.html#equal-variances"><i class="fa fa-check"></i><b>4.3.4</b> Equal Variances</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="prediction.html"><a href="prediction.html"><i class="fa fa-check"></i><b>4.4</b> Prediction</a></li>
<li class="chapter" data-level="4.5" data-path="inference.html"><a href="inference.html"><i class="fa fa-check"></i><b>4.5</b> Inference</a><ul>
<li class="chapter" data-level="4.5.1" data-path="inference.html"><a href="inference.html#t-test"><i class="fa fa-check"></i><b>4.5.1</b> <em>t</em>-Test</a></li>
<li class="chapter" data-level="4.5.2" data-path="inference.html"><a href="inference.html#f-test"><i class="fa fa-check"></i><b>4.5.2</b> <em>F</em>-Test</a></li>
</ul></li>
<li class="chapter" data-level="4.6" data-path="interpretation.html"><a href="interpretation.html"><i class="fa fa-check"></i><b>4.6</b> Interpretation</a></li>
<li class="chapter" data-level="4.7" data-path="model-validation.html"><a href="model-validation.html"><i class="fa fa-check"></i><b>4.7</b> Model Validation</a><ul>
<li class="chapter" data-level="4.7.1" data-path="model-validation.html"><a href="model-validation.html#accuracy-metrics"><i class="fa fa-check"></i><b>4.7.1</b> Accuracy Metrics</a></li>
<li class="chapter" data-level="4.7.2" data-path="model-validation.html"><a href="model-validation.html#cross-validation"><i class="fa fa-check"></i><b>4.7.2</b> Cross-Validation</a></li>
<li class="chapter" data-level="4.7.3" data-path="model-validation.html"><a href="model-validation.html#gain-curve"><i class="fa fa-check"></i><b>4.7.3</b> Gain Curve</a></li>
</ul></li>
<li class="chapter" data-level="4.8" data-path="ols-reference.html"><a href="ols-reference.html"><i class="fa fa-check"></i><b>4.8</b> OLS Reference</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="generalized-linear-models.html"><a href="generalized-linear-models.html"><i class="fa fa-check"></i><b>5</b> Generalized Linear Models</a><ul>
<li class="chapter" data-level="5.1" data-path="logistic-regression.html"><a href="logistic-regression.html"><i class="fa fa-check"></i><b>5.1</b> Logistic Regression</a></li>
<li class="chapter" data-level="5.2" data-path="multinomial-logistic-regression.html"><a href="multinomial-logistic-regression.html"><i class="fa fa-check"></i><b>5.2</b> Multinomial Logistic Regression</a></li>
<li class="chapter" data-level="5.3" data-path="ordinal-logistic-regression.html"><a href="ordinal-logistic-regression.html"><i class="fa fa-check"></i><b>5.3</b> Ordinal Logistic Regression</a><ul>
<li class="chapter" data-level="5.3.1" data-path="ordinal-logistic-regression.html"><a href="ordinal-logistic-regression.html#assumptions"><i class="fa fa-check"></i><b>5.3.1</b> Assumptions</a></li>
<li class="chapter" data-level="5.3.2" data-path="ordinal-logistic-regression.html"><a href="ordinal-logistic-regression.html#modeling"><i class="fa fa-check"></i><b>5.3.2</b> Modeling</a></li>
<li class="chapter" data-level="5.3.3" data-path="ordinal-logistic-regression.html"><a href="ordinal-logistic-regression.html#case-study"><i class="fa fa-check"></i><b>5.3.3</b> Case Study</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="poisson-regression.html"><a href="poisson-regression.html"><i class="fa fa-check"></i><b>5.4</b> Poisson Regression</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="multivariate-statistical-analysis.html"><a href="multivariate-statistical-analysis.html"><i class="fa fa-check"></i><b>6</b> Multivariate Statistical Analysis</a><ul>
<li class="chapter" data-level="6.1" data-path="background.html"><a href="background.html"><i class="fa fa-check"></i><b>6.1</b> Background</a></li>
<li class="chapter" data-level="6.2" data-path="manova.html"><a href="manova.html"><i class="fa fa-check"></i><b>6.2</b> MANOVA</a></li>
<li class="chapter" data-level="6.3" data-path="repeated-measures.html"><a href="repeated-measures.html"><i class="fa fa-check"></i><b>6.3</b> Repeated Measures</a></li>
<li class="chapter" data-level="6.4" data-path="lda.html"><a href="lda.html"><i class="fa fa-check"></i><b>6.4</b> LDA</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="regularization.html"><a href="regularization.html"><i class="fa fa-check"></i><b>7</b> Regularization</a><ul>
<li class="chapter" data-level="7.1" data-path="ridge.html"><a href="ridge.html"><i class="fa fa-check"></i><b>7.1</b> Ridge</a></li>
<li class="chapter" data-level="7.2" data-path="lasso.html"><a href="lasso.html"><i class="fa fa-check"></i><b>7.2</b> Lasso</a></li>
<li class="chapter" data-level="7.3" data-path="elastic-net.html"><a href="elastic-net.html"><i class="fa fa-check"></i><b>7.3</b> Elastic Net</a></li>
<li class="chapter" data-level="" data-path="model-summary.html"><a href="model-summary.html"><i class="fa fa-check"></i>Model Summary</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="decision-trees.html"><a href="decision-trees.html"><i class="fa fa-check"></i><b>8</b> Decision Trees</a><ul>
<li class="chapter" data-level="8.1" data-path="classification-tree.html"><a href="classification-tree.html"><i class="fa fa-check"></i><b>8.1</b> Classification Tree</a><ul>
<li class="chapter" data-level="8.1.1" data-path="classification-tree.html"><a href="classification-tree.html#measuring-performance"><i class="fa fa-check"></i><b>8.1.1</b> Measuring Performance</a></li>
<li class="chapter" data-level="8.1.2" data-path="classification-tree.html"><a href="classification-tree.html#training-with-caret"><i class="fa fa-check"></i><b>8.1.2</b> Training with Caret</a></li>
</ul></li>
<li class="chapter" data-level="8.2" data-path="regression-tree.html"><a href="regression-tree.html"><i class="fa fa-check"></i><b>8.2</b> Regression Tree</a><ul>
<li class="chapter" data-level="8.2.1" data-path="regression-tree.html"><a href="regression-tree.html#training-with-caret-1"><i class="fa fa-check"></i><b>8.2.1</b> Training with Caret</a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="bagged-trees.html"><a href="bagged-trees.html"><i class="fa fa-check"></i><b>8.3</b> Bagged Trees</a><ul>
<li class="chapter" data-level="8.3.1" data-path="bagged-trees.html"><a href="bagged-trees.html#bagged-classification-tree"><i class="fa fa-check"></i><b>8.3.1</b> Bagged Classification Tree</a></li>
<li class="chapter" data-level="8.3.2" data-path="bagged-trees.html"><a href="bagged-trees.html#bagging-regression-tree"><i class="fa fa-check"></i><b>8.3.2</b> Bagging Regression Tree</a></li>
</ul></li>
<li class="chapter" data-level="8.4" data-path="random-forests.html"><a href="random-forests.html"><i class="fa fa-check"></i><b>8.4</b> Random Forests</a></li>
<li class="chapter" data-level="8.5" data-path="gradient-boosting.html"><a href="gradient-boosting.html"><i class="fa fa-check"></i><b>8.5</b> Gradient Boosting</a></li>
<li class="chapter" data-level="8.6" data-path="summary.html"><a href="summary.html"><i class="fa fa-check"></i><b>8.6</b> Summary</a><ul>
<li class="chapter" data-level="8.6.1" data-path="summary.html"><a href="summary.html#classification-trees"><i class="fa fa-check"></i><b>8.6.1</b> Classification Trees</a></li>
<li class="chapter" data-level="8.6.2" data-path="summary.html"><a href="summary.html#regression-trees"><i class="fa fa-check"></i><b>8.6.2</b> Regression Trees</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="9" data-path="non-linear-models.html"><a href="non-linear-models.html"><i class="fa fa-check"></i><b>9</b> Non-linear Models</a><ul>
<li class="chapter" data-level="9.1" data-path="splines.html"><a href="splines.html"><i class="fa fa-check"></i><b>9.1</b> Splines</a></li>
<li class="chapter" data-level="9.2" data-path="mars.html"><a href="mars.html"><i class="fa fa-check"></i><b>9.2</b> MARS</a></li>
<li class="chapter" data-level="9.3" data-path="gam.html"><a href="gam.html"><i class="fa fa-check"></i><b>9.3</b> GAM</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="support-vector-machines.html"><a href="support-vector-machines.html"><i class="fa fa-check"></i><b>10</b> Support Vector Machines</a><ul>
<li class="chapter" data-level="10.1" data-path="maximal-margin-classifier.html"><a href="maximal-margin-classifier.html"><i class="fa fa-check"></i><b>10.1</b> Maximal Margin Classifier</a></li>
<li class="chapter" data-level="10.2" data-path="support-vector-classifier.html"><a href="support-vector-classifier.html"><i class="fa fa-check"></i><b>10.2</b> Support Vector Classifier</a></li>
<li class="chapter" data-level="10.3" data-path="support-vector-machines-1.html"><a href="support-vector-machines-1.html"><i class="fa fa-check"></i><b>10.3</b> Support Vector Machines</a></li>
<li class="chapter" data-level="10.4" data-path="my-svm-example.html"><a href="my-svm-example.html"><i class="fa fa-check"></i><b>10.4</b> My svm Example</a></li>
<li class="chapter" data-level="10.5" data-path="using-caret.html"><a href="using-caret.html"><i class="fa fa-check"></i><b>10.5</b> Using Caret</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="part-3-unupervised-machine-learning.html"><a href="part-3-unupervised-machine-learning.html"><i class="fa fa-check"></i>PART 3: Unupervised Machine Learning</a></li>
<li class="chapter" data-level="11" data-path="dimensionality-reduction.html"><a href="dimensionality-reduction.html"><i class="fa fa-check"></i><b>11</b> Dimensionality Reduction</a><ul>
<li class="chapter" data-level="11.1" data-path="pca.html"><a href="pca.html"><i class="fa fa-check"></i><b>11.1</b> PCA</a></li>
<li class="chapter" data-level="11.2" data-path="t-sne.html"><a href="t-sne.html"><i class="fa fa-check"></i><b>11.2</b> t-SNE</a></li>
<li class="chapter" data-level="11.3" data-path="svd.html"><a href="svd.html"><i class="fa fa-check"></i><b>11.3</b> SVD</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="cluster-analysis.html"><a href="cluster-analysis.html"><i class="fa fa-check"></i><b>12</b> Cluster Analysis</a><ul>
<li class="chapter" data-level="12.1" data-path="k-means.html"><a href="k-means.html"><i class="fa fa-check"></i><b>12.1</b> K-Means</a></li>
<li class="chapter" data-level="12.2" data-path="hca.html"><a href="hca.html"><i class="fa fa-check"></i><b>12.2</b> HCA</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="text-mining.html"><a href="text-mining.html"><i class="fa fa-check"></i><b>13</b> Text Mining</a><ul>
<li class="chapter" data-level="13.1" data-path="tidy-text.html"><a href="tidy-text.html"><i class="fa fa-check"></i><b>13.1</b> Tidy Text</a></li>
<li class="chapter" data-level="13.2" data-path="bag-of-words.html"><a href="bag-of-words.html"><i class="fa fa-check"></i><b>13.2</b> Bag of Words</a></li>
<li class="chapter" data-level="13.3" data-path="sentiment-analysis.html"><a href="sentiment-analysis.html"><i class="fa fa-check"></i><b>13.3</b> Sentiment Analysis</a><ul>
<li class="chapter" data-level="13.3.1" data-path="sentiment-analysis.html"><a href="sentiment-analysis.html#n-grams"><i class="fa fa-check"></i><b>13.3.1</b> N-Grams</a></li>
<li class="chapter" data-level="13.3.2" data-path="sentiment-analysis.html"><a href="sentiment-analysis.html#converting-to-and-from-non-tidy-formats"><i class="fa fa-check"></i><b>13.3.2</b> Converting to and from non-tidy formats</a></li>
<li class="chapter" data-level="13.3.3" data-path="disc-dist.html"><a href="disc-dist.html#example"><i class="fa fa-check"></i><b>13.3.3</b> Example</a></li>
</ul></li>
<li class="chapter" data-level="13.4" data-path="topic-modeling.html"><a href="topic-modeling.html"><i class="fa fa-check"></i><b>13.4</b> Topic Modeling</a></li>
<li class="chapter" data-level="13.5" data-path="appendix-string-manipulation.html"><a href="appendix-string-manipulation.html"><i class="fa fa-check"></i><b>13.5</b> Appendix: String Manipulation</a><ul>
<li class="chapter" data-level="13.5.1" data-path="appendix-string-manipulation.html"><a href="appendix-string-manipulation.html#stringr-package"><i class="fa fa-check"></i><b>13.5.1</b> stringr package</a></li>
<li class="chapter" data-level="13.5.2" data-path="appendix-string-manipulation.html"><a href="appendix-string-manipulation.html#regular-expressions"><i class="fa fa-check"></i><b>13.5.2</b> Regular Expressions</a></li>
</ul></li>
<li class="chapter" data-level="13.6" data-path="reference-links.html"><a href="reference-links.html"><i class="fa fa-check"></i><b>13.6</b> Reference Links</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="survival-analysis.html"><a href="survival-analysis.html"><i class="fa fa-check"></i><b>14</b> Survival Analysis</a><ul>
<li class="chapter" data-level="14.1" data-path="basic-concepts.html"><a href="basic-concepts.html"><i class="fa fa-check"></i><b>14.1</b> Basic Concepts</a></li>
<li class="chapter" data-level="14.2" data-path="survival-curve-estimation.html"><a href="survival-curve-estimation.html"><i class="fa fa-check"></i><b>14.2</b> Survival Curve Estimation</a><ul>
<li class="chapter" data-level="14.2.1" data-path="survival-curve-estimation.html"><a href="survival-curve-estimation.html#kaplan-meier"><i class="fa fa-check"></i><b>14.2.1</b> Kaplan-Meier</a></li>
<li class="chapter" data-level="14.2.2" data-path="survival-curve-estimation.html"><a href="survival-curve-estimation.html#weibull"><i class="fa fa-check"></i><b>14.2.2</b> Weibull</a></li>
<li class="chapter" data-level="14.2.3" data-path="survival-curve-estimation.html"><a href="survival-curve-estimation.html#cox"><i class="fa fa-check"></i><b>14.2.3</b> Cox</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="" data-path="appendix.html"><a href="appendix.html"><i class="fa fa-check"></i>Appendix</a><ul>
<li class="chapter" data-level="" data-path="publishing-to-bookdown.html"><a href="publishing-to-bookdown.html"><i class="fa fa-check"></i>Publishing to BookDown</a></li>
<li class="chapter" data-level="" data-path="shiny-apps.html"><a href="shiny-apps.html"><i class="fa fa-check"></i>Shiny Apps</a></li>
<li class="chapter" data-level="" data-path="packages.html"><a href="packages.html"><i class="fa fa-check"></i>Packages</a><ul>
<li class="chapter" data-level="" data-path="packages.html"><a href="packages.html#create-a-package"><i class="fa fa-check"></i>Create a package</a></li>
<li class="chapter" data-level="14.2.4" data-path="packages.html"><a href="packages.html#document-functions-with-roxygen"><i class="fa fa-check"></i><b>14.2.4</b> Document Functions with roxygen</a></li>
<li class="chapter" data-level="" data-path="packages.html"><a href="packages.html#create-data"><i class="fa fa-check"></i>Create Data</a></li>
<li class="chapter" data-level="" data-path="packages.html"><a href="packages.html#create-vignette"><i class="fa fa-check"></i>Create Vignette</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">My Data Science Notes</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="logistic-regression" class="section level2">
<h2><span class="header-section-number">5.1</span> Logistic Regression</h2>
<p>Logistic regression estimates the probability of a particular level of a categorical response variable given a set of predictors. The response levels can be binary, nominal (multiple categories), or ordinal (multiple levels).</p>
<p>The <strong>binary</strong> logistic regression model is</p>
<p><span class="math display">\[y = logit(\pi) = \ln \left( \frac{\pi}{1 - \pi} \right) = X \beta\]</span></p>
<p>where <span class="math inline">\(\pi\)</span> is the event probability. The model predicts the <em>log odds</em> of the response variable. The maximum likelihood estimator maximizes the likelihood function</p>
<p><span class="math display">\[L(\beta; y, X) = \prod_{i=1}^n \pi_i^{y_i}(1 - \pi_i)^{(1-y_i)} = \prod_{i=1}^n\frac{\exp(y_i X_i \beta)}{1 + \exp(X_i \beta)}.\]</span></p>
<p>There is no closed-form solution, so GLM estimates coefficients with interatively reweighted least squares.</p>
<p>Here is a case study to illustrate the points. Dataset <code>donner</code> contains observations of 45 members of the Donner party with response variable (<code>surv</code>) an explanatory variables <code>age</code> and <code>sex</code>.</p>
<div class="sourceCode" id="cb511"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb511-1"><a href="logistic-regression.html#cb511-1"></a><span class="kw">glimpse</span>(donner)</span></code></pre></div>
<pre><code>## Rows: 45
## Columns: 3
## $ age  &lt;dbl&gt; 23, 40, 40, 30, 28, 40, 45, 62, 65, 45, 25, 28, 28, 23, 22, 23...
## $ sex  &lt;fct&gt; M, F, M, M, M, M, F, M, M, F, F, M, M, M, F, F, M, F, F, M, F,...
## $ surv &lt;fct&gt; Died, Lived, Lived, Died, Died, Died, Died, Died, Died, Died, ...</code></pre>
<div class="sourceCode" id="cb513"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb513-1"><a href="logistic-regression.html#cb513-1"></a>donner <span class="op">%&gt;%</span><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">surv =</span> <span class="kw">as.numeric</span>(surv)<span class="op">-</span><span class="dv">1</span>) <span class="op">%&gt;%</span></span>
<span id="cb513-2"><a href="logistic-regression.html#cb513-2"></a><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> age, <span class="dt">y =</span> surv, <span class="dt">color =</span> sex)) <span class="op">+</span></span>
<span id="cb513-3"><a href="logistic-regression.html#cb513-3"></a><span class="st">  </span><span class="kw">geom_jitter</span>() <span class="op">+</span></span>
<span id="cb513-4"><a href="logistic-regression.html#cb513-4"></a><span class="st">  </span><span class="kw">geom_smooth</span>(<span class="dt">method =</span> <span class="st">&quot;glm&quot;</span>, <span class="dt">method.args =</span> <span class="kw">list</span>(<span class="dt">family =</span> <span class="st">&quot;binomial&quot;</span>), <span class="dt">se =</span> <span class="ot">FALSE</span>) <span class="op">+</span></span>
<span id="cb513-5"><a href="logistic-regression.html#cb513-5"></a><span class="st">  </span><span class="kw">theme_mf</span>() <span class="op">+</span></span>
<span id="cb513-6"><a href="logistic-regression.html#cb513-6"></a><span class="st">  </span><span class="kw">labs</span>(<span class="dt">title =</span> <span class="st">&quot;Donner Party Survivorship&quot;</span>, <span class="dt">color =</span> <span class="st">&quot;&quot;</span>)</span></code></pre></div>
<pre><code>## `geom_smooth()` using formula &#39;y ~ x&#39;</code></pre>
<p><img src="data-sci_files/figure-html/unnamed-chunk-216-1.png" width="672" /></p>
<p>Fit a logistic regression <span class="math inline">\(SURV = SEX + AGE + SEX : AGE\)</span>.</p>
<div class="sourceCode" id="cb515"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb515-1"><a href="logistic-regression.html#cb515-1"></a>m &lt;-<span class="st"> </span><span class="kw">glm</span>(surv <span class="op">~</span><span class="st"> </span>sex<span class="op">*</span>age, <span class="dt">data =</span> donner, <span class="dt">family =</span> <span class="kw">binomial</span>(<span class="dt">link =</span> logit))</span>
<span id="cb515-2"><a href="logistic-regression.html#cb515-2"></a><span class="kw">summary</span>(m)</span></code></pre></div>
<pre><code>## 
## Call:
## glm(formula = surv ~ sex * age, family = binomial(link = logit), 
##     data = donner)
## 
## Deviance Residuals: 
##    Min      1Q  Median      3Q     Max  
## -2.228  -0.939  -0.555   0.779   1.700  
## 
## Coefficients:
##             Estimate Std. Error z value Pr(&gt;|z|)  
## (Intercept)   7.2464     3.2052    2.26    0.024 *
## sexM         -6.9280     3.3989   -2.04    0.042 *
## age          -0.1941     0.0874   -2.22    0.026 *
## sexM:age      0.1616     0.0943    1.71    0.086 .
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 61.827  on 44  degrees of freedom
## Residual deviance: 47.346  on 41  degrees of freedom
## AIC: 55.35
## 
## Number of Fisher Scoring iterations: 5</code></pre>
<p>The “z value” in the Coefficients table is the Wald z statistic, <span class="math inline">\(z = \hat{\beta} / SE(\hat{\beta})\)</span>, which if squared is the Wald chi-squared statistic, <span class="math inline">\(z^2\)</span>. The p.value is the area to the right of <span class="math inline">\(z^2\)</span> in the <span class="math inline">\(\chi_1^2\)</span> density curve:</p>
<div class="sourceCode" id="cb517"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb517-1"><a href="logistic-regression.html#cb517-1"></a>m <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">tidy</span>() <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb517-2"><a href="logistic-regression.html#cb517-2"></a><span class="st">  </span><span class="kw">mutate</span>(</span>
<span id="cb517-3"><a href="logistic-regression.html#cb517-3"></a>    <span class="dt">z =</span> estimate <span class="op">/</span><span class="st"> </span>std.error, </span>
<span id="cb517-4"><a href="logistic-regression.html#cb517-4"></a>    <span class="dt">p_z2 =</span> <span class="kw">pchisq</span>(z<span class="op">^</span><span class="dv">2</span>, <span class="dt">df =</span> <span class="dv">1</span>, <span class="dt">lower.tail =</span> <span class="ot">FALSE</span>)</span>
<span id="cb517-5"><a href="logistic-regression.html#cb517-5"></a>  ) <span class="op">%&gt;%</span></span>
<span id="cb517-6"><a href="logistic-regression.html#cb517-6"></a><span class="st">  </span><span class="kw">select</span>(term, estimate, z, p_z2) </span></code></pre></div>
<pre><code>## # A tibble: 4 x 4
##   term        estimate     z   p_z2
##   &lt;chr&gt;          &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;
## 1 (Intercept)    7.25   2.26 0.0238
## 2 sexM          -6.93  -2.04 0.0415
## 3 age           -0.194 -2.22 0.0264
## 4 sexM:age       0.162  1.71 0.0865</code></pre>
<p>Below the Coefficients table, the “dispersion parameter” refers to overdispersion, a common issue with GLM. For a logistic regression, the response variable should be distributed <span class="math inline">\(y_i \sim Bin(n_i, \pi_i)\)</span> with <span class="math inline">\(\mu_i = n_i \pi_i\)</span> and <span class="math inline">\(\sigma^2 = \pi (1 - \pi)\)</span>. Overdispersion means the data shows evidence of variance greater than <span class="math inline">\(\sigma^2\)</span>.</p>
<p>“Fisher scoring” is a method for ML estimation. Logistic regression uses an iterative procedure to fit the model, so this section indicates whether the algorithm converged.</p>
<p>The null deviance is the likelihood ratio <span class="math inline">\(G^2 = 61.827\)</span> of the intercept-only model. The residual deviance is the likelihood ratio <span class="math inline">\(G^2 = 47.346\)</span> after including all model covariates. <span class="math inline">\(G^2\)</span> is large, so reject the null hypothesis of no age and sex effects. The ANOVA table shows the change in deviance from adding each variable successively to the model.</p>
<div class="sourceCode" id="cb519"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb519-1"><a href="logistic-regression.html#cb519-1"></a><span class="kw">anova</span>(m)</span></code></pre></div>
<pre><code>## Analysis of Deviance Table
## 
## Model: binomial, link: logit
## 
## Response: surv
## 
## Terms added sequentially (first to last)
## 
## 
##         Df Deviance Resid. Df Resid. Dev
## NULL                       44       61.8
## sex      1     4.54        43       57.3
## age      1     6.03        42       51.3
## sex:age  1     3.91        41       47.3</code></pre>
<div class="sourceCode" id="cb521"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb521-1"><a href="logistic-regression.html#cb521-1"></a><span class="kw">glance</span>(m)</span></code></pre></div>
<pre><code>## # A tibble: 1 x 7
##   null.deviance df.null logLik   AIC   BIC deviance df.residual
##           &lt;dbl&gt;   &lt;int&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;       &lt;int&gt;
## 1          61.8      44  -23.7  55.3  62.6     47.3          41</code></pre>
<p>Plug in values to interpret the model. The log odds of a 24 year-old female surviving is <span class="math inline">\(\hat{y} = 2.59\)</span>. The log odds of a 24 year-old male surviving is <span class="math inline">\(\hat{y} = -0.46\)</span>.</p>
<div class="sourceCode" id="cb523"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb523-1"><a href="logistic-regression.html#cb523-1"></a><span class="kw">coef</span>(m)[<span class="st">&quot;(Intercept)&quot;</span>] <span class="op">+</span><span class="st"> </span><span class="kw">coef</span>(m)[<span class="st">&quot;sexM&quot;</span>]<span class="op">*</span><span class="dv">0</span> <span class="op">+</span><span class="st"> </span><span class="kw">coef</span>(m)[<span class="st">&quot;age&quot;</span>]<span class="op">*</span><span class="dv">24</span> <span class="op">+</span></span>
<span id="cb523-2"><a href="logistic-regression.html#cb523-2"></a><span class="st">  </span><span class="kw">coef</span>(m)[<span class="st">&quot;sexM:age&quot;</span>]<span class="op">*</span><span class="dv">0</span><span class="op">*</span><span class="dv">24</span></span>
<span id="cb523-3"><a href="logistic-regression.html#cb523-3"></a><span class="kw">coef</span>(m)[<span class="st">&quot;(Intercept)&quot;</span>] <span class="op">+</span><span class="st"> </span><span class="kw">coef</span>(m)[<span class="st">&quot;sexM&quot;</span>]<span class="op">*</span><span class="dv">1</span> <span class="op">+</span><span class="st"> </span><span class="kw">coef</span>(m)[<span class="st">&quot;age&quot;</span>]<span class="op">*</span><span class="dv">24</span> <span class="op">+</span></span>
<span id="cb523-4"><a href="logistic-regression.html#cb523-4"></a><span class="st">  </span><span class="kw">coef</span>(m)[<span class="st">&quot;sexM:age&quot;</span>]<span class="op">*</span><span class="dv">1</span><span class="op">*</span><span class="dv">24</span></span>
<span id="cb523-5"><a href="logistic-regression.html#cb523-5"></a></span>
<span id="cb523-6"><a href="logistic-regression.html#cb523-6"></a><span class="co"># Or use predict()</span></span>
<span id="cb523-7"><a href="logistic-regression.html#cb523-7"></a>(lo_f &lt;-<span class="st"> </span><span class="kw">predict</span>(m, <span class="dt">newdata =</span> <span class="kw">data.frame</span>(<span class="dt">sex =</span> <span class="st">&quot;F&quot;</span>, <span class="dt">age =</span> <span class="dv">24</span>)))</span>
<span id="cb523-8"><a href="logistic-regression.html#cb523-8"></a>(lo_m &lt;-<span class="st"> </span><span class="kw">predict</span>(m, <span class="dt">newdata =</span> <span class="kw">data.frame</span>(<span class="dt">sex =</span> <span class="st">&quot;M&quot;</span>, <span class="dt">age =</span> <span class="dv">24</span>)))</span></code></pre></div>
<p>Log odds are not easy to interpet. Exponentiate the log odds to get the <strong>odds</strong>.</p>
<p><span class="math display">\[odds(\hat{y}) = \exp (\hat{y}) = \frac{\pi}{1 - \pi}.\]</span></p>
<p>The odds of a 24 year-old female surviving is <span class="math inline">\(\exp(\hat{y}) = 13.31\)</span>. The odds of a 24 year-old male surviving is <span class="math inline">\(\exp(\hat{y}) = 0.63\)</span>.</p>
<div class="sourceCode" id="cb524"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb524-1"><a href="logistic-regression.html#cb524-1"></a><span class="kw">exp</span>(lo_f)</span>
<span id="cb524-2"><a href="logistic-regression.html#cb524-2"></a><span class="kw">exp</span>(lo_m)</span></code></pre></div>
<p>Solve for <span class="math inline">\(\pi\)</span> to get the <strong>probability</strong>.</p>
<p><span class="math display">\[\pi = \frac{\exp (\hat{y})}{1 + \exp (\hat{y})}\]</span></p>
<p>The probability of a 24 year-old female surviving is <span class="math inline">\(\pi = 0.93\)</span>. The probability of a female of average age surviving is <span class="math inline">\(\pi = 0.39\)</span>. The <code>predict()</code> function for a logistic model returns log-odds, but can also return <span class="math inline">\(\pi\)</span> by specifying parameter <code>type = "response"</code>.</p>
<div class="sourceCode" id="cb525"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb525-1"><a href="logistic-regression.html#cb525-1"></a><span class="kw">exp</span>(lo_f) <span class="op">/</span><span class="st"> </span>(<span class="dv">1</span> <span class="op">+</span><span class="st"> </span><span class="kw">exp</span>(lo_f))</span>
<span id="cb525-2"><a href="logistic-regression.html#cb525-2"></a><span class="kw">exp</span>(lo_m) <span class="op">/</span><span class="st"> </span>(<span class="dv">1</span> <span class="op">+</span><span class="st"> </span><span class="kw">exp</span>(lo_m))</span>
<span id="cb525-3"><a href="logistic-regression.html#cb525-3"></a></span>
<span id="cb525-4"><a href="logistic-regression.html#cb525-4"></a><span class="co"># Or use predict(..., type = &quot;response&quot;)</span></span>
<span id="cb525-5"><a href="logistic-regression.html#cb525-5"></a>(p_f &lt;-<span class="st"> </span><span class="kw">predict</span>(m, <span class="dt">newdata =</span> <span class="kw">data.frame</span>(<span class="dt">sex =</span> <span class="st">&quot;F&quot;</span>, <span class="dt">age =</span><span class="dv">24</span>), <span class="dt">type =</span> <span class="st">&quot;response&quot;</span>))</span>
<span id="cb525-6"><a href="logistic-regression.html#cb525-6"></a>(p_m &lt;-<span class="st"> </span><span class="kw">predict</span>(m, <span class="dt">newdata =</span> <span class="kw">data.frame</span>(<span class="dt">sex =</span> <span class="st">&quot;M&quot;</span>, <span class="dt">age =</span><span class="dv">24</span>), <span class="dt">type =</span> <span class="st">&quot;response&quot;</span>))</span></code></pre></div>
<p>Interpret the <em>coefficient</em> estimates using the <strong>odds ratio</strong>, the ratio of the odds before and after an increment to the predictors. The odds ratio is how much the odds would be multiplied after a <span class="math inline">\(\delta = X_1 - X_0\)</span> unit increase in <span class="math inline">\(X\)</span>.</p>
<p><span class="math display">\[\theta = \frac{\pi / (1 - \pi) |_{X = X_1}}{\pi / (1 - \pi) |_{X = X_0}} = \frac{\exp (X_1 \hat{\beta})}{\exp (X_0 \hat{\beta})} = \exp ((X_1-X_0) \hat{\beta}) = \exp (\delta \hat{\beta})\]</span></p>
<p>The odds of a female surviving are multiplied by a factor of <span class="math inline">\(\exp(1 \cdot (-0.19)) = 0.824\)</span> per additional year of age (or the odds fall by <span class="math inline">\(1 - 0.824 = 17.6\%\)</span>). The odds of a male surviving are multiplied by a factor of <span class="math inline">\(\exp(1 \cdot (-0.161-0.19)) = 0.968\)</span> per additional year of age.</p>
<div class="sourceCode" id="cb526"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb526-1"><a href="logistic-regression.html#cb526-1"></a><span class="kw">exp</span>(<span class="dv">1</span> <span class="op">*</span><span class="st"> </span>(<span class="kw">coef</span>(m)[<span class="st">&quot;age&quot;</span>] <span class="op">+</span><span class="st"> </span><span class="dv">0</span><span class="op">*</span><span class="kw">coef</span>(m)[<span class="st">&quot;sexM:age&quot;</span>]))  <span class="co"># female</span></span>
<span id="cb526-2"><a href="logistic-regression.html#cb526-2"></a><span class="kw">exp</span>(<span class="dv">1</span> <span class="op">*</span><span class="st"> </span>(<span class="kw">coef</span>(m)[<span class="st">&quot;age&quot;</span>] <span class="op">+</span><span class="st"> </span><span class="dv">1</span><span class="op">*</span><span class="kw">coef</span>(m)[<span class="st">&quot;sexM:age&quot;</span>]))  <span class="co"># male</span></span></code></pre></div>
<p><code>oddsratio::or_glm()</code> calculates the odds ratio from an increment in the predictor values.</p>
<div class="sourceCode" id="cb527"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb527-1"><a href="logistic-regression.html#cb527-1"></a>oddsratio<span class="op">::</span><span class="kw">or_glm</span>(donner, m, <span class="dt">incr =</span> <span class="kw">list</span>(<span class="dt">age =</span> <span class="dv">1</span>))</span></code></pre></div>
<pre><code>##   predictor oddsratio ci_low (2.5) ci_high (97.5)          increment
## 1      sexM     0.001         0.00           0.24 Indicator variable
## 2       age     0.824         0.65           0.94                  1
## 3  sexM:age     1.175         1.00           1.50 Indicator variable</code></pre>
<p>The predicted values can also be expressed as the probabilities <span class="math inline">\(\pi\)</span>. This produces the familiar signmoidal shape of the binary relationship.</p>
<div class="sourceCode" id="cb529"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb529-1"><a href="logistic-regression.html#cb529-1"></a><span class="kw">augment</span>(m, <span class="dt">type.predict =</span> <span class="st">&quot;response&quot;</span>) <span class="op">%&gt;%</span></span>
<span id="cb529-2"><a href="logistic-regression.html#cb529-2"></a><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> age)) <span class="op">+</span></span>
<span id="cb529-3"><a href="logistic-regression.html#cb529-3"></a><span class="st">  </span><span class="kw">geom_point</span>(<span class="kw">aes</span>(<span class="dt">y =</span> surv)) <span class="op">+</span></span>
<span id="cb529-4"><a href="logistic-regression.html#cb529-4"></a><span class="st">  </span><span class="kw">geom_line</span>(<span class="kw">aes</span>(<span class="dt">y =</span> .fitted<span class="op">+</span><span class="dv">1</span>)) <span class="op">+</span></span>
<span id="cb529-5"><a href="logistic-regression.html#cb529-5"></a><span class="st">  </span><span class="kw">theme_mf</span>() <span class="op">+</span></span>
<span id="cb529-6"><a href="logistic-regression.html#cb529-6"></a><span class="st">  </span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="st">&quot;AGE&quot;</span>,</span>
<span id="cb529-7"><a href="logistic-regression.html#cb529-7"></a>       <span class="dt">y =</span> <span class="st">&quot;Probability of SURVIVE&quot;</span>,</span>
<span id="cb529-8"><a href="logistic-regression.html#cb529-8"></a>       <span class="dt">title =</span> <span class="st">&quot;Binary Fitted Line Plot&quot;</span>)</span></code></pre></div>
<p><img src="data-sci_files/figure-html/unnamed-chunk-226-1.png" width="672" /></p>
<p>Evaluate a logistic regression using a <a href="https://community.tibco.com/wiki/gains-vs-roc-curves-do-you-understand-difference">Gain curve or ROC curve</a>.</p>
<p>In the <strong>gain curve</strong>, the x-axis is the fraction of items seen when sorted by the predicted value, and the y-axis is the cumulative summed true outcome. The “wizard” curve is the gain curve when the data is sorted by the true outcome. If the model’s gain curve is close to the wizard curve, then the model predicted the response variable well. The grey area is the “gain” over a random prediction.</p>
<p>20 of the 45 members of the Donner party survived.</p>
<ul>
<li>The gain curve encountered 10 survivors (50%) within the first 12 observations (27%). It encountered all 20 survivors on the 37th observation.</li>
<li>The bottom of the grey area is the outcome of a random model. Only half the survivors would be observed within 50% of the observations.<br />
</li>
<li>The top of the grey area is the outcome of the perfect model, the “wizard curve”. Half the survivors would be observed in 10/45=22% of the observations.</li>
</ul>
<div class="sourceCode" id="cb530"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb530-1"><a href="logistic-regression.html#cb530-1"></a><span class="kw">options</span>(<span class="dt">yardstick.event_first =</span> <span class="ot">FALSE</span>)  <span class="co"># set the second level as success</span></span>
<span id="cb530-2"><a href="logistic-regression.html#cb530-2"></a><span class="kw">augment</span>(m, <span class="dt">type.predict =</span> <span class="st">&quot;response&quot;</span>) <span class="op">%&gt;%</span></span>
<span id="cb530-3"><a href="logistic-regression.html#cb530-3"></a>yardstick<span class="op">::</span><span class="kw">gain_curve</span>(surv, .fitted) <span class="op">%&gt;%</span></span>
<span id="cb530-4"><a href="logistic-regression.html#cb530-4"></a><span class="st">  </span><span class="kw">autoplot</span>() <span class="op">+</span></span>
<span id="cb530-5"><a href="logistic-regression.html#cb530-5"></a><span class="st">  </span><span class="kw">labs</span>(<span class="dt">title =</span> <span class="st">&quot;Gain Curve&quot;</span>)</span></code></pre></div>
<p><img src="data-sci_files/figure-html/unnamed-chunk-227-1.png" width="672" /></p>
<p>The ROC (Receiver Operating Characteristics) curve plots sensitivity vs specificity at different cut-off values for the probability, ranging cut-off from 0 to 1.</p>
<div class="sourceCode" id="cb531"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb531-1"><a href="logistic-regression.html#cb531-1"></a><span class="kw">options</span>(<span class="dt">yardstick.event_first =</span> <span class="ot">FALSE</span>)  <span class="co"># set the second level as success</span></span>
<span id="cb531-2"><a href="logistic-regression.html#cb531-2"></a><span class="kw">augment</span>(m, <span class="dt">type.predict =</span> <span class="st">&quot;response&quot;</span>) <span class="op">%&gt;%</span></span>
<span id="cb531-3"><a href="logistic-regression.html#cb531-3"></a>yardstick<span class="op">::</span><span class="kw">roc_curve</span>(surv, .fitted) <span class="op">%&gt;%</span></span>
<span id="cb531-4"><a href="logistic-regression.html#cb531-4"></a><span class="st">  </span><span class="kw">autoplot</span>() <span class="op">+</span></span>
<span id="cb531-5"><a href="logistic-regression.html#cb531-5"></a><span class="st">  </span><span class="kw">labs</span>(<span class="dt">title =</span> <span class="st">&quot;ROC Curve&quot;</span>)</span></code></pre></div>
<p><img src="data-sci_files/figure-html/unnamed-chunk-228-1.png" width="672" /></p>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="generalized-linear-models.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="multinomial-logistic-regression.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="assets/gitbook-2.6.7/js/app.min.js"></script>
<script src="assets/gitbook-2.6.7/js/lunr.js"></script>
<script src="assets/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="assets/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="assets/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="assets/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="assets/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="assets/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="assets/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["data-sci.pdf", "data-sci.epub"],
"toc": {
"collapse": "subsection"
},
"toolbar": {
"position": "static"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
