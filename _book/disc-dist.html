<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>1.2 Discrete Distributions | My Data Science Notes</title>
  <meta name="description" content="This is a compendium of notes from classes, tutorials, etc. that I reference from time to time." />
  <meta name="generator" content="bookdown 0.18 and GitBook 2.6.7" />

  <meta property="og:title" content="1.2 Discrete Distributions | My Data Science Notes" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="This is a compendium of notes from classes, tutorials, etc. that I reference from time to time." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="1.2 Discrete Distributions | My Data Science Notes" />
  
  <meta name="twitter:description" content="This is a compendium of notes from classes, tutorials, etc. that I reference from time to time." />
  

<meta name="author" content="Michael Foley" />


<meta name="date" content="2020-05-20" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="principles.html"/>
<link rel="next" href="cont-dist.html"/>
<script src="assets/jquery-2.2.3/jquery.min.js"></script>
<link href="assets/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="assets/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="assets/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="assets/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="assets/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="assets/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="assets/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />











<style type="text/css">
code.sourceCode > span { display: inline-block; line-height: 1.25; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">My Data Science Notes</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Intro</a></li>
<li class="chapter" data-level="1" data-path="probability.html"><a href="probability.html"><i class="fa fa-check"></i><b>1</b> Probability</a><ul>
<li class="chapter" data-level="1.1" data-path="principles.html"><a href="principles.html"><i class="fa fa-check"></i><b>1.1</b> Principles</a></li>
<li class="chapter" data-level="1.2" data-path="disc-dist.html"><a href="disc-dist.html"><i class="fa fa-check"></i><b>1.2</b> Discrete Distributions</a><ul>
<li class="chapter" data-level="1.2.1" data-path="disc-dist.html"><a href="disc-dist.html#bernoulli"><i class="fa fa-check"></i><b>1.2.1</b> Bernoulli</a></li>
<li class="chapter" data-level="1.2.2" data-path="disc-dist.html"><a href="disc-dist.html#binomial"><i class="fa fa-check"></i><b>1.2.2</b> Binomial</a></li>
<li class="chapter" data-level="1.2.3" data-path="disc-dist.html"><a href="disc-dist.html#poission"><i class="fa fa-check"></i><b>1.2.3</b> Poission</a></li>
<li class="chapter" data-level="1.2.4" data-path="disc-dist.html"><a href="disc-dist.html#multinomial"><i class="fa fa-check"></i><b>1.2.4</b> Multinomial</a></li>
<li class="chapter" data-level="1.2.5" data-path="disc-dist.html"><a href="disc-dist.html#negative-binomial"><i class="fa fa-check"></i><b>1.2.5</b> Negative-Binomial</a></li>
<li class="chapter" data-level="1.2.6" data-path="disc-dist.html"><a href="disc-dist.html#geometric"><i class="fa fa-check"></i><b>1.2.6</b> Geometric</a></li>
<li class="chapter" data-level="1.2.7" data-path="disc-dist.html"><a href="disc-dist.html#hypergeometric"><i class="fa fa-check"></i><b>1.2.7</b> Hypergeometric</a></li>
<li class="chapter" data-level="1.2.8" data-path="disc-dist.html"><a href="disc-dist.html#gamma"><i class="fa fa-check"></i><b>1.2.8</b> Gamma</a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="cont-dist.html"><a href="cont-dist.html"><i class="fa fa-check"></i><b>1.3</b> Continuous Distributions</a><ul>
<li class="chapter" data-level="1.3.1" data-path="cont-dist.html"><a href="cont-dist.html#normal"><i class="fa fa-check"></i><b>1.3.1</b> Normal</a></li>
</ul></li>
<li class="chapter" data-level="1.4" data-path="join-distributions.html"><a href="join-distributions.html"><i class="fa fa-check"></i><b>1.4</b> Join Distributions</a></li>
<li class="chapter" data-level="1.5" data-path="likelihood.html"><a href="likelihood.html"><i class="fa fa-check"></i><b>1.5</b> Likelihood</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="discrete-analysis.html"><a href="discrete-analysis.html"><i class="fa fa-check"></i><b>2</b> Categorical Analysis - Nonmodel</a><ul>
<li class="chapter" data-level="2.1" data-path="chi-square-test.html"><a href="chi-square-test.html"><i class="fa fa-check"></i><b>2.1</b> Chi-Square Test</a></li>
<li class="chapter" data-level="2.2" data-path="one-way-tables.html"><a href="one-way-tables.html"><i class="fa fa-check"></i><b>2.2</b> One-Way Tables</a><ul>
<li class="chapter" data-level="2.2.1" data-path="one-way-tables.html"><a href="one-way-tables.html#chi-square-goodness-of-fit-test"><i class="fa fa-check"></i><b>2.2.1</b> Chi-Square Goodness-of-Fit Test</a></li>
<li class="chapter" data-level="2.2.2" data-path="one-way-tables.html"><a href="one-way-tables.html#proportion-test"><i class="fa fa-check"></i><b>2.2.2</b> Proportion Test</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="two-way-tables.html"><a href="two-way-tables.html"><i class="fa fa-check"></i><b>2.3</b> Two-Way Tables</a><ul>
<li class="chapter" data-level="2.3.1" data-path="two-way-tables.html"><a href="two-way-tables.html#chi-square-independence-test"><i class="fa fa-check"></i><b>2.3.1</b> Chi-Square Independence Test</a></li>
<li class="chapter" data-level="2.3.2" data-path="two-way-tables.html"><a href="two-way-tables.html#residuals-analysis"><i class="fa fa-check"></i><b>2.3.2</b> Residuals Analysis</a></li>
<li class="chapter" data-level="2.3.3" data-path="two-way-tables.html"><a href="two-way-tables.html#difference-in-proportions"><i class="fa fa-check"></i><b>2.3.3</b> Difference in Proportions</a></li>
<li class="chapter" data-level="2.3.4" data-path="two-way-tables.html"><a href="two-way-tables.html#relative-risk"><i class="fa fa-check"></i><b>2.3.4</b> Relative Risk</a></li>
<li class="chapter" data-level="2.3.5" data-path="two-way-tables.html"><a href="two-way-tables.html#odds-ratio"><i class="fa fa-check"></i><b>2.3.5</b> Odds Ratio</a></li>
<li class="chapter" data-level="2.3.6" data-path="two-way-tables.html"><a href="two-way-tables.html#partitioning-chi-square"><i class="fa fa-check"></i><b>2.3.6</b> Partitioning Chi-Square</a></li>
<li class="chapter" data-level="2.3.7" data-path="two-way-tables.html"><a href="two-way-tables.html#correlation"><i class="fa fa-check"></i><b>2.3.7</b> Correlation</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="k-way-tables.html"><a href="k-way-tables.html"><i class="fa fa-check"></i><b>2.4</b> K-Way Tables</a><ul>
<li class="chapter" data-level="2.4.1" data-path="k-way-tables.html"><a href="k-way-tables.html#odds-ratio-1"><i class="fa fa-check"></i><b>2.4.1</b> Odds Ratio</a></li>
<li class="chapter" data-level="2.4.2" data-path="k-way-tables.html"><a href="k-way-tables.html#chi-square-independence-test-1"><i class="fa fa-check"></i><b>2.4.2</b> Chi-Square Independence Test</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="continuous-analysis.html"><a href="continuous-analysis.html"><i class="fa fa-check"></i><b>3</b> Continuous Variable Analysis</a><ul>
<li class="chapter" data-level="3.0.1" data-path="continuous-analysis.html"><a href="continuous-analysis.html#correlation-1"><i class="fa fa-check"></i><b>3.0.1</b> Correlation</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="experiment-design.html"><a href="experiment-design.html"><i class="fa fa-check"></i><b>4</b> Experiment Design</a><ul>
<li class="chapter" data-level="4.1" data-path="single-factor.html"><a href="single-factor.html"><i class="fa fa-check"></i><b>4.1</b> Single Factor</a></li>
<li class="chapter" data-level="4.2" data-path="blocking.html"><a href="blocking.html"><i class="fa fa-check"></i><b>4.2</b> Blocking</a></li>
<li class="chapter" data-level="4.3" data-path="nested.html"><a href="nested.html"><i class="fa fa-check"></i><b>4.3</b> Nested</a></li>
<li class="chapter" data-level="4.4" data-path="split-plot.html"><a href="split-plot.html"><i class="fa fa-check"></i><b>4.4</b> Split Plot</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="part-2-supervised-machine-learning.html"><a href="part-2-supervised-machine-learning.html"><i class="fa fa-check"></i>PART 2: Supervised Machine Learning</a></li>
<li class="chapter" data-level="5" data-path="ordinary-least-squares.html"><a href="ordinary-least-squares.html"><i class="fa fa-check"></i><b>5</b> Ordinary Least Squares</a><ul>
<li class="chapter" data-level="5.1" data-path="linear-regression-model.html"><a href="linear-regression-model.html"><i class="fa fa-check"></i><b>5.1</b> Linear Regression Model</a></li>
<li class="chapter" data-level="5.2" data-path="parameter-estimation.html"><a href="parameter-estimation.html"><i class="fa fa-check"></i><b>5.2</b> Parameter Estimation</a></li>
<li class="chapter" data-level="5.3" data-path="model-assumptions.html"><a href="model-assumptions.html"><i class="fa fa-check"></i><b>5.3</b> Model Assumptions</a><ul>
<li class="chapter" data-level="5.3.1" data-path="model-assumptions.html"><a href="model-assumptions.html#linearity"><i class="fa fa-check"></i><b>5.3.1</b> Linearity</a></li>
<li class="chapter" data-level="5.3.2" data-path="model-assumptions.html"><a href="model-assumptions.html#multicollinearity"><i class="fa fa-check"></i><b>5.3.2</b> Multicollinearity</a></li>
<li class="chapter" data-level="5.3.3" data-path="model-assumptions.html"><a href="model-assumptions.html#normality"><i class="fa fa-check"></i><b>5.3.3</b> Normality</a></li>
<li class="chapter" data-level="5.3.4" data-path="model-assumptions.html"><a href="model-assumptions.html#equal-variances"><i class="fa fa-check"></i><b>5.3.4</b> Equal Variances</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="prediction.html"><a href="prediction.html"><i class="fa fa-check"></i><b>5.4</b> Prediction</a></li>
<li class="chapter" data-level="5.5" data-path="inference.html"><a href="inference.html"><i class="fa fa-check"></i><b>5.5</b> Inference</a><ul>
<li class="chapter" data-level="5.5.1" data-path="inference.html"><a href="inference.html#t-test"><i class="fa fa-check"></i><b>5.5.1</b> <em>t</em>-Test</a></li>
<li class="chapter" data-level="5.5.2" data-path="inference.html"><a href="inference.html#f-test"><i class="fa fa-check"></i><b>5.5.2</b> <em>F</em>-Test</a></li>
</ul></li>
<li class="chapter" data-level="5.6" data-path="interpretation.html"><a href="interpretation.html"><i class="fa fa-check"></i><b>5.6</b> Interpretation</a></li>
<li class="chapter" data-level="5.7" data-path="model-validation.html"><a href="model-validation.html"><i class="fa fa-check"></i><b>5.7</b> Model Validation</a><ul>
<li class="chapter" data-level="5.7.1" data-path="model-validation.html"><a href="model-validation.html#accuracy-metrics"><i class="fa fa-check"></i><b>5.7.1</b> Accuracy Metrics</a></li>
<li class="chapter" data-level="5.7.2" data-path="model-validation.html"><a href="model-validation.html#cross-validation"><i class="fa fa-check"></i><b>5.7.2</b> Cross-Validation</a></li>
<li class="chapter" data-level="5.7.3" data-path="model-validation.html"><a href="model-validation.html#gain-curve"><i class="fa fa-check"></i><b>5.7.3</b> Gain Curve</a></li>
</ul></li>
<li class="chapter" data-level="5.8" data-path="reference.html"><a href="reference.html"><i class="fa fa-check"></i><b>5.8</b> Reference</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="generalized-linear-models.html"><a href="generalized-linear-models.html"><i class="fa fa-check"></i><b>6</b> Generalized Linear Models</a><ul>
<li class="chapter" data-level="6.1" data-path="logistic-regression.html"><a href="logistic-regression.html"><i class="fa fa-check"></i><b>6.1</b> Logistic Regression</a></li>
<li class="chapter" data-level="6.2" data-path="multinomial-logistic-regression.html"><a href="multinomial-logistic-regression.html"><i class="fa fa-check"></i><b>6.2</b> Multinomial Logistic Regression</a></li>
<li class="chapter" data-level="6.3" data-path="ordinal-logistic-regression.html"><a href="ordinal-logistic-regression.html"><i class="fa fa-check"></i><b>6.3</b> Ordinal Logistic Regression</a><ul>
<li class="chapter" data-level="6.3.1" data-path="ordinal-logistic-regression.html"><a href="ordinal-logistic-regression.html#assumptions"><i class="fa fa-check"></i><b>6.3.1</b> Assumptions</a></li>
<li class="chapter" data-level="6.3.2" data-path="ordinal-logistic-regression.html"><a href="ordinal-logistic-regression.html#modeling"><i class="fa fa-check"></i><b>6.3.2</b> Modeling</a></li>
<li class="chapter" data-level="6.3.3" data-path="ordinal-logistic-regression.html"><a href="ordinal-logistic-regression.html#case-study"><i class="fa fa-check"></i><b>6.3.3</b> Case Study</a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="poisson-regression.html"><a href="poisson-regression.html"><i class="fa fa-check"></i><b>6.4</b> Poisson Regression</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="multivariate-statistical-analysis.html"><a href="multivariate-statistical-analysis.html"><i class="fa fa-check"></i><b>7</b> Multivariate Statistical Analysis</a><ul>
<li class="chapter" data-level="7.1" data-path="background.html"><a href="background.html"><i class="fa fa-check"></i><b>7.1</b> Background</a></li>
<li class="chapter" data-level="7.2" data-path="manova.html"><a href="manova.html"><i class="fa fa-check"></i><b>7.2</b> MANOVA</a></li>
<li class="chapter" data-level="7.3" data-path="repeated-measures.html"><a href="repeated-measures.html"><i class="fa fa-check"></i><b>7.3</b> Repeated Measures</a></li>
<li class="chapter" data-level="7.4" data-path="lda.html"><a href="lda.html"><i class="fa fa-check"></i><b>7.4</b> LDA</a></li>
<li class="chapter" data-level="7.5" data-path="pca.html"><a href="pca.html"><i class="fa fa-check"></i><b>7.5</b> PCA</a></li>
<li class="chapter" data-level="7.6" data-path="factor-analysis.html"><a href="factor-analysis.html"><i class="fa fa-check"></i><b>7.6</b> Factor Analysis</a></li>
<li class="chapter" data-level="7.7" data-path="canonical-correlation.html"><a href="canonical-correlation.html"><i class="fa fa-check"></i><b>7.7</b> Canonical Correlation</a></li>
<li class="chapter" data-level="7.8" data-path="cluster-analysis.html"><a href="cluster-analysis.html"><i class="fa fa-check"></i><b>7.8</b> Cluster Analysis</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="classification.html"><a href="classification.html"><i class="fa fa-check"></i><b>8</b> Classification</a></li>
<li class="chapter" data-level="9" data-path="regularization.html"><a href="regularization.html"><i class="fa fa-check"></i><b>9</b> Regularization</a></li>
<li class="chapter" data-level="10" data-path="decision-trees.html"><a href="decision-trees.html"><i class="fa fa-check"></i><b>10</b> Decision Trees</a><ul>
<li class="chapter" data-level="10.1" data-path="classification-tree.html"><a href="classification-tree.html"><i class="fa fa-check"></i><b>10.1</b> Classification Tree</a><ul>
<li class="chapter" data-level="10.1.1" data-path="classification-tree.html"><a href="classification-tree.html#confusion-matrix"><i class="fa fa-check"></i><b>10.1.1</b> Confusion Matrix</a></li>
<li class="chapter" data-level="10.1.2" data-path="classification-tree.html"><a href="classification-tree.html#roc-curve"><i class="fa fa-check"></i><b>10.1.2</b> ROC Curve</a></li>
<li class="chapter" data-level="10.1.3" data-path="classification-tree.html"><a href="classification-tree.html#caret-approach"><i class="fa fa-check"></i><b>10.1.3</b> Caret Approach</a></li>
</ul></li>
<li class="chapter" data-level="10.2" data-path="regression-trees.html"><a href="regression-trees.html"><i class="fa fa-check"></i><b>10.2</b> Regression Trees</a><ul>
<li class="chapter" data-level="10.2.1" data-path="regression-trees.html"><a href="regression-trees.html#caret-approach-1"><i class="fa fa-check"></i><b>10.2.1</b> Caret Approach</a></li>
</ul></li>
<li class="chapter" data-level="10.3" data-path="bagging.html"><a href="bagging.html"><i class="fa fa-check"></i><b>10.3</b> Bagging</a></li>
<li class="chapter" data-level="10.4" data-path="random-forests.html"><a href="random-forests.html"><i class="fa fa-check"></i><b>10.4</b> Random Forests</a></li>
<li class="chapter" data-level="10.5" data-path="gradient-boosting.html"><a href="gradient-boosting.html"><i class="fa fa-check"></i><b>10.5</b> Gradient Boosting</a></li>
<li class="chapter" data-level="10.6" data-path="summary.html"><a href="summary.html"><i class="fa fa-check"></i><b>10.6</b> Summary</a></li>
<li class="chapter" data-level="10.7" data-path="reference-1.html"><a href="reference-1.html"><i class="fa fa-check"></i><b>10.7</b> Reference</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="non-linear-models.html"><a href="non-linear-models.html"><i class="fa fa-check"></i><b>11</b> Non-linear Models</a><ul>
<li class="chapter" data-level="11.1" data-path="splines.html"><a href="splines.html"><i class="fa fa-check"></i><b>11.1</b> Splines</a></li>
<li class="chapter" data-level="11.2" data-path="mars.html"><a href="mars.html"><i class="fa fa-check"></i><b>11.2</b> MARS</a></li>
<li class="chapter" data-level="11.3" data-path="gam.html"><a href="gam.html"><i class="fa fa-check"></i><b>11.3</b> GAM</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="support-vector-machines.html"><a href="support-vector-machines.html"><i class="fa fa-check"></i><b>12</b> Support Vector Machines</a><ul>
<li class="chapter" data-level="12.1" data-path="maximal-margin-classifier.html"><a href="maximal-margin-classifier.html"><i class="fa fa-check"></i><b>12.1</b> Maximal Margin Classifier</a></li>
<li class="chapter" data-level="12.2" data-path="support-vector-classifier.html"><a href="support-vector-classifier.html"><i class="fa fa-check"></i><b>12.2</b> Support Vector Classifier</a></li>
<li class="chapter" data-level="12.3" data-path="support-vector-machines-1.html"><a href="support-vector-machines-1.html"><i class="fa fa-check"></i><b>12.3</b> Support Vector Machines</a></li>
<li class="chapter" data-level="12.4" data-path="example-16.html"><a href="example-16.html"><i class="fa fa-check"></i><b>12.4</b> Example</a></li>
<li class="chapter" data-level="12.5" data-path="using-caret.html"><a href="using-caret.html"><i class="fa fa-check"></i><b>12.5</b> Using Caret</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="principal-components-analysis.html"><a href="principal-components-analysis.html"><i class="fa fa-check"></i><b>13</b> Principal Components Analysis</a></li>
<li class="chapter" data-level="14" data-path="text-mining.html"><a href="text-mining.html"><i class="fa fa-check"></i><b>14</b> Text Mining</a></li>
<li class="chapter" data-level="15" data-path="survival-analysis.html"><a href="survival-analysis.html"><i class="fa fa-check"></i><b>15</b> Survival Analysis</a><ul>
<li class="chapter" data-level="15.0.1" data-path="survival-analysis.html"><a href="survival-analysis.html#xelox"><i class="fa fa-check"></i><b>15.0.1</b> Xelox</a></li>
<li class="chapter" data-level="15.0.2" data-path="survival-analysis.html"><a href="survival-analysis.html#pancreatic"><i class="fa fa-check"></i><b>15.0.2</b> pancreatic</a></li>
<li class="chapter" data-level="15.0.3" data-path="survival-analysis.html"><a href="survival-analysis.html#prostatesurvival"><i class="fa fa-check"></i><b>15.0.3</b> prostateSurvival</a></li>
<li class="chapter" data-level="15.0.4" data-path="survival-analysis.html"><a href="survival-analysis.html#pharmacosmoking"><i class="fa fa-check"></i><b>15.0.4</b> pharmacoSmoking</a></li>
<li class="chapter" data-level="15.0.5" data-path="survival-analysis.html"><a href="survival-analysis.html#hepatocellular"><i class="fa fa-check"></i><b>15.0.5</b> hepatoCellular</a></li>
<li class="chapter" data-level="15.0.6" data-path="survival-analysis.html"><a href="survival-analysis.html#gbsg2"><i class="fa fa-check"></i><b>15.0.6</b> GBSG2</a></li>
<li class="chapter" data-level="15.0.7" data-path="survival-analysis.html"><a href="survival-analysis.html#unemp"><i class="fa fa-check"></i><b>15.0.7</b> Unemp</a></li>
<li class="chapter" data-level="15.1" data-path="survival-theory.html"><a href="survival-theory.html"><i class="fa fa-check"></i><b>15.1</b> Survival Theory</a></li>
<li class="chapter" data-level="15.2" data-path="survival-curve-estimation.html"><a href="survival-curve-estimation.html"><i class="fa fa-check"></i><b>15.2</b> Survival Curve Estimation</a></li>
<li class="chapter" data-level="15.3" data-path="survival-curve-estimation-1.html"><a href="survival-curve-estimation-1.html"><i class="fa fa-check"></i><b>15.3</b> Survival Curve Estimation</a></li>
<li class="chapter" data-level="15.4" data-path="proportional-hazards-model.html"><a href="proportional-hazards-model.html"><i class="fa fa-check"></i><b>15.4</b> Proportional Hazards Model</a></li>
</ul></li>
<li class="chapter" data-level="16" data-path="survival-analysis-1.html"><a href="survival-analysis-1.html"><i class="fa fa-check"></i><b>16</b> Survival Analysis</a><ul>
<li class="chapter" data-level="16.0.1" data-path="survival-analysis-1.html"><a href="survival-analysis-1.html#gbsg2-1"><i class="fa fa-check"></i><b>16.0.1</b> GBSG2</a></li>
<li class="chapter" data-level="16.0.2" data-path="survival-analysis-1.html"><a href="survival-analysis-1.html#unemp-1"><i class="fa fa-check"></i><b>16.0.2</b> Unemp</a></li>
<li class="chapter" data-level="16.1" data-path="background-1.html"><a href="background-1.html"><i class="fa fa-check"></i><b>16.1</b> Background</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="appendix.html"><a href="appendix.html"><i class="fa fa-check"></i>Appendix</a><ul>
<li class="chapter" data-level="" data-path="publishing-to-bookdown.html"><a href="publishing-to-bookdown.html"><i class="fa fa-check"></i>Publishing to BookDown</a></li>
<li class="chapter" data-level="" data-path="shiny-apps.html"><a href="shiny-apps.html"><i class="fa fa-check"></i>Shiny Apps</a></li>
<li class="chapter" data-level="" data-path="packages.html"><a href="packages.html"><i class="fa fa-check"></i>Packages</a><ul>
<li class="chapter" data-level="" data-path="packages.html"><a href="packages.html#create-a-package"><i class="fa fa-check"></i>Create a package</a></li>
<li class="chapter" data-level="16.1.1" data-path="packages.html"><a href="packages.html#document-functions-with-roxygen"><i class="fa fa-check"></i><b>16.1.1</b> Document Functions with roxygen</a></li>
<li class="chapter" data-level="" data-path="packages.html"><a href="packages.html#create-data"><i class="fa fa-check"></i>Create Data</a></li>
<li class="chapter" data-level="" data-path="packages.html"><a href="packages.html#create-vignette"><i class="fa fa-check"></i>Create Vignette</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">My Data Science Notes</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="disc_dist" class="section level2">
<h2><span class="header-section-number">1.2</span> Discrete Distributions</h2>
<p>These notes rely heavily on PSU STATS 504 <a href="https://online.stat.psu.edu/stat504/node/209/">course notes</a>.</p>
<p>The most important discrete distributions are the Binomial, Poisson, and Multinomial. Sometimes useful are the related Bernoulli, negative binomial, geometric, and hypergeometric distributions.</p>
<p>A discrete random variable <span class="math inline">\(X\)</span> is described by its probability mass function <span class="math inline">\(f(x) = P(X = x)\)</span>. The set of <span class="math inline">\(x\)</span> values for which <span class="math inline">\(f(x) &gt; 0\)</span> is called the <em>support</em>. If the distribution depends on unknown parameter(s) <span class="math inline">\(\theta\)</span> we write it as <span class="math inline">\(f(x; \theta)\)</span> (frequentist) or <span class="math inline">\(f(x | \theta)\)</span> (Bayesian).</p>
<div id="bernoulli" class="section level3">
<h3><span class="header-section-number">1.2.1</span> Bernoulli</h3>
<p>If <span class="math inline">\(X\)</span> is the result of a trial with two outcomes of probability <span class="math inline">\(P(X = 1) = \pi\)</span> and <span class="math inline">\(P(X = 0) = 1 - \pi\)</span>, then <span class="math inline">\(X\)</span> is a random variable with a Bernoulli distribution</p>
<p><span class="math display">\[f(x) = \pi^x (1 - \pi)^{1 - x}, \hspace{1cm} x \in (0, 1)\]</span></p>
<p>with <span class="math inline">\(E(X) = \pi\)</span> and <span class="math inline">\(Var(X) = \pi(1 - \pi)\)</span>.</p>
</div>
<div id="binomial" class="section level3">
<h3><span class="header-section-number">1.2.2</span> Binomial</h3>
<p>If <span class="math inline">\(X\)</span> is the count of successful events in <span class="math inline">\(n\)</span> identical and independent Bernoulli trials of success probability <span class="math inline">\(\pi\)</span>, then <span class="math inline">\(X\)</span> is a random variable with a binomial distribution <span class="math inline">\(X \sim Bin(n,\pi)\)</span></p>
<p><span class="math display">\[f(x;n, \pi) = \frac{n!}{x!(n-x)!} \pi^x (1-\pi)^{n-x} \hspace{1cm} x \in (0, 1, ..., n), \hspace{2mm} \pi \in [0, 1]\]</span></p>
<p>with <span class="math inline">\(E(X)=n\pi\)</span> and <span class="math inline">\(Var(X) = n\pi(1-\pi)\)</span>.</p>
<p>Binomial sampling is used to model counts of one level of a categorical variable over a <em>fixed sample size</em>. Here is a simple analysis of data from a Binomial process. Data set <code>dat</code> contains frequencies of high-risk drinkers vs non-high-risk drinkers in a college survey.</p>
<pre><code>## 
##  No Yes 
## 685 630</code></pre>
<p>The MLE of <span class="math inline">\(\pi\)</span> from the Binomial distribution is the sample mean.</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2-1"><a href="disc-dist.html#cb2-1"></a>x &lt;-<span class="st"> </span><span class="kw">sum</span>(dat<span class="op">$</span>high_risk <span class="op">==</span><span class="st"> &quot;Yes&quot;</span>)</span>
<span id="cb2-2"><a href="disc-dist.html#cb2-2"></a>n &lt;-<span class="st"> </span><span class="kw">nrow</span>(dat)</span>
<span id="cb2-3"><a href="disc-dist.html#cb2-3"></a>p &lt;-<span class="st"> </span>x <span class="op">/</span><span class="st"> </span>n</span>
<span id="cb2-4"><a href="disc-dist.html#cb2-4"></a><span class="kw">print</span>(p)</span></code></pre></div>
<pre><code>## [1] 0.4790875</code></pre>
<p>Here is the binomial distribution <span class="math inline">\(f(x; \pi), \hspace{5mm} x \in [550, 700]\)</span>.</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb4-1"><a href="disc-dist.html#cb4-1"></a>events &lt;-<span class="st"> </span><span class="kw">round</span>(<span class="kw">seq</span>(<span class="dt">from =</span> <span class="dv">550</span>, <span class="dt">to =</span> <span class="dv">700</span>, <span class="dt">length =</span> <span class="dv">20</span>), <span class="dv">0</span>)</span>
<span id="cb4-2"><a href="disc-dist.html#cb4-2"></a>density &lt;-<span class="st"> </span><span class="kw">dbinom</span>(<span class="dt">x =</span> events, <span class="dt">prob =</span> p, <span class="dt">size =</span> n)</span>
<span id="cb4-3"><a href="disc-dist.html#cb4-3"></a>prob &lt;-<span class="st"> </span><span class="kw">pbinom</span>(<span class="dt">q =</span> events, <span class="dt">prob =</span> p, <span class="dt">size =</span> n, <span class="dt">lower.tail =</span> <span class="ot">TRUE</span>)</span>
<span id="cb4-4"><a href="disc-dist.html#cb4-4"></a>df &lt;-<span class="st"> </span><span class="kw">data.frame</span>(events, density, prob)</span>
<span id="cb4-5"><a href="disc-dist.html#cb4-5"></a><span class="kw">ggplot</span>(df, <span class="kw">aes</span>(<span class="dt">x =</span> <span class="kw">factor</span>(events))) <span class="op">+</span></span>
<span id="cb4-6"><a href="disc-dist.html#cb4-6"></a><span class="co">#  geom_col(aes(y = density)) +</span></span>
<span id="cb4-7"><a href="disc-dist.html#cb4-7"></a><span class="st">  </span><span class="kw">geom_col</span>(<span class="kw">aes</span>(<span class="dt">y =</span> density), <span class="dt">fill =</span> <span class="kw">mf_pal</span>()(<span class="dv">1</span>), <span class="dt">alpha =</span> <span class="fl">0.8</span>) <span class="op">+</span></span>
<span id="cb4-8"><a href="disc-dist.html#cb4-8"></a><span class="st">  </span><span class="kw">geom_text</span>(</span>
<span id="cb4-9"><a href="disc-dist.html#cb4-9"></a>    <span class="kw">aes</span>(<span class="dt">label =</span> <span class="kw">round</span>(density, <span class="dv">3</span>), <span class="dt">y =</span> density <span class="op">+</span><span class="st"> </span><span class="fl">0.001</span>),</span>
<span id="cb4-10"><a href="disc-dist.html#cb4-10"></a>    <span class="dt">position =</span> <span class="kw">position_dodge</span>(<span class="fl">0.9</span>),</span>
<span id="cb4-11"><a href="disc-dist.html#cb4-11"></a>    <span class="dt">size =</span> <span class="dv">3</span>,</span>
<span id="cb4-12"><a href="disc-dist.html#cb4-12"></a>    <span class="dt">vjust =</span> <span class="dv">0</span></span>
<span id="cb4-13"><a href="disc-dist.html#cb4-13"></a>  ) <span class="op">+</span></span>
<span id="cb4-14"><a href="disc-dist.html#cb4-14"></a><span class="st">  </span><span class="kw">geom_line</span>(</span>
<span id="cb4-15"><a href="disc-dist.html#cb4-15"></a>    <span class="dt">data =</span> df, </span>
<span id="cb4-16"><a href="disc-dist.html#cb4-16"></a>    <span class="kw">aes</span>(<span class="dt">x =</span> <span class="kw">as.numeric</span>(<span class="kw">factor</span>(events)), <span class="dt">y =</span> prob<span class="op">/</span><span class="dv">40</span>), </span>
<span id="cb4-17"><a href="disc-dist.html#cb4-17"></a>    <span class="dt">color =</span> <span class="kw">mf_pal</span>()(<span class="dv">1</span>), </span>
<span id="cb4-18"><a href="disc-dist.html#cb4-18"></a>    <span class="dt">size =</span> <span class="dv">1</span>) <span class="op">+</span></span>
<span id="cb4-19"><a href="disc-dist.html#cb4-19"></a><span class="st">  </span><span class="kw">scale_y_continuous</span>(<span class="dt">sec.axis =</span> <span class="kw">sec_axis</span>(<span class="op">~</span>.<span class="op">*</span><span class="dv">40</span>, <span class="dt">name =</span> <span class="st">&quot;Cum Prob&quot;</span>)) <span class="op">+</span></span>
<span id="cb4-20"><a href="disc-dist.html#cb4-20"></a><span class="st">  </span><span class="kw">theme_mf</span>() <span class="op">+</span></span>
<span id="cb4-21"><a href="disc-dist.html#cb4-21"></a><span class="st">  </span><span class="kw">labs</span>(<span class="dt">title =</span> <span class="st">&quot;PMF and CDF of Binomial Distribution&quot;</span>,</span>
<span id="cb4-22"><a href="disc-dist.html#cb4-22"></a>       <span class="dt">subtitle =</span> <span class="st">&quot;Bin(1315, 0.479).&quot;</span>,</span>
<span id="cb4-23"><a href="disc-dist.html#cb4-23"></a>       <span class="dt">x =</span> <span class="st">&quot;Events (x)&quot;</span>,</span>
<span id="cb4-24"><a href="disc-dist.html#cb4-24"></a>       <span class="dt">y =</span> <span class="st">&quot;Density&quot;</span>)</span></code></pre></div>
<p><img src="data-sci_files/figure-html/unnamed-chunk-4-1.png" width="672" /></p>
<p>There are several ways to calculate a confidence interval for <span class="math inline">\(\pi\)</span>. One method is the <strong>normal approximation</strong> (Wald) interval.</p>
<p><span class="math display">\[\pi = p \pm z_{\alpha /2} \sqrt{\frac{p (1 - p)}{n}}\]</span></p>
<div class="sourceCode" id="cb5"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb5-1"><a href="disc-dist.html#cb5-1"></a>alpha &lt;-<span class="st"> </span><span class="fl">.05</span></span>
<span id="cb5-2"><a href="disc-dist.html#cb5-2"></a>z &lt;-<span class="st"> </span><span class="kw">qnorm</span>(<span class="dv">1</span> <span class="op">-</span><span class="st"> </span>alpha <span class="op">/</span><span class="st"> </span><span class="dv">2</span>)</span>
<span id="cb5-3"><a href="disc-dist.html#cb5-3"></a>se &lt;-<span class="st"> </span><span class="kw">sqrt</span>(p <span class="op">*</span><span class="st"> </span>(<span class="dv">1</span> <span class="op">-</span><span class="st"> </span>p) <span class="op">/</span><span class="st"> </span>n)</span>
<span id="cb5-4"><a href="disc-dist.html#cb5-4"></a>p <span class="op">+</span><span class="st"> </span><span class="kw">c</span>(<span class="op">-</span>z<span class="op">*</span>se, z<span class="op">*</span>se)</span></code></pre></div>
<pre><code>## [1] 0.4520868 0.5060882</code></pre>
<p>This method is easy to understand and calculate by hand, but its accuracy suffers when <span class="math inline">\(np&lt;5\)</span> or <span class="math inline">\(n(1-p)&lt;5\)</span> and it does not work at all when <span class="math inline">\(p = 0\)</span> or <span class="math inline">\(p = 1\)</span>. Option two is the <strong>Wilson</strong> method.</p>
<p><span class="math display">\[\frac{p + \frac{z^2}{2n}}{1 + \frac{z^2}{n}} \pm \frac{z}{1 + \frac{z^2}{n}} \sqrt{\frac{p(1 - p)}{n} + \frac{z^2}{4n^2}}\]</span></p>
<div class="sourceCode" id="cb7"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb7-1"><a href="disc-dist.html#cb7-1"></a>est &lt;-<span class="st"> </span>(p <span class="op">+</span><span class="st"> </span>(z<span class="op">^</span><span class="dv">2</span>)<span class="op">/</span>(<span class="dv">2</span><span class="op">*</span>n)) <span class="op">/</span><span class="st"> </span>(<span class="dv">1</span> <span class="op">+</span><span class="st"> </span>(z<span class="op">^</span><span class="dv">2</span>) <span class="op">/</span><span class="st"> </span>n)</span>
<span id="cb7-2"><a href="disc-dist.html#cb7-2"></a>pm &lt;-<span class="st"> </span>z <span class="op">/</span><span class="st"> </span>(<span class="dv">1</span> <span class="op">+</span><span class="st"> </span>(z<span class="op">^</span><span class="dv">2</span>)<span class="op">/</span>n) <span class="op">*</span><span class="st"> </span><span class="kw">sqrt</span>(p<span class="op">*</span>(<span class="dv">1</span><span class="op">-</span>p)<span class="op">/</span>n <span class="op">+</span><span class="st"> </span>(z<span class="op">^</span><span class="dv">2</span>) <span class="op">/</span><span class="st"> </span>(<span class="dv">4</span><span class="op">*</span>(n<span class="op">^</span><span class="dv">2</span>)))</span>
<span id="cb7-3"><a href="disc-dist.html#cb7-3"></a>est <span class="op">+</span><span class="st"> </span><span class="kw">c</span>(<span class="op">-</span>pm, pm)</span></code></pre></div>
<pre><code>## [1] 0.4521869 0.5061098</code></pre>
<p>This is what <code>prop.test()</code> does when you set <code>correct = FALSE</code>.</p>
<div class="sourceCode" id="cb9"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb9-1"><a href="disc-dist.html#cb9-1"></a><span class="kw">prop.test</span>(<span class="dt">x =</span> x, <span class="dt">n =</span> n, <span class="dt">correct =</span> <span class="ot">FALSE</span>)</span></code></pre></div>
<pre><code>## 
##  1-sample proportions test without continuity correction
## 
## data:  x out of n, null probability 0.5
## X-squared = 2.3004, df = 1, p-value = 0.1293
## alternative hypothesis: true p is not equal to 0.5
## 95 percent confidence interval:
##  0.4521869 0.5061098
## sample estimates:
##         p 
## 0.4790875</code></pre>
<p>There is a second version of the Wilson interval that applies a “continuity correction” that aligns the “minimum coverage probability”, rather than the “average probability”, with the nominal value. <em>I’ll need to learn what’s inside those quotations at some point.</em></p>
<div class="sourceCode" id="cb11"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb11-1"><a href="disc-dist.html#cb11-1"></a><span class="kw">prop.test</span>(<span class="dt">x =</span> x, <span class="dt">n =</span> n)</span></code></pre></div>
<pre><code>## 
##  1-sample proportions test with continuity correction
## 
## data:  x out of n, null probability 0.5
## X-squared = 2.2175, df = 1, p-value = 0.1365
## alternative hypothesis: true p is not equal to 0.5
## 95 percent confidence interval:
##  0.4518087 0.5064898
## sample estimates:
##         p 
## 0.4790875</code></pre>
<p>Finally, there is the Clopper-Pearson <strong>exact confidence interval</strong>. Clopper-Pearson inverts two single-tailed binomial tests at the desired alpha. This is a non-trivial calculation, so there is no easy formula to crank through. Just use the <code>binom.test()</code> function and pray no one asks for an explanation.</p>
<div class="sourceCode" id="cb13"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb13-1"><a href="disc-dist.html#cb13-1"></a><span class="kw">binom.test</span>(<span class="dt">x =</span> x, <span class="dt">n =</span> n)</span></code></pre></div>
<pre><code>## 
##  Exact binomial test
## 
## data:  x and n
## number of successes = 630, number of trials = 1315, p-value = 0.1364
## alternative hypothesis: true probability of success is not equal to 0.5
## 95 percent confidence interval:
##  0.4517790 0.5064896
## sample estimates:
## probability of success 
##              0.4790875</code></pre>
<p>The expected probability of no one being a high-risk drinker is <span class="math inline">\(f(0;0.479) = \frac{1315!}{0!(1315-0)!} 0.479^0 (1-0.479)^{1315-0} = 0\)</span>.</p>
<div class="sourceCode" id="cb15"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb15-1"><a href="disc-dist.html#cb15-1"></a><span class="kw">dbinom</span>(<span class="dt">x =</span> <span class="dv">0</span>, <span class="dt">size =</span> n, <span class="dt">p =</span> p)</span></code></pre></div>
<pre><code>## [1] 0</code></pre>
<p>The expected probability of half the population being a high-risk drinker, <span class="math inline">\(f(658, 0.479)\)</span>, is impossible to write out, and slow to calculate.</p>
<div class="sourceCode" id="cb17"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb17-1"><a href="disc-dist.html#cb17-1"></a><span class="kw">pbinom</span>(<span class="dt">q =</span> <span class="fl">.5</span><span class="op">*</span>n, <span class="dt">size =</span> n, <span class="dt">prob =</span> p, <span class="dt">lower.tail =</span> <span class="ot">FALSE</span>)</span></code></pre></div>
<pre><code>## [1] 0.06455096</code></pre>
<p>As n increases for fixed <span class="math inline">\(\pi\)</span>, the binomial distribution approaches normal distribution <span class="math inline">\(N(n\pi, n\pi(1−\pi))\)</span>. The normal distribution is a good approximation when <span class="math inline">\(n\)</span> is large.</p>
<div class="sourceCode" id="cb19"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb19-1"><a href="disc-dist.html#cb19-1"></a><span class="kw">pnorm</span>(<span class="dt">q =</span> <span class="fl">0.5</span>, <span class="dt">mean =</span> p, <span class="dt">sd =</span> se, <span class="dt">lower.tail =</span> <span class="ot">FALSE</span>)</span></code></pre></div>
<pre><code>## [1] 0.06450357</code></pre>
<p>Here are some more examples using smaller sample sizes. The probability 2 out of 10 coin flips are heads if the probability of heads is 0.3:</p>
<div class="sourceCode" id="cb21"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb21-1"><a href="disc-dist.html#cb21-1"></a><span class="kw">dbinom</span>(<span class="dt">x =</span> <span class="dv">2</span>, <span class="dt">size =</span> <span class="dv">10</span>, <span class="dt">prob =</span> <span class="fl">0.3</span>)</span></code></pre></div>
<pre><code>## [1] 0.2334744</code></pre>
<p>Here is a simulation from n = 10,000 random samples of size 10. <code>rbinom()</code> generates a random sample of numbers from the binomial distribution.</p>
<div class="sourceCode" id="cb23"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb23-1"><a href="disc-dist.html#cb23-1"></a><span class="kw">data.frame</span>(<span class="dt">cnt =</span> <span class="kw">rbinom</span>(<span class="dt">n =</span> <span class="dv">10000</span>, <span class="dt">size =</span> <span class="dv">10</span>, <span class="dt">prob =</span> <span class="fl">0.3</span>)) <span class="op">%&gt;%</span></span>
<span id="cb23-2"><a href="disc-dist.html#cb23-2"></a><span class="st">  </span><span class="kw">count</span>(cnt) <span class="op">%&gt;%</span></span>
<span id="cb23-3"><a href="disc-dist.html#cb23-3"></a><span class="st">  </span><span class="kw">ungroup</span>() <span class="op">%&gt;%</span></span>
<span id="cb23-4"><a href="disc-dist.html#cb23-4"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">pct =</span> n <span class="op">/</span><span class="st"> </span><span class="kw">sum</span>(n),</span>
<span id="cb23-5"><a href="disc-dist.html#cb23-5"></a>         <span class="dt">X_eq_x =</span> cnt <span class="op">==</span><span class="st"> </span><span class="dv">2</span>) <span class="op">%&gt;%</span></span>
<span id="cb23-6"><a href="disc-dist.html#cb23-6"></a><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> <span class="kw">as.factor</span>(cnt), <span class="dt">y =</span> n, <span class="dt">fill =</span> X_eq_x, <span class="dt">label =</span> pct)) <span class="op">+</span></span>
<span id="cb23-7"><a href="disc-dist.html#cb23-7"></a><span class="st">  </span><span class="kw">geom_col</span>(<span class="dt">alpha =</span> <span class="fl">0.8</span>) <span class="op">+</span></span>
<span id="cb23-8"><a href="disc-dist.html#cb23-8"></a><span class="st">  </span><span class="kw">scale_fill_mf</span>() <span class="op">+</span></span>
<span id="cb23-9"><a href="disc-dist.html#cb23-9"></a><span class="st">  </span><span class="kw">geom_label</span>(<span class="kw">aes</span>(<span class="dt">label =</span> <span class="kw">round</span>(pct, <span class="dv">2</span>)), <span class="dt">size =</span> <span class="dv">3</span>, <span class="dt">alpha =</span> <span class="fl">.6</span>) <span class="op">+</span></span>
<span id="cb23-10"><a href="disc-dist.html#cb23-10"></a><span class="st">  </span><span class="kw">theme_mf</span>() <span class="op">+</span></span>
<span id="cb23-11"><a href="disc-dist.html#cb23-11"></a><span class="st">  </span><span class="kw">theme</span>(<span class="dt">legend.position =</span> <span class="st">&quot;none&quot;</span>) <span class="op">+</span></span>
<span id="cb23-12"><a href="disc-dist.html#cb23-12"></a><span class="st">  </span><span class="kw">labs</span>(<span class="dt">title =</span> <span class="st">&quot;Binomial Distribution&quot;</span>, </span>
<span id="cb23-13"><a href="disc-dist.html#cb23-13"></a>       <span class="dt">subtitle =</span> <span class="kw">paste0</span>(</span>
<span id="cb23-14"><a href="disc-dist.html#cb23-14"></a>         <span class="st">&quot;P(X=2) successes in 10 trials when p = 0.3 is &quot;</span>, </span>
<span id="cb23-15"><a href="disc-dist.html#cb23-15"></a>         <span class="kw">round</span>(<span class="kw">dbinom</span>(<span class="dv">2</span>, <span class="dv">10</span>, <span class="fl">0.3</span>), <span class="dv">4</span>), <span class="st">&quot;.&quot;</span></span>
<span id="cb23-16"><a href="disc-dist.html#cb23-16"></a>       ),</span>
<span id="cb23-17"><a href="disc-dist.html#cb23-17"></a>       <span class="dt">x =</span> <span class="st">&quot;Successes&quot;</span>,</span>
<span id="cb23-18"><a href="disc-dist.html#cb23-18"></a>       <span class="dt">y =</span> <span class="st">&quot;Count&quot;</span>,</span>
<span id="cb23-19"><a href="disc-dist.html#cb23-19"></a>       <span class="dt">caption =</span> <span class="st">&quot;Simulation from n = 10,000 binomial random samples.&quot;</span>) </span></code></pre></div>
<p><img src="data-sci_files/figure-html/unnamed-chunk-14-1.png" width="480" /></p>
<p>What is the probability of &lt;=2 heads in 10 coin flips where probability of heads is 0.3? The cumulative probability is the sum of the first three bars in the simulation above. Function <code>pbinom()</code> calculates the <em>cumulative</em> binomial probability.</p>
<div class="sourceCode" id="cb24"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb24-1"><a href="disc-dist.html#cb24-1"></a><span class="kw">pbinom</span>(<span class="dt">q =</span> <span class="dv">2</span>, <span class="dt">size =</span> <span class="dv">10</span>, <span class="dt">prob =</span> <span class="fl">0.3</span>, <span class="dt">lower.tail =</span> <span class="ot">TRUE</span>)</span></code></pre></div>
<pre><code>## [1] 0.3827828</code></pre>
<p>What is the expected number of heads in 25 coin flips if the probability of heads is 0.3?</p>
<p>The expected value, <span class="math inline">\(\mu = np\)</span>, is 7.5. Here’s an empirical test from 10,000 samples.</p>
<div class="sourceCode" id="cb26"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb26-1"><a href="disc-dist.html#cb26-1"></a><span class="kw">mean</span>(<span class="kw">rbinom</span>(<span class="dt">n =</span> <span class="dv">10000</span>, <span class="dt">size =</span> <span class="dv">25</span>, <span class="dt">prob =</span> <span class="fl">.3</span>))</span></code></pre></div>
<pre><code>## [1] 7.4763</code></pre>
<p>The variance, <span class="math inline">\(\sigma^2 = np (1 - p)\)</span>, is 5.25. Here’s an empirical test.</p>
<div class="sourceCode" id="cb28"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb28-1"><a href="disc-dist.html#cb28-1"></a><span class="kw">var</span>(<span class="kw">rbinom</span>(<span class="dt">n =</span> <span class="dv">10000</span>, <span class="dt">size =</span> <span class="dv">25</span>, <span class="dt">prob =</span> <span class="fl">.3</span>))</span></code></pre></div>
<pre><code>## [1] 5.265115</code></pre>
<p>Suppose X and Y are independent random variables distributed <span class="math inline">\(X \sim Bin(10, .6)\)</span> and <span class="math inline">\(Y \sim Bin(10, .7)\)</span>. What is the probability that either variable is &lt;=4?</p>
<p>Let <span class="math inline">\(P(A) = P(X&lt;=4)\)</span> and <span class="math inline">\(P(B) = P(Y&lt;=4)\)</span>. Then <span class="math inline">\(P(A|B) = P(A) + P(B) - P(AB)\)</span>, and because the events are independent, <span class="math inline">\(P(AB) = P(A)P(B)\)</span>.</p>
<div class="sourceCode" id="cb30"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb30-1"><a href="disc-dist.html#cb30-1"></a>p_a &lt;-<span class="st"> </span><span class="kw">pbinom</span>(<span class="dt">q =</span> <span class="dv">4</span>, <span class="dt">size =</span> <span class="dv">10</span>, <span class="dt">prob =</span> <span class="fl">0.6</span>, <span class="dt">lower.tail =</span> <span class="ot">TRUE</span>)</span>
<span id="cb30-2"><a href="disc-dist.html#cb30-2"></a>p_b &lt;-<span class="st"> </span><span class="kw">pbinom</span>(<span class="dt">q =</span> <span class="dv">4</span>, <span class="dt">size =</span> <span class="dv">10</span>, <span class="dt">prob =</span> <span class="fl">0.7</span>, <span class="dt">lower.tail =</span> <span class="ot">TRUE</span>)</span>
<span id="cb30-3"><a href="disc-dist.html#cb30-3"></a>p_a <span class="op">+</span><span class="st"> </span>p_b <span class="op">-</span><span class="st"> </span>(p_a <span class="op">*</span><span class="st"> </span>p_b)</span></code></pre></div>
<pre><code>## [1] 0.2057164</code></pre>
<p>Here’s an empirical test.</p>
<div class="sourceCode" id="cb32"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb32-1"><a href="disc-dist.html#cb32-1"></a>df &lt;-<span class="st"> </span><span class="kw">data.frame</span>(</span>
<span id="cb32-2"><a href="disc-dist.html#cb32-2"></a>  <span class="dt">x =</span> <span class="kw">rbinom</span>(<span class="dv">10000</span>, <span class="dv">10</span>, <span class="fl">0.6</span>),</span>
<span id="cb32-3"><a href="disc-dist.html#cb32-3"></a>  <span class="dt">y =</span> <span class="kw">rbinom</span>(<span class="dv">10000</span>, <span class="dv">10</span>, <span class="fl">0.7</span>)</span>
<span id="cb32-4"><a href="disc-dist.html#cb32-4"></a>  )</span>
<span id="cb32-5"><a href="disc-dist.html#cb32-5"></a><span class="kw">mean</span>(<span class="kw">if_else</span>(df<span class="op">$</span>x <span class="op">&lt;=</span><span class="st"> </span><span class="dv">4</span> <span class="op">|</span><span class="st"> </span>df<span class="op">$</span>y <span class="op">&lt;=</span><span class="st"> </span><span class="dv">4</span>, <span class="dv">1</span>, <span class="dv">0</span>))</span></code></pre></div>
<pre><code>## [1] 0.2078</code></pre>
<p>A couple other points to remember:</p>
<ul>
<li>The Bernoulli distribution is a special case of the binomial with <span class="math inline">\(n = 1\)</span>.</li>
<li>The binomial distribution assumes independent trials. If you sample <em>without replacement from a finite population</em>, use the hypergeometric distribution.</li>
</ul>
</div>
<div id="poission" class="section level3">
<h3><span class="header-section-number">1.2.3</span> Poission</h3>
<p>If <span class="math inline">\(X\)</span> is the number of successes in <span class="math inline">\(n\)</span> (many) trials when the probability of success <span class="math inline">\(\lambda / n\)</span> is small, then <span class="math inline">\(X\)</span> is a random variable with a Poisson distribution <span class="math inline">\(X \sim Poisson(\lambda)\)</span></p>
<p><span class="math display">\[f(x;\lambda) = \frac{e^{-\lambda} \lambda^x}{x!} \hspace{1cm} x \in (0, 1, ...), \hspace{2mm} \lambda &gt; 0\]</span></p>
<p>with <span class="math inline">\(E(X)=\lambda\)</span> and <span class="math inline">\(Var(X) = \lambda\)</span>.</p>
<p>The Poisson likelihood function is</p>
<p><span class="math display">\[L(\lambda; x) = \prod_{i=1}^N f(x_i; \lambda) = \prod_{i=1}^N \frac{e^{-\lambda} \lambda^x_i}{x_i !} = \frac{e^{-n \lambda} \lambda^{\sum x_i}}{\prod x_i}.\]</span></p>
<p>The Poisson loglikelihood function is</p>
<p><span class="math display">\[l(\lambda; x) = \sum_{i=1}^N x_i \log \lambda - n \lambda.\]</span></p>
<p>One can show that the loglikelihood function is maximized at</p>
<p><span class="math display">\[\hat{\lambda} = \sum_{i=1}^N x_i / n.\]</span></p>
<p>Thus, for a Poisson sample, the MLE for <span class="math inline">\(\lambda\)</span> is just the sample mean.</p>
<p>Poisson sampling is used to model counts of events that occur randomly over a <em>fixed period of time</em>. Here is a simple analysis of data from a Poisson process. Data set <code>dat</code> contains frequencies of goal counts during the first round matches of the 2002 World Cup.</p>
<pre><code>##   goals freq
## 1     0   23
## 2     1   37
## 3     2   20
## 4     3   11
## 5     4    2
## 6     5    1
## 7     6    0
## 8     7    0
## 9     8    1</code></pre>
<p>The MLE of <span class="math inline">\(\lambda\)</span> from the Poisson distribution is the sample mean.</p>
<div class="sourceCode" id="cb35"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb35-1"><a href="disc-dist.html#cb35-1"></a>lambda &lt;-<span class="st"> </span><span class="kw">weighted.mean</span>(dat<span class="op">$</span>goals, dat<span class="op">$</span>freq)</span>
<span id="cb35-2"><a href="disc-dist.html#cb35-2"></a><span class="kw">print</span>(lambda)</span></code></pre></div>
<pre><code>## [1] 1.378947</code></pre>
<p>The 0.95 CI is <span class="math inline">\(\lambda \pm z_{.05/2} \sqrt{\lambda / n}\)</span></p>
<div class="sourceCode" id="cb37"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb37-1"><a href="disc-dist.html#cb37-1"></a>n &lt;-<span class="st"> </span><span class="kw">sum</span>(dat<span class="op">$</span>freq)</span>
<span id="cb37-2"><a href="disc-dist.html#cb37-2"></a>z &lt;-<span class="st"> </span><span class="kw">qnorm</span>(<span class="fl">0.975</span>)</span>
<span id="cb37-3"><a href="disc-dist.html#cb37-3"></a>se &lt;-<span class="st"> </span><span class="kw">sqrt</span>(lambda <span class="op">/</span><span class="st"> </span>n)</span>
<span id="cb37-4"><a href="disc-dist.html#cb37-4"></a><span class="kw">paste0</span>(<span class="st">&quot;[&quot;</span>, <span class="kw">round</span>(lambda <span class="op">-</span><span class="st"> </span>z<span class="op">*</span>se, <span class="dv">2</span>), <span class="st">&quot;, &quot;</span>, <span class="kw">round</span>(lambda <span class="op">+</span><span class="st"> </span>z<span class="op">*</span>se, <span class="dv">2</span>),<span class="st">&quot;]&quot;</span>)</span></code></pre></div>
<pre><code>## [1] &quot;[1.14, 1.62]&quot;</code></pre>
<p>The expected probability of scoring 2 goals in a match is <span class="math inline">\(\frac{e^{-1.38} 1.38^2}{2!} = 0.239\)</span>.</p>
<div class="sourceCode" id="cb39"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb39-1"><a href="disc-dist.html#cb39-1"></a><span class="kw">dpois</span>(<span class="dt">x =</span> <span class="dv">2</span>, <span class="dt">lambda =</span> lambda)</span></code></pre></div>
<pre><code>## [1] 0.2394397</code></pre>
<div class="sourceCode" id="cb41"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb41-1"><a href="disc-dist.html#cb41-1"></a>events &lt;-<span class="st"> </span><span class="dv">0</span><span class="op">:</span><span class="dv">10</span></span>
<span id="cb41-2"><a href="disc-dist.html#cb41-2"></a>density &lt;-<span class="st"> </span><span class="kw">dpois</span>(<span class="dt">x =</span> events, <span class="dt">lambda =</span> <span class="dv">3</span>)</span>
<span id="cb41-3"><a href="disc-dist.html#cb41-3"></a>prob &lt;-<span class="st"> </span><span class="kw">ppois</span>(<span class="dt">q =</span> events, <span class="dt">lambda =</span> <span class="dv">3</span>, <span class="dt">lower.tail =</span> <span class="ot">TRUE</span>)</span>
<span id="cb41-4"><a href="disc-dist.html#cb41-4"></a>df &lt;-<span class="st"> </span><span class="kw">data.frame</span>(events, density, prob)</span>
<span id="cb41-5"><a href="disc-dist.html#cb41-5"></a><span class="kw">ggplot</span>(df, <span class="kw">aes</span>(<span class="dt">x =</span> <span class="kw">factor</span>(events), <span class="dt">y =</span> density)) <span class="op">+</span></span>
<span id="cb41-6"><a href="disc-dist.html#cb41-6"></a><span class="st">  </span><span class="kw">geom_col</span>() <span class="op">+</span></span>
<span id="cb41-7"><a href="disc-dist.html#cb41-7"></a><span class="st">  </span><span class="kw">geom_text</span>(</span>
<span id="cb41-8"><a href="disc-dist.html#cb41-8"></a>    <span class="kw">aes</span>(<span class="dt">label =</span> <span class="kw">round</span>(density, <span class="dv">3</span>), <span class="dt">y =</span> density <span class="op">+</span><span class="st"> </span><span class="fl">0.01</span>),</span>
<span id="cb41-9"><a href="disc-dist.html#cb41-9"></a>    <span class="dt">position =</span> <span class="kw">position_dodge</span>(<span class="fl">0.9</span>),</span>
<span id="cb41-10"><a href="disc-dist.html#cb41-10"></a>    <span class="dt">size =</span> <span class="dv">3</span>,</span>
<span id="cb41-11"><a href="disc-dist.html#cb41-11"></a>    <span class="dt">vjust =</span> <span class="dv">0</span></span>
<span id="cb41-12"><a href="disc-dist.html#cb41-12"></a>  ) <span class="op">+</span></span>
<span id="cb41-13"><a href="disc-dist.html#cb41-13"></a><span class="st">  </span><span class="kw">geom_line</span>(</span>
<span id="cb41-14"><a href="disc-dist.html#cb41-14"></a>    <span class="dt">data =</span> df, </span>
<span id="cb41-15"><a href="disc-dist.html#cb41-15"></a>    <span class="kw">aes</span>(<span class="dt">x =</span> events, <span class="dt">y =</span> prob<span class="op">/</span><span class="dv">4</span>), </span>
<span id="cb41-16"><a href="disc-dist.html#cb41-16"></a>    <span class="dt">size =</span> <span class="dv">1</span>) <span class="op">+</span></span>
<span id="cb41-17"><a href="disc-dist.html#cb41-17"></a><span class="st">  </span><span class="kw">scale_y_continuous</span>(<span class="dt">sec.axis =</span> <span class="kw">sec_axis</span>(<span class="op">~</span>.<span class="op">*</span><span class="dv">4</span>, <span class="dt">name =</span> <span class="st">&quot;Cum Prob&quot;</span>)) <span class="op">+</span></span>
<span id="cb41-18"><a href="disc-dist.html#cb41-18"></a><span class="st">  </span><span class="kw">theme_mf</span>() <span class="op">+</span></span>
<span id="cb41-19"><a href="disc-dist.html#cb41-19"></a><span class="st">  </span><span class="kw">scale_fill_mf</span>() <span class="op">+</span></span>
<span id="cb41-20"><a href="disc-dist.html#cb41-20"></a><span class="st">  </span><span class="kw">labs</span>(<span class="dt">title =</span> <span class="st">&quot;PMF and CDF of Poisson Distribution&quot;</span>,</span>
<span id="cb41-21"><a href="disc-dist.html#cb41-21"></a>       <span class="dt">subtitle =</span> <span class="st">&quot;Poisson(3).&quot;</span>,</span>
<span id="cb41-22"><a href="disc-dist.html#cb41-22"></a>       <span class="dt">x =</span> <span class="st">&quot;Events (x)&quot;</span>,</span>
<span id="cb41-23"><a href="disc-dist.html#cb41-23"></a>       <span class="dt">y =</span> <span class="st">&quot;Density&quot;</span>)</span></code></pre></div>
<p><img src="data-sci_files/figure-html/unnamed-chunk-24-1.png" width="672" /></p>
<p>The expected probability of scoring 2 to 4 goals in a match is</p>
<div class="sourceCode" id="cb42"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb42-1"><a href="disc-dist.html#cb42-1"></a><span class="kw">sum</span>(<span class="kw">dpois</span>(<span class="dt">x =</span> <span class="kw">c</span>(<span class="dv">2</span><span class="op">:</span><span class="dv">4</span>), <span class="dt">lambda =</span> lambda))</span></code></pre></div>
<pre><code>## [1] 0.3874391</code></pre>
<p>Or, using the cumulative probability distribution,</p>
<div class="sourceCode" id="cb44"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb44-1"><a href="disc-dist.html#cb44-1"></a><span class="kw">ppois</span>(<span class="dt">q =</span> <span class="dv">4</span>, <span class="dt">lambda =</span> lambda) <span class="op">-</span><span class="st"> </span><span class="kw">ppois</span>(<span class="dt">q =</span> <span class="dv">1</span>, <span class="dt">lambda =</span> lambda)</span></code></pre></div>
<pre><code>## [1] 0.3874391</code></pre>
<p>How well does the Poisson distribution fit the 2002 World Cup data?</p>
<div class="sourceCode" id="cb46"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb46-1"><a href="disc-dist.html#cb46-1"></a>dat <span class="op">%&gt;%</span></span>
<span id="cb46-2"><a href="disc-dist.html#cb46-2"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">pred =</span> n <span class="op">*</span><span class="st"> </span><span class="kw">dpois</span>(<span class="dt">x =</span> goals, <span class="dt">lambda =</span> lambda)) <span class="op">%&gt;%</span></span>
<span id="cb46-3"><a href="disc-dist.html#cb46-3"></a><span class="st">  </span><span class="kw">rename</span>(<span class="dt">obs =</span> freq) <span class="op">%&gt;%</span></span>
<span id="cb46-4"><a href="disc-dist.html#cb46-4"></a><span class="st">  </span><span class="kw">pivot_longer</span>(<span class="dt">cols =</span> <span class="op">-</span>goals) <span class="op">%&gt;%</span></span>
<span id="cb46-5"><a href="disc-dist.html#cb46-5"></a><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> goals, <span class="dt">y =</span> value, <span class="dt">color =</span> name)) <span class="op">+</span></span>
<span id="cb46-6"><a href="disc-dist.html#cb46-6"></a><span class="st">  </span><span class="kw">geom_point</span>() <span class="op">+</span></span>
<span id="cb46-7"><a href="disc-dist.html#cb46-7"></a><span class="st">  </span><span class="kw">theme_mf</span>() <span class="op">+</span></span>
<span id="cb46-8"><a href="disc-dist.html#cb46-8"></a><span class="st">  </span><span class="kw">scale_color_mf</span>() <span class="op">+</span></span>
<span id="cb46-9"><a href="disc-dist.html#cb46-9"></a><span class="st">  </span><span class="kw">geom_smooth</span>(<span class="dt">se =</span> <span class="ot">FALSE</span>) <span class="op">+</span></span>
<span id="cb46-10"><a href="disc-dist.html#cb46-10"></a><span class="st">  </span><span class="kw">labs</span>(</span>
<span id="cb46-11"><a href="disc-dist.html#cb46-11"></a>    <span class="dt">title =</span> <span class="st">&quot;Poisson Dist: Observed vs Expected&quot;</span>,</span>
<span id="cb46-12"><a href="disc-dist.html#cb46-12"></a>    <span class="dt">color =</span> <span class="st">&quot;&quot;</span>,</span>
<span id="cb46-13"><a href="disc-dist.html#cb46-13"></a>    <span class="dt">y =</span> <span class="st">&quot;frequencey&quot;</span></span>
<span id="cb46-14"><a href="disc-dist.html#cb46-14"></a>  )</span></code></pre></div>
<p><img src="data-sci_files/figure-html/unnamed-chunk-27-1.png" width="672" /></p>
<p>It fits the data pretty good!</p>
<p><span class="math inline">\(Poison(\lambda) \rightarrow Bin(n, \pi)\)</span> when <span class="math inline">\(n\pi = \lambda\)</span> and <span class="math inline">\(n \rightarrow \infty\)</span> and <span class="math inline">\(\pi \rightarrow 0\)</span>. Because the Poisson is limit of the <span class="math inline">\(Bin(n, \pi)\)</span>, it is useful as an approximation to the binomial when <span class="math inline">\(n\)</span> is large (<span class="math inline">\(n&gt;=20\)</span>) and <span class="math inline">\(\pi\)</span> small (<span class="math inline">\(p&lt;=0.05\)</span>).</p>
<p>For example, suppose a baseball player has a p=.03 chance of hitting a homerun. What is the probability of X&gt;=20 homeruns in 500 at-bats? This is a binomial process because the sample size is fixed.</p>
<div class="sourceCode" id="cb47"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb47-1"><a href="disc-dist.html#cb47-1"></a><span class="kw">pbinom</span>(<span class="dt">q =</span> <span class="dv">20</span>, <span class="dt">size =</span> <span class="dv">500</span>, <span class="dt">prob =</span> <span class="fl">0.03</span>, <span class="dt">lower.tail =</span> <span class="ot">FALSE</span>)</span></code></pre></div>
<pre><code>## [1] 0.07979678</code></pre>
<p>But <span class="math inline">\(n\)</span> is large and <span class="math inline">\(\pi\)</span> is small, so the Poission distribution will work well too.</p>
<div class="sourceCode" id="cb49"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb49-1"><a href="disc-dist.html#cb49-1"></a><span class="kw">ppois</span>(<span class="dt">q =</span> <span class="dv">20</span>, <span class="dt">lambda =</span> <span class="fl">0.03</span> <span class="op">*</span><span class="st"> </span><span class="dv">500</span>, <span class="dt">lower.tail =</span> <span class="ot">FALSE</span>)</span></code></pre></div>
<pre><code>## [1] 0.08297091</code></pre>
<p>What is the distribution of successes from a sample of n = 50 when the probability of success is p = .03?</p>
<div class="sourceCode" id="cb51"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb51-1"><a href="disc-dist.html#cb51-1"></a>n =<span class="st"> </span><span class="dv">500</span></span>
<span id="cb51-2"><a href="disc-dist.html#cb51-2"></a>p =<span class="st"> </span><span class="fl">0.03</span></span>
<span id="cb51-3"><a href="disc-dist.html#cb51-3"></a>x =<span class="st"> </span><span class="dv">0</span><span class="op">:</span><span class="dv">30</span></span>
<span id="cb51-4"><a href="disc-dist.html#cb51-4"></a><span class="kw">data.frame</span>(</span>
<span id="cb51-5"><a href="disc-dist.html#cb51-5"></a>  <span class="dt">events =</span> x, </span>
<span id="cb51-6"><a href="disc-dist.html#cb51-6"></a>  <span class="dt">Poisson =</span> <span class="kw">dpois</span>(<span class="dt">x =</span> x, <span class="dt">lambda =</span> p <span class="op">*</span><span class="st"> </span>n),</span>
<span id="cb51-7"><a href="disc-dist.html#cb51-7"></a>  <span class="dt">Binomial =</span> <span class="kw">dbinom</span>(<span class="dt">x =</span> x, <span class="dt">size =</span> n, <span class="dt">p =</span> p)</span>
<span id="cb51-8"><a href="disc-dist.html#cb51-8"></a>) <span class="op">%&gt;%</span></span>
<span id="cb51-9"><a href="disc-dist.html#cb51-9"></a><span class="st">  </span><span class="kw">pivot_longer</span>(<span class="dt">cols =</span> <span class="op">-</span>events) <span class="op">%&gt;%</span></span>
<span id="cb51-10"><a href="disc-dist.html#cb51-10"></a><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> events, <span class="dt">y =</span> value, <span class="dt">color =</span> name)) <span class="op">+</span></span>
<span id="cb51-11"><a href="disc-dist.html#cb51-11"></a><span class="st">  </span><span class="kw">geom_point</span>() <span class="op">+</span></span>
<span id="cb51-12"><a href="disc-dist.html#cb51-12"></a><span class="st">  </span><span class="kw">theme_mf</span>() <span class="op">+</span></span>
<span id="cb51-13"><a href="disc-dist.html#cb51-13"></a><span class="st">  </span><span class="kw">scale_color_mf</span>() <span class="op">+</span></span>
<span id="cb51-14"><a href="disc-dist.html#cb51-14"></a><span class="st">  </span><span class="kw">labs</span>(<span class="dt">title =</span> <span class="st">&quot;Poisson(15) vs. Bin(500, .03)&quot;</span>,</span>
<span id="cb51-15"><a href="disc-dist.html#cb51-15"></a>       <span class="dt">subtitle =</span> <span class="st">&quot;Poisson approximation to binomial.&quot;</span>,</span>
<span id="cb51-16"><a href="disc-dist.html#cb51-16"></a>       <span class="dt">x =</span> <span class="st">&quot;Events&quot;</span>,</span>
<span id="cb51-17"><a href="disc-dist.html#cb51-17"></a>       <span class="dt">y =</span> <span class="st">&quot;Density&quot;</span>,</span>
<span id="cb51-18"><a href="disc-dist.html#cb51-18"></a>       <span class="dt">color =</span> <span class="st">&quot;&quot;</span>)</span></code></pre></div>
<p><img src="data-sci_files/figure-html/unnamed-chunk-30-1.png" width="480" /></p>
<p>When the observed variance is greater than <span class="math inline">\(\lambda\)</span> (overdispersion), the Negative Binomial distribution can be used instead of Poisson.</p>
<p>Suppose the probability that a drug produces a certain side effect is p = = 0.1% and n = 1,000 patients in a clinical trial receive the drug. What is the probability 0 people experience the side effect?</p>
<p>The expected value is np, 1. The probability of measuring 0 when the expected value is 1 is <code>dpois(x = 0, lambda = 1000 * .001) =</code> 0.3678794.</p>
<p><img src="data-sci_files/figure-html/unnamed-chunk-31-1.png" width="480" /></p>
</div>
<div id="multinomial" class="section level3">
<h3><span class="header-section-number">1.2.4</span> Multinomial</h3>
<p>If <span class="math inline">\(X = (X_1, X_2, \cdots, X_k)\)</span> are the counts of successful events in <span class="math inline">\(n\)</span> identical and independent trials of success probabilities <span class="math inline">\(\pi = (\pi_1, \pi_2, \cdots, \pi_k)\)</span>, then <span class="math inline">\(X\)</span> is a random variable with a multinomial distribution <span class="math inline">\(X \sim Mult(n,\pi)\)</span></p>
<p><span class="math display">\[f(x; n, \pi) = \frac{n!}{x_{1}! x_{2}! \cdots x_{k}!} \pi^{x_1} \pi^{x_2} \cdots \pi^{x_k} \hspace{1cm} x \in \{0, 1, ..., n \}, \hspace{2mm} \pi \in [0, 1]\]</span></p>
<p>with expected values vector <span class="math inline">\(E(X_j) = n\pi_j\)</span> and covariance matrix</p>
<p><span class="math display">\[Var(X) = \begin{bmatrix}n\pi_{1}(1-\pi_{1}) &amp; -n\pi_{1}\pi_{2} &amp; \cdots &amp; -n\pi_{1}\pi_{k}\\
-n\pi_{1}\pi_{2} &amp; n\pi_{2}(1-\pi_{2}) &amp; \cdots &amp; -n\pi_{2}\pi_{k}\\
\vdots &amp; \vdots &amp; \ddots &amp; \vdots\\
-n\pi_{1}\pi_{k} &amp; -n\pi_{2}\pi_{k} &amp; \cdots &amp; n\pi_{k}(1-\pi_{k})
\end{bmatrix}\]</span></p>
<p>so <span class="math inline">\(Var(X_j) = n \pi_j (1 - \pi_j)\)</span> and <span class="math inline">\(cov(X_j, X_k) = -n \pi_j \pi_k\)</span>.</p>
<p>The individual components of a multinomial random vector are binomial and have a binomial distribution, <span class="math inline">\(X_i = Bin(n, \pi_i)\)</span>. Binomial is a special case of multinomial for k = 2.</p>
<p>Suppose a city population is 20% black, 15% Hispanic, and 65% other. From a random sample of <span class="math inline">\(n = 12\)</span> persons, what is the probability of 4 black and 8 other?</p>
<p><span class="math display">\[f(x;\pi) = \frac{12!}{4! 0! 8!} (0.20)^4 (0.15)^0 (0.65)^8 = 0.0252\]</span></p>
<p>Function <code>dmultinom()</code> calculates the multinomial probability.</p>
<div class="sourceCode" id="cb52"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb52-1"><a href="disc-dist.html#cb52-1"></a><span class="kw">dmultinom</span>(<span class="dt">x =</span> <span class="kw">c</span>(<span class="dv">4</span>, <span class="dv">0</span>, <span class="dv">8</span>), <span class="dt">prob =</span> <span class="kw">c</span>(<span class="fl">0.20</span>, <span class="fl">0.15</span>, <span class="fl">0.65</span>))</span></code></pre></div>
<pre><code>## [1] 0.025</code></pre>
<p>To calculate the probability of <em>&lt;= 1</em> black, combine Hispanic and other, then sum the probability of black = 1 and black = 2.</p>
<p><span class="math display">\[f(x;\pi) = \frac{12!}{0! 12!} (0.20)^0 (0.80)^{12} + \frac{12!}{1! 11!} (0.20)^1 (0.80)^{11} = 0.2748\]</span></p>
<div class="sourceCode" id="cb54"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb54-1"><a href="disc-dist.html#cb54-1"></a><span class="kw">dmultinom</span>(<span class="dt">x =</span> <span class="kw">c</span>(<span class="dv">0</span>, <span class="dv">12</span>), <span class="dt">prob =</span> <span class="kw">c</span>(<span class="fl">0.20</span>, <span class="fl">0.80</span>)) <span class="op">+</span><span class="st"> </span></span>
<span id="cb54-2"><a href="disc-dist.html#cb54-2"></a><span class="st">  </span><span class="kw">dmultinom</span>(<span class="dt">x =</span> <span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">11</span>), <span class="dt">prob =</span> <span class="kw">c</span>(<span class="fl">0.20</span>, <span class="fl">0.80</span>))</span></code></pre></div>
<pre><code>## [1] 0.27</code></pre>
</div>
<div id="negative-binomial" class="section level3">
<h3><span class="header-section-number">1.2.5</span> Negative-Binomial</h3>
<p>If <span class="math inline">\(X\)</span> is the count of failure events ocurring prior to reaching <span class="math inline">\(r\)</span> successful events in a sequence of Bernouli trias of success probability <span class="math inline">\(p\)</span>, then <span class="math inline">\(X\)</span> is a random variable with a negative-binomial distribution <span class="math inline">\(X \sim NB(r, p)\)</span>. The probability of <span class="math inline">\(X = x\)</span> failures prior to <span class="math inline">\(r\)</span> successes is</p>
<p><span class="math display">\[f(x;r, p) = {{x + r - 1} \choose {r - 1}} p^r (1-p)^{x}.\]</span></p>
<p>with <span class="math inline">\(E(X) = r (1 - p) / p\)</span> and <span class="math inline">\(Var(X) = r (1-p) / p^2\)</span>.</p>
<p>When the data has overdispersion, model the data with the negative-binomial distribution instead of Poission.</p>
<div id="examples" class="section level4 unnumbered">
<h4>Examples</h4>
<p>An oil company has a <span class="math inline">\(p = 0.20\)</span> chance of striking oil when drilling a well. What is the probability the company drills <span class="math inline">\(x + r = 7\)</span> wells to strike oil <span class="math inline">\(r = 3\)</span> times? Note that the question is formulated as counting total events, <span class="math inline">\(x + r = 7\)</span>, so translate it to total <em>failed</em> events, <span class="math inline">\(x = 4\)</span>.</p>
<p><span class="math display">\[f(x;r, p) = {{4 + 3 - 1} \choose {3 - 1}} (0.20)^3 (1 - 0.20)^4 = 0.049.\]</span></p>
<p>Function <code>dnbinom()</code> calculates the negative-binomial probability. Parameter <code>x</code> equals the number of failures, <span class="math inline">\(x - r\)</span>.</p>
<div class="sourceCode" id="cb56"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb56-1"><a href="disc-dist.html#cb56-1"></a><span class="kw">dnbinom</span>(<span class="dt">x =</span> <span class="dv">4</span>, <span class="dt">size =</span> <span class="dv">3</span>, <span class="dt">prob =</span> <span class="fl">0.2</span>)</span></code></pre></div>
<pre><code>## [1] 0.049</code></pre>
<p>The expected number of failures prior to 3 successes is <span class="math inline">\(E(X) = 3 (1 - 0.20) / 0.20 = 12\)</span> with variance <span class="math inline">\(Var(X) = 3 (1 - 0.20) / 0.20^2 = 60\)</span>. Confirm this with a simulation from n = 10,000 random samples using <code>rnbinom()</code>.</p>
<div class="sourceCode" id="cb58"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb58-1"><a href="disc-dist.html#cb58-1"></a>my_dat &lt;-<span class="st"> </span><span class="kw">rnbinom</span>(<span class="dt">n =</span> <span class="dv">10000</span>, <span class="dt">size =</span> <span class="dv">3</span>, <span class="dt">prob =</span> <span class="fl">0.20</span>)</span>
<span id="cb58-2"><a href="disc-dist.html#cb58-2"></a><span class="kw">mean</span>(my_dat)</span></code></pre></div>
<pre><code>## [1] 12</code></pre>
<div class="sourceCode" id="cb60"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb60-1"><a href="disc-dist.html#cb60-1"></a><span class="kw">var</span>(my_dat)</span></code></pre></div>
<pre><code>## [1] 61</code></pre>
<p><img src="data-sci_files/figure-html/unnamed-chunk-36-1.png" width="576" /></p>
</div>
</div>
<div id="geometric" class="section level3">
<h3><span class="header-section-number">1.2.6</span> Geometric</h3>
<p>If <span class="math inline">\(X\)</span> is the count of Bernoulli trials of success probability <span class="math inline">\(p\)</span> required to achieve the first successful event, then <span class="math inline">\(X\)</span> is a random variable with a geometric distribution <span class="math inline">\(X \sim G(p)\)</span>. The probability of <span class="math inline">\(X = x\)</span> trials is</p>
<p><span class="math display">\[f(x; p) = p(1-p)^{x-1}.\]</span></p>
<p>with <span class="math inline">\(E(X)=\frac{{n}}{{p}}\)</span> and <span class="math inline">\(Var(X) = \frac{(1-p)}{p^2}\)</span>. The probability of <span class="math inline">\(X&lt;=n\)</span> trials is</p>
<p><span class="math display">\[F(X=n) = 1 - (1-p)^n.\]</span></p>
<div id="examples-1" class="section level4 unnumbered">
<h4>Examples</h4>
<p>What is the probability a marketer encounters x = 3 people on the street who did not attend a sporting event before the first success if the population probability is p = 0.20?</p>
<p><span class="math display">\[f(4; 0.20) = 0.20(1-0.20)^{4-1} = 0.102.\]</span></p>
<p>Function <code>dgeom()</code> calculates the geometric distribution probability. Parameter <code>x</code> is the number of <em>failures</em>, not the number of trials.</p>
<div class="sourceCode" id="cb62"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb62-1"><a href="disc-dist.html#cb62-1"></a><span class="kw">dgeom</span>(<span class="dt">x =</span> <span class="dv">3</span>, <span class="dt">prob =</span> <span class="fl">0.20</span>)</span></code></pre></div>
<pre><code>## [1] 0.1</code></pre>
<div class="sourceCode" id="cb64"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb64-1"><a href="disc-dist.html#cb64-1"></a><span class="kw">data.frame</span>(<span class="dt">cnt =</span> <span class="kw">rgeom</span>(<span class="dt">n =</span> <span class="dv">10000</span>, <span class="dt">prob =</span> <span class="fl">0.20</span>)) <span class="op">%&gt;%</span></span>
<span id="cb64-2"><a href="disc-dist.html#cb64-2"></a><span class="st">  </span><span class="kw">count</span>(cnt) <span class="op">%&gt;%</span></span>
<span id="cb64-3"><a href="disc-dist.html#cb64-3"></a><span class="st">  </span><span class="kw">top_n</span>(<span class="dt">n =</span> <span class="dv">15</span>, <span class="dt">wt =</span> n) <span class="op">%&gt;%</span></span>
<span id="cb64-4"><a href="disc-dist.html#cb64-4"></a><span class="st">  </span><span class="kw">ungroup</span>() <span class="op">%&gt;%</span></span>
<span id="cb64-5"><a href="disc-dist.html#cb64-5"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">pct =</span> <span class="kw">round</span>(n <span class="op">/</span><span class="st"> </span><span class="kw">sum</span>(n), <span class="dv">3</span>),</span>
<span id="cb64-6"><a href="disc-dist.html#cb64-6"></a>         <span class="dt">X_eq_x =</span> cnt <span class="op">==</span><span class="st"> </span><span class="dv">3</span>) <span class="op">%&gt;%</span></span>
<span id="cb64-7"><a href="disc-dist.html#cb64-7"></a><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> <span class="kw">as.factor</span>(cnt), <span class="dt">y =</span> n, <span class="dt">fill =</span> X_eq_x, <span class="dt">label =</span> pct)) <span class="op">+</span></span>
<span id="cb64-8"><a href="disc-dist.html#cb64-8"></a><span class="st">  </span><span class="kw">geom_col</span>(<span class="dt">alpha =</span> <span class="fl">0.8</span>) <span class="op">+</span></span>
<span id="cb64-9"><a href="disc-dist.html#cb64-9"></a><span class="st">  </span><span class="kw">scale_fill_mf</span>() <span class="op">+</span></span>
<span id="cb64-10"><a href="disc-dist.html#cb64-10"></a><span class="st">  </span><span class="kw">geom_text</span>(<span class="dt">size =</span> <span class="dv">3</span>) <span class="op">+</span></span>
<span id="cb64-11"><a href="disc-dist.html#cb64-11"></a><span class="st">  </span><span class="kw">theme_mf</span>() <span class="op">+</span></span>
<span id="cb64-12"><a href="disc-dist.html#cb64-12"></a><span class="st">  </span><span class="kw">theme</span>(<span class="dt">legend.position =</span> <span class="st">&quot;none&quot;</span>) <span class="op">+</span></span>
<span id="cb64-13"><a href="disc-dist.html#cb64-13"></a><span class="st">  </span><span class="kw">labs</span>(<span class="dt">title =</span> <span class="st">&quot;Distribution of trials prior to first success&quot;</span>,</span>
<span id="cb64-14"><a href="disc-dist.html#cb64-14"></a>       <span class="dt">subtitle =</span> <span class="kw">paste</span>(<span class="st">&quot;P(X = 3) | X ~ G(.2) = &quot;</span>, <span class="kw">round</span>(<span class="kw">dgeom</span>(<span class="dv">2</span>, <span class="fl">.2</span>), <span class="dv">3</span>)),</span>
<span id="cb64-15"><a href="disc-dist.html#cb64-15"></a>       <span class="dt">x =</span> <span class="st">&quot;Unsuccessful trials&quot;</span>,</span>
<span id="cb64-16"><a href="disc-dist.html#cb64-16"></a>       <span class="dt">y =</span> <span class="st">&quot;Count&quot;</span>,</span>
<span id="cb64-17"><a href="disc-dist.html#cb64-17"></a>       <span class="dt">caption =</span> <span class="st">&quot;simulation of n = 10,000 samples from geometric dist.&quot;</span>) </span></code></pre></div>
<p><img src="data-sci_files/figure-html/unnamed-chunk-38-1.png" width="480" /></p>
<p>What is the probability the marketer fails to find someone who attended a game in x &lt;= 5 trials before finding someone who attended a game on the sixth trial when the population probability is p = 0.20?</p>
<div class="sourceCode" id="cb65"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb65-1"><a href="disc-dist.html#cb65-1"></a>p =<span class="st"> </span><span class="fl">0.20</span></span>
<span id="cb65-2"><a href="disc-dist.html#cb65-2"></a>n =<span class="st"> </span><span class="dv">5</span></span>
<span id="cb65-3"><a href="disc-dist.html#cb65-3"></a><span class="co"># exact</span></span>
<span id="cb65-4"><a href="disc-dist.html#cb65-4"></a><span class="kw">pgeom</span>(<span class="dt">q =</span> n, <span class="dt">prob =</span> p, <span class="dt">lower.tail =</span> <span class="ot">TRUE</span>)</span></code></pre></div>
<pre><code>## [1] 0.74</code></pre>
<div class="sourceCode" id="cb67"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb67-1"><a href="disc-dist.html#cb67-1"></a><span class="co"># simulated</span></span>
<span id="cb67-2"><a href="disc-dist.html#cb67-2"></a><span class="kw">mean</span>(<span class="kw">rgeom</span>(<span class="dt">n =</span> <span class="dv">10000</span>, <span class="dt">prob =</span> p) <span class="op">&lt;=</span><span class="st"> </span>n)</span></code></pre></div>
<pre><code>## [1] 0.74</code></pre>
<p><img src="data-sci_files/figure-html/unnamed-chunk-40-1.png" width="480" /></p>
<p>What is the probability the marketer fails to find someone who attended a game on x &gt;= 5 trials before finding someone who attended a game on the next trial?</p>
<div class="sourceCode" id="cb69"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb69-1"><a href="disc-dist.html#cb69-1"></a>p =<span class="st"> </span><span class="fl">0.20</span></span>
<span id="cb69-2"><a href="disc-dist.html#cb69-2"></a>n =<span class="st"> </span><span class="dv">5</span></span>
<span id="cb69-3"><a href="disc-dist.html#cb69-3"></a><span class="co"># exact</span></span>
<span id="cb69-4"><a href="disc-dist.html#cb69-4"></a><span class="kw">pgeom</span>(<span class="dt">q =</span> n, <span class="dt">prob =</span> p, <span class="dt">lower.tail =</span> <span class="ot">FALSE</span>)</span></code></pre></div>
<pre><code>## [1] 0.26</code></pre>
<div class="sourceCode" id="cb71"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb71-1"><a href="disc-dist.html#cb71-1"></a><span class="co"># simulated</span></span>
<span id="cb71-2"><a href="disc-dist.html#cb71-2"></a><span class="kw">mean</span>(<span class="kw">rgeom</span>(<span class="dt">n =</span> <span class="dv">10000</span>, <span class="dt">prob =</span> p) <span class="op">&gt;</span><span class="st"> </span>n)</span></code></pre></div>
<pre><code>## [1] 0.26</code></pre>
<p><img src="data-sci_files/figure-html/unnamed-chunk-42-1.png" width="480" /></p>
<p>The expected number of trials to achieve the first success is <code>1 / 0.20 =</code> 5, <code>Var(X) = (1 - 0.20) / 0.20^2 =</code> 20?</p>
<div class="sourceCode" id="cb73"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb73-1"><a href="disc-dist.html#cb73-1"></a>p =<span class="st"> </span><span class="fl">0.20</span></span>
<span id="cb73-2"><a href="disc-dist.html#cb73-2"></a><span class="co"># mean</span></span>
<span id="cb73-3"><a href="disc-dist.html#cb73-3"></a><span class="co"># exact</span></span>
<span id="cb73-4"><a href="disc-dist.html#cb73-4"></a><span class="dv">1</span> <span class="op">/</span><span class="st"> </span>p</span></code></pre></div>
<pre><code>## [1] 5</code></pre>
<div class="sourceCode" id="cb75"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb75-1"><a href="disc-dist.html#cb75-1"></a><span class="co"># simulated</span></span>
<span id="cb75-2"><a href="disc-dist.html#cb75-2"></a><span class="kw">mean</span>(<span class="kw">rgeom</span>(<span class="dt">n =</span> <span class="dv">10000</span>, <span class="dt">prob =</span> p)) <span class="op">+</span><span class="st"> </span><span class="dv">1</span></span></code></pre></div>
<pre><code>## [1] 5</code></pre>
<div class="sourceCode" id="cb77"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb77-1"><a href="disc-dist.html#cb77-1"></a><span class="co"># Variance</span></span>
<span id="cb77-2"><a href="disc-dist.html#cb77-2"></a><span class="co"># exact</span></span>
<span id="cb77-3"><a href="disc-dist.html#cb77-3"></a>(<span class="dv">1</span> <span class="op">-</span><span class="st"> </span>p) <span class="op">/</span><span class="st"> </span>p<span class="op">^</span><span class="dv">2</span></span></code></pre></div>
<pre><code>## [1] 20</code></pre>
<div class="sourceCode" id="cb79"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb79-1"><a href="disc-dist.html#cb79-1"></a><span class="co"># simulated</span></span>
<span id="cb79-2"><a href="disc-dist.html#cb79-2"></a><span class="kw">var</span>(<span class="kw">rgeom</span>(<span class="dt">n =</span> <span class="dv">100000</span>, <span class="dt">prob =</span> p))</span></code></pre></div>
<pre><code>## [1] 20</code></pre>
</div>
</div>
<div id="hypergeometric" class="section level3">
<h3><span class="header-section-number">1.2.7</span> Hypergeometric</h3>
<p>If <span class="math inline">\(X\)</span> is the count of successful events in a sample of size <span class="math inline">\(n\)</span> <em>without replacement</em> from a population of size <span class="math inline">\(N\)</span> containing <span class="math inline">\(K\)</span> successes and <span class="math inline">\(N-K\)</span> non-successes, then <span class="math inline">\(X\)</span> is a random variable with a hypergeometric distribution</p>
<p><span class="math display">\[f(x|N,K,n) = \frac{{{K}\choose{k}}{{N-K}\choose{n-k}}}{{N}\choose{n}}.\]</span></p>
<p>with <span class="math inline">\(E(X) = n\frac{K}{N}\)</span> and <span class="math inline">\(Var(X) = n \frac{K}{N} \cdot \frac{N-n}{N} \cdot \frac{N-K}{N-1}\)</span>.</p>
<p>The formula follows from the frequency table of the possible outcomes.</p>
<table>
<thead>
<tr class="header">
<th></th>
<th>Sampled</th>
<th>Not Sampled</th>
<th>Total</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>success</td>
<td>k</td>
<td>K-k</td>
<td>K</td>
</tr>
<tr class="even">
<td>non-success</td>
<td>n-k</td>
<td>(N-K)-(n-k)</td>
<td>N-K</td>
</tr>
<tr class="odd">
<td>Total</td>
<td>n</td>
<td>N-n</td>
<td>N</td>
</tr>
</tbody>
</table>
<p>If <span class="math inline">\(X\)</span> is the count of successful events in a sample of size <span class="math inline">\(k\)</span> <em>without replacement</em> from a population containing <span class="math inline">\(M\)</span> successes and <span class="math inline">\(N\)</span> non-successes, then <span class="math inline">\(X\)</span> is a random variable with a hypergeometric distribution</p>
<p><span class="math display">\[f(x|m,n,k) = \frac{{{m}\choose{x}}{{n}\choose{k-x}}}{{m+n}\choose{k}}.\]</span></p>
<p>with <span class="math inline">\(E(X)=k\frac{m}{m+n}\)</span> and <span class="math inline">\(Var(X) = k\frac{m}{m+n}\cdot\frac{m+n-k}{m+n}\cdot\frac{n}{m+n-1}\)</span>.</p>
<p><code>phyper</code> returns the cumulative probability (percentile) <code>p</code> at the specified value (quantile) <code>q</code>. <code>qhyper</code> returns the value (quantile) <code>q</code> at the specified cumulative probability (percentile) <code>p</code>.</p>
<div id="example" class="section level4 unnumbered">
<h4>Example</h4>
<p>What is the probability of selecting <span class="math inline">\(X = 14\)</span> red marbles from a sample of <span class="math inline">\(k = 20\)</span> taken from an urn containing <span class="math inline">\(m = 70\)</span> red marbles and <span class="math inline">\(n = 30\)</span> green marbles?</p>
<p>Function <code>dhyper()</code> calculates the hypergeometric probability.</p>
<div class="sourceCode" id="cb81"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb81-1"><a href="disc-dist.html#cb81-1"></a>x =<span class="st"> </span><span class="dv">14</span></span>
<span id="cb81-2"><a href="disc-dist.html#cb81-2"></a>m =<span class="st"> </span><span class="dv">70</span></span>
<span id="cb81-3"><a href="disc-dist.html#cb81-3"></a>n =<span class="st"> </span><span class="dv">30</span></span>
<span id="cb81-4"><a href="disc-dist.html#cb81-4"></a>k =<span class="st"> </span><span class="dv">20</span></span>
<span id="cb81-5"><a href="disc-dist.html#cb81-5"></a></span>
<span id="cb81-6"><a href="disc-dist.html#cb81-6"></a><span class="kw">dhyper</span>(<span class="dt">x =</span> x, <span class="dt">m =</span> m, <span class="dt">n =</span> n, <span class="dt">k =</span> k)</span></code></pre></div>
<pre><code>## [1] 0.21</code></pre>
<p>The expected value is 14 and variance is 3.39.</p>
<p><img src="data-sci_files/figure-html/unnamed-chunk-45-1.png" width="480" /></p>
<p>The hypergeometric random variable is similar to the binomial random variable except that it applies to situations of sampling <em>without</em> replacement from a small population. As the population size increases, sampling without replacement converges to sampling <em>with</em> replacement, and the hypergeometric distribution converges to the binomial. What if the total population size is 250? 500? 1000?</p>
<p><img src="data-sci_files/figure-html/unnamed-chunk-46-1.png" width="480" /></p>
</div>
</div>
<div id="gamma" class="section level3">
<h3><span class="header-section-number">1.2.8</span> Gamma</h3>
<p>If <span class="math inline">\(X\)</span> is the interval until the <span class="math inline">\(\alpha^{th}\)</span> successful event when the average interval is <span class="math inline">\(\theta\)</span>, then <span class="math inline">\(X\)</span> is a random variable with a gamma distribution <span class="math inline">\(X \sim \Gamma(\alpha, \theta)\)</span>. The probability of an interval of <span class="math inline">\(X = x\)</span> is</p>
<p><span class="math display">\[f(x; \alpha, \theta) = \frac{1}{\Gamma(\alpha)\theta^\alpha}x^{\alpha-1}e^{-x/\theta}.\]</span></p>
<p>where <span class="math inline">\(\Gamma(\alpha) = (1 - \alpha)!\)</span> with <span class="math inline">\(E(X) = \alpha \theta\)</span> and <span class="math inline">\(Var(X) = \alpha \theta^2\)</span>.</p>
<div id="examples-2" class="section level4 unnumbered">
<h4>Examples</h4>
<p>On average, someone sends a money order once per 15 minutes (<span class="math inline">\(\theta = .25\)</span>). What is the probability someone sends <span class="math inline">\(\alpha = 10\)</span> money orders in less than <span class="math inline">\(x = 3\)</span> hours?*</p>
<div class="sourceCode" id="cb83"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb83-1"><a href="disc-dist.html#cb83-1"></a>theta =<span class="st"> </span><span class="fl">0.25</span></span>
<span id="cb83-2"><a href="disc-dist.html#cb83-2"></a>alpha =<span class="st"> </span><span class="dv">10</span></span>
<span id="cb83-3"><a href="disc-dist.html#cb83-3"></a><span class="kw">pgamma</span>(<span class="dt">q =</span> <span class="dv">3</span>, <span class="dt">shape =</span> alpha, <span class="dt">scale =</span> <span class="fl">0.25</span>)</span></code></pre></div>
<pre><code>## [1] 0.76</code></pre>
<div class="sourceCode" id="cb85"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb85-1"><a href="disc-dist.html#cb85-1"></a><span class="kw">data.frame</span>(<span class="dt">x =</span> <span class="dv">0</span><span class="op">:</span><span class="dv">1000</span> <span class="op">/</span><span class="st"> </span><span class="dv">100</span>, <span class="dt">prob =</span> <span class="kw">pgamma</span>(<span class="dt">q =</span> <span class="dv">0</span><span class="op">:</span><span class="dv">1000</span> <span class="op">/</span><span class="st"> </span><span class="dv">100</span>, <span class="dt">shape =</span> alpha, <span class="dt">scale =</span> theta, <span class="dt">lower.tail =</span> <span class="ot">TRUE</span>)) <span class="op">%&gt;%</span></span>
<span id="cb85-2"><a href="disc-dist.html#cb85-2"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">Interval =</span> <span class="kw">ifelse</span>(x <span class="op">&gt;=</span><span class="st"> </span><span class="dv">0</span> <span class="op">&amp;</span><span class="st"> </span>x <span class="op">&lt;=</span><span class="st"> </span><span class="dv">3</span>, <span class="st">&quot;0 to 3&quot;</span>, <span class="st">&quot;other&quot;</span>)) <span class="op">%&gt;%</span></span>
<span id="cb85-3"><a href="disc-dist.html#cb85-3"></a><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> x, <span class="dt">y =</span> prob, <span class="dt">fill =</span> Interval)) <span class="op">+</span></span>
<span id="cb85-4"><a href="disc-dist.html#cb85-4"></a><span class="st">  </span><span class="kw">geom_area</span>(<span class="dt">alpha =</span> <span class="fl">0.9</span>) <span class="op">+</span></span>
<span id="cb85-5"><a href="disc-dist.html#cb85-5"></a><span class="st">  </span><span class="kw">theme_mf</span>() <span class="op">+</span></span>
<span id="cb85-6"><a href="disc-dist.html#cb85-6"></a><span class="st">  </span><span class="kw">scale_fill_mf</span>() <span class="op">+</span></span>
<span id="cb85-7"><a href="disc-dist.html#cb85-7"></a><span class="st">  </span><span class="kw">labs</span>(<span class="dt">title =</span> <span class="st">&quot;X ~ Gam(alpha = 10, theta = .25)&quot;</span>,</span>
<span id="cb85-8"><a href="disc-dist.html#cb85-8"></a>       <span class="dt">subtitle =</span> <span class="st">&quot;Probability of 10 events in X hours when the mean time to an event is .25 hours.&quot;</span>,</span>
<span id="cb85-9"><a href="disc-dist.html#cb85-9"></a>       <span class="dt">x =</span> <span class="st">&quot;Interval (x)&quot;</span>,</span>
<span id="cb85-10"><a href="disc-dist.html#cb85-10"></a>       <span class="dt">y =</span> <span class="st">&quot;pgamma&quot;</span>) </span></code></pre></div>
<p><img src="data-sci_files/figure-html/unnamed-chunk-48-1.png" width="672" /></p>
</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="principles.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="cont-dist.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="assets/gitbook-2.6.7/js/app.min.js"></script>
<script src="assets/gitbook-2.6.7/js/lunr.js"></script>
<script src="assets/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="assets/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="assets/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="assets/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="assets/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="assets/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="assets/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["data-sci.pdf", "data-sci.epub"],
"toc": {
"collapse": "subsection"
},
"toolbar": {
"position": "static"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
