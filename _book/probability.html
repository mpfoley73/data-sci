<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 1 Probability | My Data Science Notes</title>
  <meta name="description" content="This is a compendium of notes from classes, tutorials, etc. that I reference from time to time." />
  <meta name="generator" content="bookdown 0.21 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 1 Probability | My Data Science Notes" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="This is a compendium of notes from classes, tutorials, etc. that I reference from time to time." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 1 Probability | My Data Science Notes" />
  
  <meta name="twitter:description" content="This is a compendium of notes from classes, tutorials, etc. that I reference from time to time." />
  

<meta name="author" content="Michael Foley" />


<meta name="date" content="2020-12-24" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="index.html"/>
<link rel="next" href="contingency-tables.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<script src="libs/accessible-code-block-0.0.1/empty-anchor.js"></script>
<link href="libs/anchor-sections-1.0/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0/anchor-sections.js"></script>


<style type="text/css">
code.sourceCode > span { display: inline-block; line-height: 1.25; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">My Data Science Notes</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Intro</a></li>
<li class="chapter" data-level="1" data-path="probability.html"><a href="probability.html"><i class="fa fa-check"></i><b>1</b> Probability</a><ul>
<li class="chapter" data-level="1.1" data-path="probability.html"><a href="probability.html#principles"><i class="fa fa-check"></i><b>1.1</b> Principles</a></li>
<li class="chapter" data-level="1.2" data-path="probability.html"><a href="probability.html#disc_dist"><i class="fa fa-check"></i><b>1.2</b> Discrete Distributions</a><ul>
<li class="chapter" data-level="1.2.1" data-path="probability.html"><a href="probability.html#bernoulli"><i class="fa fa-check"></i><b>1.2.1</b> Bernoulli</a></li>
<li class="chapter" data-level="1.2.2" data-path="probability.html"><a href="probability.html#binomial"><i class="fa fa-check"></i><b>1.2.2</b> Binomial</a></li>
<li class="chapter" data-level="1.2.3" data-path="probability.html"><a href="probability.html#poission"><i class="fa fa-check"></i><b>1.2.3</b> Poission</a></li>
<li class="chapter" data-level="1.2.4" data-path="probability.html"><a href="probability.html#multinomial"><i class="fa fa-check"></i><b>1.2.4</b> Multinomial</a></li>
<li class="chapter" data-level="1.2.5" data-path="probability.html"><a href="probability.html#negative-binomial"><i class="fa fa-check"></i><b>1.2.5</b> Negative-Binomial</a></li>
<li class="chapter" data-level="1.2.6" data-path="probability.html"><a href="probability.html#geometric"><i class="fa fa-check"></i><b>1.2.6</b> Geometric</a></li>
<li class="chapter" data-level="1.2.7" data-path="probability.html"><a href="probability.html#hypergeometric"><i class="fa fa-check"></i><b>1.2.7</b> Hypergeometric</a></li>
<li class="chapter" data-level="1.2.8" data-path="probability.html"><a href="probability.html#gamma"><i class="fa fa-check"></i><b>1.2.8</b> Gamma</a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="probability.html"><a href="probability.html#cont_dist"><i class="fa fa-check"></i><b>1.3</b> Continuous Distributions</a><ul>
<li class="chapter" data-level="1.3.1" data-path="probability.html"><a href="probability.html#normal"><i class="fa fa-check"></i><b>1.3.1</b> Normal</a></li>
<li class="chapter" data-level="1.3.2" data-path="probability.html"><a href="probability.html#chi-squared"><i class="fa fa-check"></i><b>1.3.2</b> Chi-Squared</a></li>
</ul></li>
<li class="chapter" data-level="1.4" data-path="probability.html"><a href="probability.html#join-distributions"><i class="fa fa-check"></i><b>1.4</b> Join Distributions</a></li>
<li class="chapter" data-level="1.5" data-path="probability.html"><a href="probability.html#likelihood"><i class="fa fa-check"></i><b>1.5</b> Likelihood</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="contingency-tables.html"><a href="contingency-tables.html"><i class="fa fa-check"></i><b>2</b> Contingency Tables</a><ul>
<li class="chapter" data-level="2.1" data-path="contingency-tables.html"><a href="contingency-tables.html#one-way-tables"><i class="fa fa-check"></i><b>2.1</b> One-Way Tables</a><ul>
<li class="chapter" data-level="2.1.1" data-path="contingency-tables.html"><a href="contingency-tables.html#one-proportion-z-test"><i class="fa fa-check"></i><b>2.1.1</b> One-Proportion <em>Z</em>-Test</a></li>
<li class="chapter" data-level="2.1.2" data-path="contingency-tables.html"><a href="contingency-tables.html#exact-binomial-test"><i class="fa fa-check"></i><b>2.1.2</b> Exact Binomial Test</a></li>
<li class="chapter" data-level="2.1.3" data-path="contingency-tables.html"><a href="contingency-tables.html#chi-squared-goodness-of-fit-test"><i class="fa fa-check"></i><b>2.1.3</b> Chi-Squared Goodness-of-Fit Test</a></li>
<li class="chapter" data-level="2.1.4" data-path="contingency-tables.html"><a href="contingency-tables.html#g-test"><i class="fa fa-check"></i><b>2.1.4</b> G-Test</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="contingency-tables.html"><a href="contingency-tables.html#two-way-tables"><i class="fa fa-check"></i><b>2.2</b> Two-Way Tables</a><ul>
<li class="chapter" data-level="2.2.1" data-path="contingency-tables.html"><a href="contingency-tables.html#proportion-difference-z-test"><i class="fa fa-check"></i><b>2.2.1</b> Proportion Difference <em>Z</em>-Test</a></li>
<li class="chapter" data-level="2.2.2" data-path="contingency-tables.html"><a href="contingency-tables.html#fisher-exact-test"><i class="fa fa-check"></i><b>2.2.2</b> Fisher Exact Test</a></li>
<li class="chapter" data-level="2.2.3" data-path="contingency-tables.html"><a href="contingency-tables.html#chi-square-independence-test"><i class="fa fa-check"></i><b>2.2.3</b> Chi-Square Independence Test</a></li>
<li class="chapter" data-level="2.2.4" data-path="contingency-tables.html"><a href="contingency-tables.html#residuals-analysis"><i class="fa fa-check"></i><b>2.2.4</b> Residuals Analysis</a></li>
<li class="chapter" data-level="2.2.5" data-path="contingency-tables.html"><a href="contingency-tables.html#difference-in-proportions"><i class="fa fa-check"></i><b>2.2.5</b> Difference in Proportions</a></li>
<li class="chapter" data-level="2.2.6" data-path="contingency-tables.html"><a href="contingency-tables.html#relative-risk"><i class="fa fa-check"></i><b>2.2.6</b> Relative Risk</a></li>
<li class="chapter" data-level="2.2.7" data-path="contingency-tables.html"><a href="contingency-tables.html#odds-ratio"><i class="fa fa-check"></i><b>2.2.7</b> Odds Ratio</a></li>
<li class="chapter" data-level="2.2.8" data-path="contingency-tables.html"><a href="contingency-tables.html#partitioning-chi-square"><i class="fa fa-check"></i><b>2.2.8</b> Partitioning Chi-Square</a></li>
<li class="chapter" data-level="2.2.9" data-path="contingency-tables.html"><a href="contingency-tables.html#correlation"><i class="fa fa-check"></i><b>2.2.9</b> Correlation</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="contingency-tables.html"><a href="contingency-tables.html#k-way-tables"><i class="fa fa-check"></i><b>2.3</b> K-Way Tables</a><ul>
<li class="chapter" data-level="2.3.1" data-path="contingency-tables.html"><a href="contingency-tables.html#odds-ratio-1"><i class="fa fa-check"></i><b>2.3.1</b> Odds Ratio</a></li>
<li class="chapter" data-level="2.3.2" data-path="contingency-tables.html"><a href="contingency-tables.html#chi-square-independence-test-1"><i class="fa fa-check"></i><b>2.3.2</b> Chi-Square Independence Test</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="analysis-of-variance.html"><a href="analysis-of-variance.html"><i class="fa fa-check"></i><b>3</b> Analysis of Variance</a><ul>
<li class="chapter" data-level="3.1" data-path="analysis-of-variance.html"><a href="analysis-of-variance.html#one-way-anova"><i class="fa fa-check"></i><b>3.1</b> One-Way ANOVA</a><ul>
<li class="chapter" data-level="" data-path="analysis-of-variance.html"><a href="analysis-of-variance.html#checking-conditions"><i class="fa fa-check"></i>Checking Conditions</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="analysis-of-variance.html"><a href="analysis-of-variance.html#handling-non-constant-variance"><i class="fa fa-check"></i><b>3.2</b> Handling Non-Constant Variance</a><ul>
<li class="chapter" data-level="3.2.1" data-path="analysis-of-variance.html"><a href="analysis-of-variance.html#example"><i class="fa fa-check"></i><b>3.2.1</b> Example</a></li>
<li class="chapter" data-level="3.2.2" data-path="analysis-of-variance.html"><a href="analysis-of-variance.html#multiple-variance-comparison-f-test"><i class="fa fa-check"></i><b>3.2.2</b> Multiple Variance Comparison F Test</a></li>
<li class="chapter" data-level="3.2.3" data-path="analysis-of-variance.html"><a href="analysis-of-variance.html#example-1"><i class="fa fa-check"></i><b>3.2.3</b> Example</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="analysis-of-variance.html"><a href="analysis-of-variance.html#references"><i class="fa fa-check"></i><b>3.3</b> References</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="continuous-analysis.html"><a href="continuous-analysis.html"><i class="fa fa-check"></i><b>4</b> Continuous Variable Analysis</a><ul>
<li class="chapter" data-level="4.1" data-path="continuous-analysis.html"><a href="continuous-analysis.html#correlation-1"><i class="fa fa-check"></i><b>4.1</b> Correlation</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="part-2-supervised-machine-learning.html"><a href="part-2-supervised-machine-learning.html"><i class="fa fa-check"></i>PART 2: Supervised Machine Learning</a><ul>
<li class="chapter" data-level="4.2" data-path="part-2-supervised-machine-learning.html"><a href="part-2-supervised-machine-learning.html#linear-regression-model"><i class="fa fa-check"></i><b>4.2</b> Linear Regression Model</a></li>
<li class="chapter" data-level="4.3" data-path="part-2-supervised-machine-learning.html"><a href="part-2-supervised-machine-learning.html#parameter-estimation"><i class="fa fa-check"></i><b>4.3</b> Parameter Estimation</a></li>
<li class="chapter" data-level="4.4" data-path="part-2-supervised-machine-learning.html"><a href="part-2-supervised-machine-learning.html#model-assumptions"><i class="fa fa-check"></i><b>4.4</b> Model Assumptions</a><ul>
<li class="chapter" data-level="4.4.1" data-path="part-2-supervised-machine-learning.html"><a href="part-2-supervised-machine-learning.html#linearity"><i class="fa fa-check"></i><b>4.4.1</b> Linearity</a></li>
<li class="chapter" data-level="4.4.2" data-path="part-2-supervised-machine-learning.html"><a href="part-2-supervised-machine-learning.html#multicollinearity"><i class="fa fa-check"></i><b>4.4.2</b> Multicollinearity</a></li>
<li class="chapter" data-level="4.4.3" data-path="part-2-supervised-machine-learning.html"><a href="part-2-supervised-machine-learning.html#normality-1"><i class="fa fa-check"></i><b>4.4.3</b> Normality</a></li>
<li class="chapter" data-level="4.4.4" data-path="part-2-supervised-machine-learning.html"><a href="part-2-supervised-machine-learning.html#equal-variances-1"><i class="fa fa-check"></i><b>4.4.4</b> Equal Variances</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="part-2-supervised-machine-learning.html"><a href="part-2-supervised-machine-learning.html#prediction"><i class="fa fa-check"></i><b>4.5</b> Prediction</a></li>
<li class="chapter" data-level="4.6" data-path="part-2-supervised-machine-learning.html"><a href="part-2-supervised-machine-learning.html#inference"><i class="fa fa-check"></i><b>4.6</b> Inference</a><ul>
<li class="chapter" data-level="4.6.1" data-path="part-2-supervised-machine-learning.html"><a href="part-2-supervised-machine-learning.html#t-test"><i class="fa fa-check"></i><b>4.6.1</b> <em>t</em>-Test</a></li>
<li class="chapter" data-level="4.6.2" data-path="part-2-supervised-machine-learning.html"><a href="part-2-supervised-machine-learning.html#f-test"><i class="fa fa-check"></i><b>4.6.2</b> <em>F</em>-Test</a></li>
</ul></li>
<li class="chapter" data-level="4.7" data-path="part-2-supervised-machine-learning.html"><a href="part-2-supervised-machine-learning.html#interpretation"><i class="fa fa-check"></i><b>4.7</b> Interpretation</a></li>
<li class="chapter" data-level="4.8" data-path="part-2-supervised-machine-learning.html"><a href="part-2-supervised-machine-learning.html#model-validation"><i class="fa fa-check"></i><b>4.8</b> Model Validation</a><ul>
<li class="chapter" data-level="4.8.1" data-path="part-2-supervised-machine-learning.html"><a href="part-2-supervised-machine-learning.html#accuracy-metrics"><i class="fa fa-check"></i><b>4.8.1</b> Accuracy Metrics</a></li>
<li class="chapter" data-level="4.8.2" data-path="part-2-supervised-machine-learning.html"><a href="part-2-supervised-machine-learning.html#cross-validation"><i class="fa fa-check"></i><b>4.8.2</b> Cross-Validation</a></li>
<li class="chapter" data-level="4.8.3" data-path="part-2-supervised-machine-learning.html"><a href="part-2-supervised-machine-learning.html#gain-curve"><i class="fa fa-check"></i><b>4.8.3</b> Gain Curve</a></li>
</ul></li>
<li class="chapter" data-level="4.9" data-path="part-2-supervised-machine-learning.html"><a href="part-2-supervised-machine-learning.html#ols-reference"><i class="fa fa-check"></i><b>4.9</b> OLS Reference</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="generalized-linear-models.html"><a href="generalized-linear-models.html"><i class="fa fa-check"></i><b>5</b> Generalized Linear Models</a><ul>
<li class="chapter" data-level="5.1" data-path="generalized-linear-models.html"><a href="generalized-linear-models.html#logistic-regression"><i class="fa fa-check"></i><b>5.1</b> Logistic Regression</a></li>
<li class="chapter" data-level="5.2" data-path="generalized-linear-models.html"><a href="generalized-linear-models.html#multinomial-logistic-regression"><i class="fa fa-check"></i><b>5.2</b> Multinomial Logistic Regression</a></li>
<li class="chapter" data-level="5.3" data-path="generalized-linear-models.html"><a href="generalized-linear-models.html#ordinal-logistic-regression"><i class="fa fa-check"></i><b>5.3</b> Ordinal Logistic Regression</a><ul>
<li class="chapter" data-level="5.3.1" data-path="generalized-linear-models.html"><a href="generalized-linear-models.html#assumptions"><i class="fa fa-check"></i><b>5.3.1</b> Assumptions</a></li>
<li class="chapter" data-level="5.3.2" data-path="generalized-linear-models.html"><a href="generalized-linear-models.html#modeling"><i class="fa fa-check"></i><b>5.3.2</b> Modeling</a></li>
<li class="chapter" data-level="5.3.3" data-path="generalized-linear-models.html"><a href="generalized-linear-models.html#case-study"><i class="fa fa-check"></i><b>5.3.3</b> Case Study</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="generalized-linear-models.html"><a href="generalized-linear-models.html#poisson-regression"><i class="fa fa-check"></i><b>5.4</b> Poisson Regression</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="multivariate-statistical-analysis.html"><a href="multivariate-statistical-analysis.html"><i class="fa fa-check"></i><b>6</b> Multivariate Statistical Analysis</a><ul>
<li class="chapter" data-level="6.1" data-path="multivariate-statistical-analysis.html"><a href="multivariate-statistical-analysis.html#background"><i class="fa fa-check"></i><b>6.1</b> Background</a></li>
<li class="chapter" data-level="6.2" data-path="multivariate-statistical-analysis.html"><a href="multivariate-statistical-analysis.html#manova"><i class="fa fa-check"></i><b>6.2</b> MANOVA</a></li>
<li class="chapter" data-level="6.3" data-path="multivariate-statistical-analysis.html"><a href="multivariate-statistical-analysis.html#repeated-measures"><i class="fa fa-check"></i><b>6.3</b> Repeated Measures</a></li>
<li class="chapter" data-level="6.4" data-path="multivariate-statistical-analysis.html"><a href="multivariate-statistical-analysis.html#lda"><i class="fa fa-check"></i><b>6.4</b> LDA</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="regularization.html"><a href="regularization.html"><i class="fa fa-check"></i><b>7</b> Regularization</a><ul>
<li class="chapter" data-level="7.1" data-path="regularization.html"><a href="regularization.html#ridge"><i class="fa fa-check"></i><b>7.1</b> Ridge</a></li>
<li class="chapter" data-level="7.2" data-path="regularization.html"><a href="regularization.html#lasso"><i class="fa fa-check"></i><b>7.2</b> Lasso</a></li>
<li class="chapter" data-level="7.3" data-path="regularization.html"><a href="regularization.html#elastic-net"><i class="fa fa-check"></i><b>7.3</b> Elastic Net</a></li>
<li class="chapter" data-level="" data-path="regularization.html"><a href="regularization.html#model-summary"><i class="fa fa-check"></i>Model Summary</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="decision-trees.html"><a href="decision-trees.html"><i class="fa fa-check"></i><b>8</b> Decision Trees</a><ul>
<li class="chapter" data-level="8.1" data-path="decision-trees.html"><a href="decision-trees.html#classification-tree"><i class="fa fa-check"></i><b>8.1</b> Classification Tree</a><ul>
<li class="chapter" data-level="8.1.1" data-path="decision-trees.html"><a href="decision-trees.html#measuring-performance"><i class="fa fa-check"></i><b>8.1.1</b> Measuring Performance</a></li>
<li class="chapter" data-level="8.1.2" data-path="decision-trees.html"><a href="decision-trees.html#training-with-caret"><i class="fa fa-check"></i><b>8.1.2</b> Training with Caret</a></li>
</ul></li>
<li class="chapter" data-level="8.2" data-path="decision-trees.html"><a href="decision-trees.html#regression-tree"><i class="fa fa-check"></i><b>8.2</b> Regression Tree</a><ul>
<li class="chapter" data-level="8.2.1" data-path="decision-trees.html"><a href="decision-trees.html#training-with-caret-1"><i class="fa fa-check"></i><b>8.2.1</b> Training with Caret</a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="decision-trees.html"><a href="decision-trees.html#bagged-trees"><i class="fa fa-check"></i><b>8.3</b> Bagged Trees</a><ul>
<li class="chapter" data-level="8.3.1" data-path="decision-trees.html"><a href="decision-trees.html#bagged-classification-tree"><i class="fa fa-check"></i><b>8.3.1</b> Bagged Classification Tree</a></li>
<li class="chapter" data-level="8.3.2" data-path="decision-trees.html"><a href="decision-trees.html#bagging-regression-tree"><i class="fa fa-check"></i><b>8.3.2</b> Bagging Regression Tree</a></li>
</ul></li>
<li class="chapter" data-level="8.4" data-path="decision-trees.html"><a href="decision-trees.html#random-forests"><i class="fa fa-check"></i><b>8.4</b> Random Forests</a></li>
<li class="chapter" data-level="8.5" data-path="decision-trees.html"><a href="decision-trees.html#gradient-boosting"><i class="fa fa-check"></i><b>8.5</b> Gradient Boosting</a></li>
<li class="chapter" data-level="8.6" data-path="decision-trees.html"><a href="decision-trees.html#summary"><i class="fa fa-check"></i><b>8.6</b> Summary</a><ul>
<li class="chapter" data-level="8.6.1" data-path="decision-trees.html"><a href="decision-trees.html#classification-trees"><i class="fa fa-check"></i><b>8.6.1</b> Classification Trees</a></li>
<li class="chapter" data-level="8.6.2" data-path="decision-trees.html"><a href="decision-trees.html#regression-trees"><i class="fa fa-check"></i><b>8.6.2</b> Regression Trees</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="9" data-path="non-linear-models.html"><a href="non-linear-models.html"><i class="fa fa-check"></i><b>9</b> Non-linear Models</a><ul>
<li class="chapter" data-level="9.1" data-path="non-linear-models.html"><a href="non-linear-models.html#splines"><i class="fa fa-check"></i><b>9.1</b> Splines</a></li>
<li class="chapter" data-level="9.2" data-path="non-linear-models.html"><a href="non-linear-models.html#mars"><i class="fa fa-check"></i><b>9.2</b> MARS</a></li>
<li class="chapter" data-level="9.3" data-path="non-linear-models.html"><a href="non-linear-models.html#gam"><i class="fa fa-check"></i><b>9.3</b> GAM</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="support-vector-machines.html"><a href="support-vector-machines.html"><i class="fa fa-check"></i><b>10</b> Support Vector Machines</a><ul>
<li class="chapter" data-level="10.1" data-path="support-vector-machines.html"><a href="support-vector-machines.html#maximal-margin-classifier"><i class="fa fa-check"></i><b>10.1</b> Maximal Margin Classifier</a></li>
<li class="chapter" data-level="10.2" data-path="support-vector-machines.html"><a href="support-vector-machines.html#support-vector-classifier"><i class="fa fa-check"></i><b>10.2</b> Support Vector Classifier</a></li>
<li class="chapter" data-level="10.3" data-path="support-vector-machines.html"><a href="support-vector-machines.html#support-vector-machines-1"><i class="fa fa-check"></i><b>10.3</b> Support Vector Machines</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="part-3-unupervised-machine-learning.html"><a href="part-3-unupervised-machine-learning.html"><i class="fa fa-check"></i>PART 3: Unupervised Machine Learning</a><ul>
<li class="chapter" data-level="10.4" data-path="part-3-unupervised-machine-learning.html"><a href="part-3-unupervised-machine-learning.html#exploratory-factor-analysis"><i class="fa fa-check"></i><b>10.4</b> Exploratory Factor Analysis</a></li>
<li class="chapter" data-level="10.5" data-path="part-3-unupervised-machine-learning.html"><a href="part-3-unupervised-machine-learning.html#confirmatory-factor-analysis"><i class="fa fa-check"></i><b>10.5</b> Confirmatory Factor Analysis</a></li>
<li class="chapter" data-level="10.6" data-path="part-3-unupervised-machine-learning.html"><a href="part-3-unupervised-machine-learning.html#pca"><i class="fa fa-check"></i><b>10.6</b> PCA</a></li>
<li class="chapter" data-level="10.7" data-path="part-3-unupervised-machine-learning.html"><a href="part-3-unupervised-machine-learning.html#t-sne"><i class="fa fa-check"></i><b>10.7</b> t-SNE</a></li>
<li class="chapter" data-level="10.8" data-path="part-3-unupervised-machine-learning.html"><a href="part-3-unupervised-machine-learning.html#svd"><i class="fa fa-check"></i><b>10.8</b> SVD</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="cluster-analysis.html"><a href="cluster-analysis.html"><i class="fa fa-check"></i><b>11</b> Cluster Analysis</a><ul>
<li class="chapter" data-level="11.1" data-path="cluster-analysis.html"><a href="cluster-analysis.html#k-means"><i class="fa fa-check"></i><b>11.1</b> K-Means</a></li>
<li class="chapter" data-level="11.2" data-path="cluster-analysis.html"><a href="cluster-analysis.html#hca"><i class="fa fa-check"></i><b>11.2</b> HCA</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="text-mining.html"><a href="text-mining.html"><i class="fa fa-check"></i><b>12</b> Text Mining</a><ul>
<li class="chapter" data-level="12.1" data-path="text-mining.html"><a href="text-mining.html#topic-modeling"><i class="fa fa-check"></i><b>12.1</b> Topic Modeling</a><ul>
<li class="chapter" data-level="12.1.1" data-path="text-mining.html"><a href="text-mining.html#lda-1"><i class="fa fa-check"></i><b>12.1.1</b> LDA</a></li>
<li class="chapter" data-level="12.1.2" data-path="text-mining.html"><a href="text-mining.html#stm"><i class="fa fa-check"></i><b>12.1.2</b> STM</a></li>
</ul></li>
<li class="chapter" data-level="12.2" data-path="text-mining.html"><a href="text-mining.html#sentiment-analysis"><i class="fa fa-check"></i><b>12.2</b> Sentiment Analysis</a><ul>
<li class="chapter" data-level="12.2.1" data-path="text-mining.html"><a href="text-mining.html#n-grams"><i class="fa fa-check"></i><b>12.2.1</b> N-Grams</a></li>
<li class="chapter" data-level="12.2.2" data-path="text-mining.html"><a href="text-mining.html#converting-to-and-from-non-tidy-formats"><i class="fa fa-check"></i><b>12.2.2</b> Converting to and from non-tidy formats</a></li>
<li class="chapter" data-level="12.2.3" data-path="text-mining.html"><a href="text-mining.html#example-14"><i class="fa fa-check"></i><b>12.2.3</b> Example</a></li>
</ul></li>
<li class="chapter" data-level="12.3" data-path="text-mining.html"><a href="text-mining.html#text-classification-modeling"><i class="fa fa-check"></i><b>12.3</b> Text Classification Modeling</a></li>
<li class="chapter" data-level="12.4" data-path="text-mining.html"><a href="text-mining.html#named-entity-recognition"><i class="fa fa-check"></i><b>12.4</b> Named Entity Recognition</a></li>
<li class="chapter" data-level="12.5" data-path="text-mining.html"><a href="text-mining.html#tidy-text"><i class="fa fa-check"></i><b>12.5</b> Tidy Text</a></li>
<li class="chapter" data-level="12.6" data-path="text-mining.html"><a href="text-mining.html#appendix-regular-expressions"><i class="fa fa-check"></i><b>12.6</b> Appendix: Regular Expressions</a><ul>
<li class="chapter" data-level="12.6.1" data-path="text-mining.html"><a href="text-mining.html#base-r"><i class="fa fa-check"></i><b>12.6.1</b> Base R</a></li>
<li class="chapter" data-level="12.6.2" data-path="text-mining.html"><a href="text-mining.html#stringr"><i class="fa fa-check"></i><b>12.6.2</b> stringr</a></li>
<li class="chapter" data-level="12.6.3" data-path="text-mining.html"><a href="text-mining.html#regular-expressions"><i class="fa fa-check"></i><b>12.6.3</b> Regular Expressions</a></li>
</ul></li>
<li class="chapter" data-level="12.7" data-path="text-mining.html"><a href="text-mining.html#appendix-tidytext"><i class="fa fa-check"></i><b>12.7</b> Appendix: tidytext</a></li>
<li class="chapter" data-level="12.8" data-path="text-mining.html"><a href="text-mining.html#appendix-tm"><i class="fa fa-check"></i><b>12.8</b> Appendix: tm</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="survival-analysis.html"><a href="survival-analysis.html"><i class="fa fa-check"></i><b>13</b> Survival Analysis</a><ul>
<li class="chapter" data-level="13.1" data-path="survival-analysis.html"><a href="survival-analysis.html#basic-concepts"><i class="fa fa-check"></i><b>13.1</b> Basic Concepts</a></li>
<li class="chapter" data-level="13.2" data-path="survival-analysis.html"><a href="survival-analysis.html#survival-curve-estimation"><i class="fa fa-check"></i><b>13.2</b> Survival Curve Estimation</a><ul>
<li class="chapter" data-level="13.2.1" data-path="survival-analysis.html"><a href="survival-analysis.html#kaplan-meier"><i class="fa fa-check"></i><b>13.2.1</b> Kaplan-Meier</a></li>
<li class="chapter" data-level="13.2.2" data-path="survival-analysis.html"><a href="survival-analysis.html#weibull"><i class="fa fa-check"></i><b>13.2.2</b> Weibull</a></li>
<li class="chapter" data-level="13.2.3" data-path="survival-analysis.html"><a href="survival-analysis.html#cox"><i class="fa fa-check"></i><b>13.2.3</b> Cox</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="" data-path="appendix.html"><a href="appendix.html"><i class="fa fa-check"></i>Appendix</a><ul>
<li class="chapter" data-level="" data-path="appendix.html"><a href="appendix.html#publishing-to-bookdown"><i class="fa fa-check"></i>Publishing to BookDown</a></li>
<li class="chapter" data-level="" data-path="appendix.html"><a href="appendix.html#shiny-apps"><i class="fa fa-check"></i>Shiny Apps</a></li>
<li class="chapter" data-level="" data-path="appendix.html"><a href="appendix.html#packages"><i class="fa fa-check"></i>Packages</a><ul>
<li class="chapter" data-level="" data-path="appendix.html"><a href="appendix.html#create-a-package"><i class="fa fa-check"></i>Create a package</a></li>
<li class="chapter" data-level="13.2.4" data-path="appendix.html"><a href="appendix.html#document-functions-with-roxygen"><i class="fa fa-check"></i><b>13.2.4</b> Document Functions with roxygen</a></li>
<li class="chapter" data-level="" data-path="appendix.html"><a href="appendix.html#create-data"><i class="fa fa-check"></i>Create Data</a></li>
<li class="chapter" data-level="" data-path="appendix.html"><a href="appendix.html#create-vignette"><i class="fa fa-check"></i>Create Vignette</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="" data-path="references-1.html"><a href="references-1.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">My Data Science Notes</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="probability" class="section level1">
<h1><span class="header-section-number">Chapter 1</span> Probability</h1>
<div id="principles" class="section level2">
<h2><span class="header-section-number">1.1</span> Principles</h2>
<p>Here are three rules that come up all the time.</p>
<ul>
<li><p><span class="math inline">\(Pr(A \cup B) = Pr(A)+Pr(B) - Pr(AB)\)</span>. This rule generalizes to
<span class="math inline">\(Pr(A \cup B \cup C)=Pr(A)+Pr(B)+Pr(C)-Pr(AB)-Pr(AC)-Pr(BC)+Pr(ABC)\)</span>.</p></li>
<li><p><span class="math inline">\(Pr(A|B) = \frac{P(AB)}{P(B)}\)</span></p></li>
<li><p>If A and B are independent, <span class="math inline">\(Pr(A \cap B) = Pr(A)Pr(B)\)</span>, and <span class="math inline">\(Pr(A|B)=Pr(A)\)</span>.</p></li>
</ul>
<p>Uniform distributions on finite sample spaces often reduce to counting the elements of <em>A</em> and the sample space <em>S</em>, a process called combinatorics. Here are three important combinatorial rules.</p>
<p><strong>Multiplication Rule</strong>. <span class="math inline">\(|S|=|S_1 |⋯|S_k|\)</span>.</p>
<p><em>How many outcomes are possible from a sequence of 4 coin flips and 2 rolls of a die?</em>
<span class="math inline">\(|S|=|S_1| \cdot |S_2| \dots |S_6| = 2 \cdot 2 \cdot 2 \cdot 2 \cdot 6 \cdot 6 = 288\)</span>.</p>
<p><em>How many subsets are possible from a set of n=10 elements?</em>
In each subset, each element is either included or not, so there are <span class="math inline">\(2^n = 1024\)</span> subsets.</p>
<p><em>How many subsets are possible from a set of n=10 elements taken k at a time with replacement?</em>
Each experiment has <span class="math inline">\(n\)</span> possible outcomes and is repeated <span class="math inline">\(k\)</span> times, so there are <span class="math inline">\(n^k\)</span> subsets.</p>
<p><strong>Permutations</strong>. The number of <em>ordered</em> arrangements (permutations) of a set of <span class="math inline">\(|S|=n\)</span> items taken <span class="math inline">\(k\)</span> at a time <em>without</em> replacement has <span class="math inline">\(n(n-1) \dots (n-k+1)\)</span> subsets because each draw is one of k experiments with decreasing number of possible outcomes.</p>
<p><span class="math display">\[_nP_k = \frac{n!}{(n-k)!}\]</span></p>
<p>Notice that if <span class="math inline">\(k=0\)</span> then there is 1 permutation; if <span class="math inline">\(k=1\)</span> then there are <span class="math inline">\(n\)</span> permutations; if <span class="math inline">\(k=n\)</span> then there are <span class="math inline">\(n!\)</span> permutations.</p>
<p><em>How many ways can you distribute 4 jackets among 4 people?</em>
<span class="math inline">\(_nP_k = \frac{4!}{(4-4)!} = 4! = 24\)</span></p>
<p><em>How many ways can you distribute 4 jackets among 2 people?</em>
<span class="math inline">\(_nP_k = \frac{4!}{(4-2)!} = 12\)</span></p>
<p><strong>Subsets</strong>. The number of <em>unordered</em> arrangements (combinations) of a set of <span class="math inline">\(|S|=n\)</span> items taken <span class="math inline">\(k\)</span> at a time <em>without</em> replacement has</p>
<p><span class="math display">\[_nC_k = {n \choose k} = \frac{n!}{k!(n-k)!}\]</span></p>
<p>combinations and is called the binomial coefficient. The binomial coefficient is the number of different subsets. Notice that if k=0 then there is 1 subset; if k=1 then there are n subsets; if k=n then there is 1 subset. The connection with the permutation rule is that there are <span class="math inline">\(n!/(n-k)!\)</span> permutations and each permutation has <span class="math inline">\(k!\)</span> permutations.</p>
<p><em>How many subsets of 7 people can be taken from a set of 12 persons?</em>
<span class="math inline">\(_{12}C_7 = {12 \choose 7} = \frac{12!}{7!(12-7)!} = 792\)</span></p>
<p><em>If you are dealt five cards, what is the probability of getting a “full-house” hand containing three kings and two aces (KKKAA)?</em>
<span class="math display">\[P(F) = \frac{{4 \choose 3} {4 \choose 2}}{{52 \choose 5}}\]</span></p>
<p><strong>Distinguishable permutations</strong>. The number of <em>unordered</em> arrangements (distinguishable permutations) of a set of <span class="math inline">\(|S|=n\)</span> items in which <span class="math inline">\(n_1\)</span> are of one type, <span class="math inline">\(n_2\)</span> are of another type, etc., is</p>
<p><span class="math display">\[{n \choose {n_1, n_2, \dots, n_k}} = \frac{n!}{n_{1}! n_{2}! \dots n_{k}!}\]</span></p>
<p><em>How many ordered arrangements are there of the letters in the word PHILIPPINES?</em> There are n=11 objects. <span class="math inline">\(|P|=n_1=3\)</span>; <span class="math inline">\(|H|=n_2=1\)</span>; <span class="math inline">\(|I|=n_3=3\)</span>; <span class="math inline">\(|L|=n_4=1\)</span>; <span class="math inline">\(|N|=n_5=1\)</span>; <span class="math inline">\(|E|=n_6=1\)</span>; <span class="math inline">\(|S|=n_7=1\)</span>.</p>
<p><span class="math display">\[{n \choose {n_1, n_2, \dots, n_k}} = \frac{11!}{3! 1! 3! 1! 1! 1! 1!} = 1,108,800\]</span></p>
<p><em>How many ways can a research pool of 15 subjects be divided into three equally sized test groups?</em></p>
<p><span class="math display">\[{n \choose {n_1, n_2, \dots, n_k}} = \frac{15!}{5! 5! 5!} = 756,756\]</span></p>
</div>
<div id="disc_dist" class="section level2">
<h2><span class="header-section-number">1.2</span> Discrete Distributions</h2>
<p>These notes rely heavily on PSU STATS 504 <a href="https://online.stat.psu.edu/stat504/node/209/">course notes</a>.</p>
<p>The most important discrete distributions are the Binomial, Poisson, and Multinomial. Sometimes useful are the related Bernoulli, negative binomial, geometric, and hypergeometric distributions.</p>
<p>A discrete random variable <span class="math inline">\(X\)</span> is described by its probability mass function <span class="math inline">\(f(x) = P(X = x)\)</span>. The set of <span class="math inline">\(x\)</span> values for which <span class="math inline">\(f(x) &gt; 0\)</span> is called the <em>support</em>. If the distribution depends on unknown parameter(s) <span class="math inline">\(\theta\)</span> we write it as <span class="math inline">\(f(x; \theta)\)</span> (frequentist) or <span class="math inline">\(f(x | \theta)\)</span> (Bayesian).</p>
<div id="bernoulli" class="section level3">
<h3><span class="header-section-number">1.2.1</span> Bernoulli</h3>
<p>If <span class="math inline">\(X\)</span> is the result of a trial with two outcomes of probability <span class="math inline">\(P(X = 1) = \pi\)</span> and <span class="math inline">\(P(X = 0) = 1 - \pi\)</span>, then <span class="math inline">\(X\)</span> is a random variable with a Bernoulli distribution</p>
<p><span class="math display">\[f(x) = \pi^x (1 - \pi)^{1 - x}, \hspace{1cm} x \in (0, 1)\]</span></p>
<p>with <span class="math inline">\(E(X) = \pi\)</span> and <span class="math inline">\(Var(X) = \pi(1 - \pi)\)</span>.</p>
</div>
<div id="binomial" class="section level3">
<h3><span class="header-section-number">1.2.2</span> Binomial</h3>
<p>If <span class="math inline">\(X\)</span> is the count of successful events in <span class="math inline">\(n\)</span> identical and independent Bernoulli trials of success probability <span class="math inline">\(\pi\)</span>, then <span class="math inline">\(X\)</span> is a random variable with a binomial distribution <span class="math inline">\(X \sim Bin(n,\pi)\)</span></p>
<p><span class="math display">\[f(x;n, \pi) = \frac{n!}{x!(n-x)!} \pi^x (1-\pi)^{n-x} \hspace{1cm} x \in (0, 1, ..., n), \hspace{2mm} \pi \in [0, 1]\]</span></p>
<p>with <span class="math inline">\(E(X)=n\pi\)</span> and <span class="math inline">\(Var(X) = n\pi(1-\pi)\)</span>.</p>
<p>Binomial sampling is used to model counts of one level of a categorical variable over a <em>fixed sample size</em>. Here is a simple analysis of data from a Binomial process. Data set <code>dat</code> contains frequencies of high-risk drinkers vs non-high-risk drinkers in a college survey.</p>
<pre><code>## 
##  No Yes 
## 685 630</code></pre>
<p>The MLE of <span class="math inline">\(\pi\)</span> from the Binomial distribution is the sample mean.</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2-1"><a href="probability.html#cb2-1"></a>x &lt;-<span class="st"> </span><span class="kw">sum</span>(dat<span class="op">$</span>high_risk <span class="op">==</span><span class="st"> &quot;Yes&quot;</span>)</span>
<span id="cb2-2"><a href="probability.html#cb2-2"></a>n &lt;-<span class="st"> </span><span class="kw">nrow</span>(dat)</span>
<span id="cb2-3"><a href="probability.html#cb2-3"></a>p &lt;-<span class="st"> </span>x <span class="op">/</span><span class="st"> </span>n</span>
<span id="cb2-4"><a href="probability.html#cb2-4"></a><span class="kw">print</span>(p)</span></code></pre></div>
<pre><code>## [1] 0.4790875</code></pre>
<p>Here is the binomial distribution <span class="math inline">\(f(x; \pi), \hspace{5mm} x \in [550, 700]\)</span>.</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb4-1"><a href="probability.html#cb4-1"></a>events &lt;-<span class="st"> </span><span class="kw">round</span>(<span class="kw">seq</span>(<span class="dt">from =</span> <span class="dv">550</span>, <span class="dt">to =</span> <span class="dv">700</span>, <span class="dt">length =</span> <span class="dv">20</span>), <span class="dv">0</span>)</span>
<span id="cb4-2"><a href="probability.html#cb4-2"></a>density &lt;-<span class="st"> </span><span class="kw">dbinom</span>(<span class="dt">x =</span> events, <span class="dt">prob =</span> p, <span class="dt">size =</span> n)</span>
<span id="cb4-3"><a href="probability.html#cb4-3"></a>prob &lt;-<span class="st"> </span><span class="kw">pbinom</span>(<span class="dt">q =</span> events, <span class="dt">prob =</span> p, <span class="dt">size =</span> n, <span class="dt">lower.tail =</span> <span class="ot">TRUE</span>)</span>
<span id="cb4-4"><a href="probability.html#cb4-4"></a>df &lt;-<span class="st"> </span><span class="kw">data.frame</span>(events, density, prob)</span>
<span id="cb4-5"><a href="probability.html#cb4-5"></a><span class="kw">ggplot</span>(df, <span class="kw">aes</span>(<span class="dt">x =</span> <span class="kw">factor</span>(events))) <span class="op">+</span></span>
<span id="cb4-6"><a href="probability.html#cb4-6"></a><span class="co">#  geom_col(aes(y = density)) +</span></span>
<span id="cb4-7"><a href="probability.html#cb4-7"></a><span class="st">  </span><span class="kw">geom_col</span>(<span class="kw">aes</span>(<span class="dt">y =</span> density), <span class="dt">fill =</span> <span class="kw">mf_pal</span>()(<span class="dv">1</span>), <span class="dt">alpha =</span> <span class="fl">0.8</span>) <span class="op">+</span></span>
<span id="cb4-8"><a href="probability.html#cb4-8"></a><span class="st">  </span><span class="kw">geom_text</span>(</span>
<span id="cb4-9"><a href="probability.html#cb4-9"></a>    <span class="kw">aes</span>(<span class="dt">label =</span> <span class="kw">round</span>(density, <span class="dv">3</span>), <span class="dt">y =</span> density <span class="op">+</span><span class="st"> </span><span class="fl">0.001</span>),</span>
<span id="cb4-10"><a href="probability.html#cb4-10"></a>    <span class="dt">position =</span> <span class="kw">position_dodge</span>(<span class="fl">0.9</span>),</span>
<span id="cb4-11"><a href="probability.html#cb4-11"></a>    <span class="dt">size =</span> <span class="dv">3</span>,</span>
<span id="cb4-12"><a href="probability.html#cb4-12"></a>    <span class="dt">vjust =</span> <span class="dv">0</span></span>
<span id="cb4-13"><a href="probability.html#cb4-13"></a>  ) <span class="op">+</span></span>
<span id="cb4-14"><a href="probability.html#cb4-14"></a><span class="st">  </span><span class="kw">geom_line</span>(</span>
<span id="cb4-15"><a href="probability.html#cb4-15"></a>    <span class="dt">data =</span> df, </span>
<span id="cb4-16"><a href="probability.html#cb4-16"></a>    <span class="kw">aes</span>(<span class="dt">x =</span> <span class="kw">as.numeric</span>(<span class="kw">factor</span>(events)), <span class="dt">y =</span> prob<span class="op">/</span><span class="dv">40</span>), </span>
<span id="cb4-17"><a href="probability.html#cb4-17"></a>    <span class="dt">color =</span> <span class="kw">mf_pal</span>()(<span class="dv">1</span>), </span>
<span id="cb4-18"><a href="probability.html#cb4-18"></a>    <span class="dt">size =</span> <span class="dv">1</span>) <span class="op">+</span></span>
<span id="cb4-19"><a href="probability.html#cb4-19"></a><span class="st">  </span><span class="kw">scale_y_continuous</span>(<span class="dt">sec.axis =</span> <span class="kw">sec_axis</span>(<span class="op">~</span>.<span class="op">*</span><span class="dv">40</span>, <span class="dt">name =</span> <span class="st">&quot;Cum Prob&quot;</span>)) <span class="op">+</span></span>
<span id="cb4-20"><a href="probability.html#cb4-20"></a><span class="st">  </span><span class="kw">theme_mf</span>() <span class="op">+</span></span>
<span id="cb4-21"><a href="probability.html#cb4-21"></a><span class="st">  </span><span class="kw">labs</span>(<span class="dt">title =</span> <span class="st">&quot;PMF and CDF of Binomial Distribution&quot;</span>,</span>
<span id="cb4-22"><a href="probability.html#cb4-22"></a>       <span class="dt">subtitle =</span> <span class="st">&quot;Bin(1315, 0.479).&quot;</span>,</span>
<span id="cb4-23"><a href="probability.html#cb4-23"></a>       <span class="dt">x =</span> <span class="st">&quot;Events (x)&quot;</span>,</span>
<span id="cb4-24"><a href="probability.html#cb4-24"></a>       <span class="dt">y =</span> <span class="st">&quot;Density&quot;</span>)</span></code></pre></div>
<p><img src="data-sci_files/figure-html/unnamed-chunk-4-1.png" width="672" /></p>
<p>There are several ways to calculate a confidence interval for <span class="math inline">\(\pi\)</span>. One method is the <strong>normal approximation</strong> (Wald) interval.</p>
<p><span class="math display">\[\pi = p \pm z_{\alpha /2} \sqrt{\frac{p (1 - p)}{n}}\]</span></p>
<div class="sourceCode" id="cb5"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb5-1"><a href="probability.html#cb5-1"></a>alpha &lt;-<span class="st"> </span><span class="fl">.05</span></span>
<span id="cb5-2"><a href="probability.html#cb5-2"></a>z &lt;-<span class="st"> </span><span class="kw">qnorm</span>(<span class="dv">1</span> <span class="op">-</span><span class="st"> </span>alpha <span class="op">/</span><span class="st"> </span><span class="dv">2</span>)</span>
<span id="cb5-3"><a href="probability.html#cb5-3"></a>se &lt;-<span class="st"> </span><span class="kw">sqrt</span>(p <span class="op">*</span><span class="st"> </span>(<span class="dv">1</span> <span class="op">-</span><span class="st"> </span>p) <span class="op">/</span><span class="st"> </span>n)</span>
<span id="cb5-4"><a href="probability.html#cb5-4"></a>p <span class="op">+</span><span class="st"> </span><span class="kw">c</span>(<span class="op">-</span>z<span class="op">*</span>se, z<span class="op">*</span>se)</span></code></pre></div>
<pre><code>## [1] 0.4520868 0.5060882</code></pre>
<p>This method is easy to understand and calculate by hand, but its accuracy suffers when <span class="math inline">\(np&lt;5\)</span> or <span class="math inline">\(n(1-p)&lt;5\)</span> and it does not work at all when <span class="math inline">\(p = 0\)</span> or <span class="math inline">\(p = 1\)</span>. Option two is the <strong>Wilson</strong> method.</p>
<p><span class="math display">\[\frac{p + \frac{z^2}{2n}}{1 + \frac{z^2}{n}} \pm \frac{z}{1 + \frac{z^2}{n}} \sqrt{\frac{p(1 - p)}{n} + \frac{z^2}{4n^2}}\]</span></p>
<div class="sourceCode" id="cb7"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb7-1"><a href="probability.html#cb7-1"></a>est &lt;-<span class="st"> </span>(p <span class="op">+</span><span class="st"> </span>(z<span class="op">^</span><span class="dv">2</span>)<span class="op">/</span>(<span class="dv">2</span><span class="op">*</span>n)) <span class="op">/</span><span class="st"> </span>(<span class="dv">1</span> <span class="op">+</span><span class="st"> </span>(z<span class="op">^</span><span class="dv">2</span>) <span class="op">/</span><span class="st"> </span>n)</span>
<span id="cb7-2"><a href="probability.html#cb7-2"></a>pm &lt;-<span class="st"> </span>z <span class="op">/</span><span class="st"> </span>(<span class="dv">1</span> <span class="op">+</span><span class="st"> </span>(z<span class="op">^</span><span class="dv">2</span>)<span class="op">/</span>n) <span class="op">*</span><span class="st"> </span><span class="kw">sqrt</span>(p<span class="op">*</span>(<span class="dv">1</span><span class="op">-</span>p)<span class="op">/</span>n <span class="op">+</span><span class="st"> </span>(z<span class="op">^</span><span class="dv">2</span>) <span class="op">/</span><span class="st"> </span>(<span class="dv">4</span><span class="op">*</span>(n<span class="op">^</span><span class="dv">2</span>)))</span>
<span id="cb7-3"><a href="probability.html#cb7-3"></a>est <span class="op">+</span><span class="st"> </span><span class="kw">c</span>(<span class="op">-</span>pm, pm)</span></code></pre></div>
<pre><code>## [1] 0.4521869 0.5061098</code></pre>
<p>This is what <code>prop.test()</code> does when you set <code>correct = FALSE</code>.</p>
<div class="sourceCode" id="cb9"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb9-1"><a href="probability.html#cb9-1"></a><span class="kw">prop.test</span>(<span class="dt">x =</span> x, <span class="dt">n =</span> n, <span class="dt">correct =</span> <span class="ot">FALSE</span>)</span></code></pre></div>
<pre><code>## 
##  1-sample proportions test without continuity correction
## 
## data:  x out of n, null probability 0.5
## X-squared = 2.3004, df = 1, p-value = 0.1293
## alternative hypothesis: true p is not equal to 0.5
## 95 percent confidence interval:
##  0.4521869 0.5061098
## sample estimates:
##         p 
## 0.4790875</code></pre>
<p>There is a second version of the Wilson interval that applies a “continuity correction” that aligns the “minimum coverage probability”, rather than the “average probability”, with the nominal value. <em>I’ll need to learn what’s inside those quotations at some point.</em></p>
<div class="sourceCode" id="cb11"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb11-1"><a href="probability.html#cb11-1"></a><span class="kw">prop.test</span>(<span class="dt">x =</span> x, <span class="dt">n =</span> n)</span></code></pre></div>
<pre><code>## 
##  1-sample proportions test with continuity correction
## 
## data:  x out of n, null probability 0.5
## X-squared = 2.2175, df = 1, p-value = 0.1365
## alternative hypothesis: true p is not equal to 0.5
## 95 percent confidence interval:
##  0.4518087 0.5064898
## sample estimates:
##         p 
## 0.4790875</code></pre>
<p>Finally, there is the Clopper-Pearson <strong>exact confidence interval</strong>. Clopper-Pearson inverts two single-tailed binomial tests at the desired alpha. This is a non-trivial calculation, so there is no easy formula to crank through. Just use the <code>binom.test()</code> function and pray no one asks for an explanation.</p>
<div class="sourceCode" id="cb13"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb13-1"><a href="probability.html#cb13-1"></a><span class="kw">binom.test</span>(<span class="dt">x =</span> x, <span class="dt">n =</span> n)</span></code></pre></div>
<pre><code>## 
##  Exact binomial test
## 
## data:  x and n
## number of successes = 630, number of trials = 1315, p-value = 0.1364
## alternative hypothesis: true probability of success is not equal to 0.5
## 95 percent confidence interval:
##  0.4517790 0.5064896
## sample estimates:
## probability of success 
##              0.4790875</code></pre>
<p>The expected probability of no one being a high-risk drinker is <span class="math inline">\(f(0;0.479) = \frac{1315!}{0!(1315-0)!} 0.479^0 (1-0.479)^{1315-0} = 0\)</span>.</p>
<div class="sourceCode" id="cb15"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb15-1"><a href="probability.html#cb15-1"></a><span class="kw">dbinom</span>(<span class="dt">x =</span> <span class="dv">0</span>, <span class="dt">size =</span> n, <span class="dt">p =</span> p)</span></code></pre></div>
<pre><code>## [1] 0</code></pre>
<p>The expected probability of half the population being a high-risk drinker, <span class="math inline">\(f(658, 0.479)\)</span>, is impossible to write out, and slow to calculate.</p>
<div class="sourceCode" id="cb17"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb17-1"><a href="probability.html#cb17-1"></a><span class="kw">pbinom</span>(<span class="dt">q =</span> <span class="fl">.5</span><span class="op">*</span>n, <span class="dt">size =</span> n, <span class="dt">prob =</span> p, <span class="dt">lower.tail =</span> <span class="ot">FALSE</span>)</span></code></pre></div>
<pre><code>## [1] 0.06455096</code></pre>
<p>As n increases for fixed <span class="math inline">\(\pi\)</span>, the binomial distribution approaches normal distribution <span class="math inline">\(N(n\pi, n\pi(1−\pi))\)</span>. The normal distribution is a good approximation when <span class="math inline">\(n\)</span> is large.</p>
<div class="sourceCode" id="cb19"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb19-1"><a href="probability.html#cb19-1"></a><span class="kw">pnorm</span>(<span class="dt">q =</span> <span class="fl">0.5</span>, <span class="dt">mean =</span> p, <span class="dt">sd =</span> se, <span class="dt">lower.tail =</span> <span class="ot">FALSE</span>)</span></code></pre></div>
<pre><code>## [1] 0.06450357</code></pre>
<p>Here are some more examples using smaller sample sizes. The probability 2 out of 10 coin flips are heads if the probability of heads is 0.3:</p>
<div class="sourceCode" id="cb21"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb21-1"><a href="probability.html#cb21-1"></a><span class="kw">dbinom</span>(<span class="dt">x =</span> <span class="dv">2</span>, <span class="dt">size =</span> <span class="dv">10</span>, <span class="dt">prob =</span> <span class="fl">0.3</span>)</span></code></pre></div>
<pre><code>## [1] 0.2334744</code></pre>
<p>Here is a simulation from n = 10,000 random samples of size 10. <code>rbinom()</code> generates a random sample of numbers from the binomial distribution.</p>
<div class="sourceCode" id="cb23"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb23-1"><a href="probability.html#cb23-1"></a><span class="kw">data.frame</span>(<span class="dt">cnt =</span> <span class="kw">rbinom</span>(<span class="dt">n =</span> <span class="dv">10000</span>, <span class="dt">size =</span> <span class="dv">10</span>, <span class="dt">prob =</span> <span class="fl">0.3</span>)) <span class="op">%&gt;%</span></span>
<span id="cb23-2"><a href="probability.html#cb23-2"></a><span class="st">  </span><span class="kw">count</span>(cnt) <span class="op">%&gt;%</span></span>
<span id="cb23-3"><a href="probability.html#cb23-3"></a><span class="st">  </span><span class="kw">ungroup</span>() <span class="op">%&gt;%</span></span>
<span id="cb23-4"><a href="probability.html#cb23-4"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">pct =</span> n <span class="op">/</span><span class="st"> </span><span class="kw">sum</span>(n),</span>
<span id="cb23-5"><a href="probability.html#cb23-5"></a>         <span class="dt">X_eq_x =</span> cnt <span class="op">==</span><span class="st"> </span><span class="dv">2</span>) <span class="op">%&gt;%</span></span>
<span id="cb23-6"><a href="probability.html#cb23-6"></a><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> <span class="kw">as.factor</span>(cnt), <span class="dt">y =</span> n, <span class="dt">fill =</span> X_eq_x, <span class="dt">label =</span> pct)) <span class="op">+</span></span>
<span id="cb23-7"><a href="probability.html#cb23-7"></a><span class="st">  </span><span class="kw">geom_col</span>(<span class="dt">alpha =</span> <span class="fl">0.8</span>) <span class="op">+</span></span>
<span id="cb23-8"><a href="probability.html#cb23-8"></a><span class="st">  </span><span class="kw">scale_fill_mf</span>() <span class="op">+</span></span>
<span id="cb23-9"><a href="probability.html#cb23-9"></a><span class="st">  </span><span class="kw">geom_label</span>(<span class="kw">aes</span>(<span class="dt">label =</span> <span class="kw">round</span>(pct, <span class="dv">2</span>)), <span class="dt">size =</span> <span class="dv">3</span>, <span class="dt">alpha =</span> <span class="fl">.6</span>) <span class="op">+</span></span>
<span id="cb23-10"><a href="probability.html#cb23-10"></a><span class="st">  </span><span class="kw">theme_mf</span>() <span class="op">+</span></span>
<span id="cb23-11"><a href="probability.html#cb23-11"></a><span class="st">  </span><span class="kw">theme</span>(<span class="dt">legend.position =</span> <span class="st">&quot;none&quot;</span>) <span class="op">+</span></span>
<span id="cb23-12"><a href="probability.html#cb23-12"></a><span class="st">  </span><span class="kw">labs</span>(<span class="dt">title =</span> <span class="st">&quot;Binomial Distribution&quot;</span>, </span>
<span id="cb23-13"><a href="probability.html#cb23-13"></a>       <span class="dt">subtitle =</span> <span class="kw">paste0</span>(</span>
<span id="cb23-14"><a href="probability.html#cb23-14"></a>         <span class="st">&quot;P(X=2) successes in 10 trials when p = 0.3 is &quot;</span>, </span>
<span id="cb23-15"><a href="probability.html#cb23-15"></a>         <span class="kw">round</span>(<span class="kw">dbinom</span>(<span class="dv">2</span>, <span class="dv">10</span>, <span class="fl">0.3</span>), <span class="dv">4</span>), <span class="st">&quot;.&quot;</span></span>
<span id="cb23-16"><a href="probability.html#cb23-16"></a>       ),</span>
<span id="cb23-17"><a href="probability.html#cb23-17"></a>       <span class="dt">x =</span> <span class="st">&quot;Successes&quot;</span>,</span>
<span id="cb23-18"><a href="probability.html#cb23-18"></a>       <span class="dt">y =</span> <span class="st">&quot;Count&quot;</span>,</span>
<span id="cb23-19"><a href="probability.html#cb23-19"></a>       <span class="dt">caption =</span> <span class="st">&quot;Simulation from n = 10,000 binomial random samples.&quot;</span>) </span></code></pre></div>
<p><img src="data-sci_files/figure-html/unnamed-chunk-14-1.png" width="480" /></p>
<p>What is the probability of &lt;=2 heads in 10 coin flips where probability of heads is 0.3? The cumulative probability is the sum of the first three bars in the simulation above. Function <code>pbinom()</code> calculates the <em>cumulative</em> binomial probability.</p>
<div class="sourceCode" id="cb24"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb24-1"><a href="probability.html#cb24-1"></a><span class="kw">pbinom</span>(<span class="dt">q =</span> <span class="dv">2</span>, <span class="dt">size =</span> <span class="dv">10</span>, <span class="dt">prob =</span> <span class="fl">0.3</span>, <span class="dt">lower.tail =</span> <span class="ot">TRUE</span>)</span></code></pre></div>
<pre><code>## [1] 0.3827828</code></pre>
<p>What is the expected number of heads in 25 coin flips if the probability of heads is 0.3?</p>
<p>The expected value, <span class="math inline">\(\mu = np\)</span>, is 7.5. Here’s an empirical test from 10,000 samples.</p>
<div class="sourceCode" id="cb26"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb26-1"><a href="probability.html#cb26-1"></a><span class="kw">mean</span>(<span class="kw">rbinom</span>(<span class="dt">n =</span> <span class="dv">10000</span>, <span class="dt">size =</span> <span class="dv">25</span>, <span class="dt">prob =</span> <span class="fl">.3</span>))</span></code></pre></div>
<pre><code>## [1] 7.4645</code></pre>
<p>The variance, <span class="math inline">\(\sigma^2 = np (1 - p)\)</span>, is 5.25. Here’s an empirical test.</p>
<div class="sourceCode" id="cb28"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb28-1"><a href="probability.html#cb28-1"></a><span class="kw">var</span>(<span class="kw">rbinom</span>(<span class="dt">n =</span> <span class="dv">10000</span>, <span class="dt">size =</span> <span class="dv">25</span>, <span class="dt">prob =</span> <span class="fl">.3</span>))</span></code></pre></div>
<pre><code>## [1] 5.326368</code></pre>
<p>Suppose X and Y are independent random variables distributed <span class="math inline">\(X \sim Bin(10, .6)\)</span> and <span class="math inline">\(Y \sim Bin(10, .7)\)</span>. What is the probability that either variable is &lt;=4?</p>
<p>Let <span class="math inline">\(P(A) = P(X&lt;=4)\)</span> and <span class="math inline">\(P(B) = P(Y&lt;=4)\)</span>. Then <span class="math inline">\(P(A|B) = P(A) + P(B) - P(AB)\)</span>, and because the events are independent, <span class="math inline">\(P(AB) = P(A)P(B)\)</span>.</p>
<div class="sourceCode" id="cb30"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb30-1"><a href="probability.html#cb30-1"></a>p_a &lt;-<span class="st"> </span><span class="kw">pbinom</span>(<span class="dt">q =</span> <span class="dv">4</span>, <span class="dt">size =</span> <span class="dv">10</span>, <span class="dt">prob =</span> <span class="fl">0.6</span>, <span class="dt">lower.tail =</span> <span class="ot">TRUE</span>)</span>
<span id="cb30-2"><a href="probability.html#cb30-2"></a>p_b &lt;-<span class="st"> </span><span class="kw">pbinom</span>(<span class="dt">q =</span> <span class="dv">4</span>, <span class="dt">size =</span> <span class="dv">10</span>, <span class="dt">prob =</span> <span class="fl">0.7</span>, <span class="dt">lower.tail =</span> <span class="ot">TRUE</span>)</span>
<span id="cb30-3"><a href="probability.html#cb30-3"></a>p_a <span class="op">+</span><span class="st"> </span>p_b <span class="op">-</span><span class="st"> </span>(p_a <span class="op">*</span><span class="st"> </span>p_b)</span></code></pre></div>
<pre><code>## [1] 0.2057164</code></pre>
<p>Here’s an empirical test.</p>
<div class="sourceCode" id="cb32"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb32-1"><a href="probability.html#cb32-1"></a>df &lt;-<span class="st"> </span><span class="kw">data.frame</span>(</span>
<span id="cb32-2"><a href="probability.html#cb32-2"></a>  <span class="dt">x =</span> <span class="kw">rbinom</span>(<span class="dv">10000</span>, <span class="dv">10</span>, <span class="fl">0.6</span>),</span>
<span id="cb32-3"><a href="probability.html#cb32-3"></a>  <span class="dt">y =</span> <span class="kw">rbinom</span>(<span class="dv">10000</span>, <span class="dv">10</span>, <span class="fl">0.7</span>)</span>
<span id="cb32-4"><a href="probability.html#cb32-4"></a>  )</span>
<span id="cb32-5"><a href="probability.html#cb32-5"></a><span class="kw">mean</span>(<span class="kw">if_else</span>(df<span class="op">$</span>x <span class="op">&lt;=</span><span class="st"> </span><span class="dv">4</span> <span class="op">|</span><span class="st"> </span>df<span class="op">$</span>y <span class="op">&lt;=</span><span class="st"> </span><span class="dv">4</span>, <span class="dv">1</span>, <span class="dv">0</span>))</span></code></pre></div>
<pre><code>## [1] 0.2095</code></pre>
<p>A couple other points to remember:</p>
<ul>
<li>The Bernoulli distribution is a special case of the binomial with <span class="math inline">\(n = 1\)</span>.</li>
<li>The binomial distribution assumes independent trials. If you sample <em>without replacement from a finite population</em>, use the hypergeometric distribution.</li>
</ul>
</div>
<div id="poission" class="section level3">
<h3><span class="header-section-number">1.2.3</span> Poission</h3>
<p>If <span class="math inline">\(X\)</span> is the number of successes in <span class="math inline">\(n\)</span> (many) trials when the probability of success <span class="math inline">\(\lambda / n\)</span> is small, then <span class="math inline">\(X\)</span> is a random variable with a Poisson distribution <span class="math inline">\(X \sim Poisson(\lambda)\)</span></p>
<p><span class="math display">\[f(x;\lambda) = \frac{e^{-\lambda} \lambda^x}{x!} \hspace{1cm} x \in (0, 1, ...), \hspace{2mm} \lambda &gt; 0\]</span></p>
<p>with <span class="math inline">\(E(X)=\lambda\)</span> and <span class="math inline">\(Var(X) = \lambda\)</span>.</p>
<p>The Poisson likelihood function is</p>
<p><span class="math display">\[L(\lambda; x) = \prod_{i=1}^N f(x_i; \lambda) = \prod_{i=1}^N \frac{e^{-\lambda} \lambda^x_i}{x_i !} = \frac{e^{-n \lambda} \lambda^{\sum x_i}}{\prod x_i}.\]</span></p>
<p>The Poisson loglikelihood function is</p>
<p><span class="math display">\[l(\lambda; x) = \sum_{i=1}^N x_i \log \lambda - n \lambda.\]</span></p>
<p>One can show that the loglikelihood function is maximized at</p>
<p><span class="math display">\[\hat{\lambda} = \sum_{i=1}^N x_i / n.\]</span></p>
<p>Thus, for a Poisson sample, the MLE for <span class="math inline">\(\lambda\)</span> is just the sample mean.</p>
<p>Poisson sampling is used to model counts of events that occur randomly over a <em>fixed period of time</em>. Here is a simple analysis of data from a Poisson process. Data set <code>dat</code> contains frequencies of goal counts during the first round matches of the 2002 World Cup.</p>
<pre><code>##   goals freq
## 1     0   23
## 2     1   37
## 3     2   20
## 4     3   11
## 5     4    2
## 6     5    1
## 7     6    0
## 8     7    0
## 9     8    1</code></pre>
<p>The MLE of <span class="math inline">\(\lambda\)</span> from the Poisson distribution is the sample mean.</p>
<div class="sourceCode" id="cb35"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb35-1"><a href="probability.html#cb35-1"></a>lambda &lt;-<span class="st"> </span><span class="kw">weighted.mean</span>(dat<span class="op">$</span>goals, dat<span class="op">$</span>freq)</span>
<span id="cb35-2"><a href="probability.html#cb35-2"></a><span class="kw">print</span>(lambda)</span></code></pre></div>
<pre><code>## [1] 1.378947</code></pre>
<p>The 0.95 CI is <span class="math inline">\(\lambda \pm z_{.05/2} \sqrt{\lambda / n}\)</span></p>
<div class="sourceCode" id="cb37"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb37-1"><a href="probability.html#cb37-1"></a>n &lt;-<span class="st"> </span><span class="kw">sum</span>(dat<span class="op">$</span>freq)</span>
<span id="cb37-2"><a href="probability.html#cb37-2"></a>z &lt;-<span class="st"> </span><span class="kw">qnorm</span>(<span class="fl">0.975</span>)</span>
<span id="cb37-3"><a href="probability.html#cb37-3"></a>se &lt;-<span class="st"> </span><span class="kw">sqrt</span>(lambda <span class="op">/</span><span class="st"> </span>n)</span>
<span id="cb37-4"><a href="probability.html#cb37-4"></a><span class="kw">paste0</span>(<span class="st">&quot;[&quot;</span>, <span class="kw">round</span>(lambda <span class="op">-</span><span class="st"> </span>z<span class="op">*</span>se, <span class="dv">2</span>), <span class="st">&quot;, &quot;</span>, <span class="kw">round</span>(lambda <span class="op">+</span><span class="st"> </span>z<span class="op">*</span>se, <span class="dv">2</span>),<span class="st">&quot;]&quot;</span>)</span></code></pre></div>
<pre><code>## [1] &quot;[1.14, 1.62]&quot;</code></pre>
<p>The expected probability of scoring 2 goals in a match is <span class="math inline">\(\frac{e^{-1.38} 1.38^2}{2!} = 0.239\)</span>.</p>
<div class="sourceCode" id="cb39"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb39-1"><a href="probability.html#cb39-1"></a><span class="kw">dpois</span>(<span class="dt">x =</span> <span class="dv">2</span>, <span class="dt">lambda =</span> lambda)</span></code></pre></div>
<pre><code>## [1] 0.2394397</code></pre>
<div class="sourceCode" id="cb41"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb41-1"><a href="probability.html#cb41-1"></a>events &lt;-<span class="st"> </span><span class="dv">0</span><span class="op">:</span><span class="dv">10</span></span>
<span id="cb41-2"><a href="probability.html#cb41-2"></a>density &lt;-<span class="st"> </span><span class="kw">dpois</span>(<span class="dt">x =</span> events, <span class="dt">lambda =</span> <span class="dv">3</span>)</span>
<span id="cb41-3"><a href="probability.html#cb41-3"></a>prob &lt;-<span class="st"> </span><span class="kw">ppois</span>(<span class="dt">q =</span> events, <span class="dt">lambda =</span> <span class="dv">3</span>, <span class="dt">lower.tail =</span> <span class="ot">TRUE</span>)</span>
<span id="cb41-4"><a href="probability.html#cb41-4"></a>df &lt;-<span class="st"> </span><span class="kw">data.frame</span>(events, density, prob)</span>
<span id="cb41-5"><a href="probability.html#cb41-5"></a><span class="kw">ggplot</span>(df, <span class="kw">aes</span>(<span class="dt">x =</span> <span class="kw">factor</span>(events), <span class="dt">y =</span> density)) <span class="op">+</span></span>
<span id="cb41-6"><a href="probability.html#cb41-6"></a><span class="st">  </span><span class="kw">geom_col</span>() <span class="op">+</span></span>
<span id="cb41-7"><a href="probability.html#cb41-7"></a><span class="st">  </span><span class="kw">geom_text</span>(</span>
<span id="cb41-8"><a href="probability.html#cb41-8"></a>    <span class="kw">aes</span>(<span class="dt">label =</span> <span class="kw">round</span>(density, <span class="dv">3</span>), <span class="dt">y =</span> density <span class="op">+</span><span class="st"> </span><span class="fl">0.01</span>),</span>
<span id="cb41-9"><a href="probability.html#cb41-9"></a>    <span class="dt">position =</span> <span class="kw">position_dodge</span>(<span class="fl">0.9</span>),</span>
<span id="cb41-10"><a href="probability.html#cb41-10"></a>    <span class="dt">size =</span> <span class="dv">3</span>,</span>
<span id="cb41-11"><a href="probability.html#cb41-11"></a>    <span class="dt">vjust =</span> <span class="dv">0</span></span>
<span id="cb41-12"><a href="probability.html#cb41-12"></a>  ) <span class="op">+</span></span>
<span id="cb41-13"><a href="probability.html#cb41-13"></a><span class="st">  </span><span class="kw">geom_line</span>(</span>
<span id="cb41-14"><a href="probability.html#cb41-14"></a>    <span class="dt">data =</span> df, </span>
<span id="cb41-15"><a href="probability.html#cb41-15"></a>    <span class="kw">aes</span>(<span class="dt">x =</span> events, <span class="dt">y =</span> prob<span class="op">/</span><span class="dv">4</span>), </span>
<span id="cb41-16"><a href="probability.html#cb41-16"></a>    <span class="dt">size =</span> <span class="dv">1</span>) <span class="op">+</span></span>
<span id="cb41-17"><a href="probability.html#cb41-17"></a><span class="st">  </span><span class="kw">scale_y_continuous</span>(<span class="dt">sec.axis =</span> <span class="kw">sec_axis</span>(<span class="op">~</span>.<span class="op">*</span><span class="dv">4</span>, <span class="dt">name =</span> <span class="st">&quot;Cum Prob&quot;</span>)) <span class="op">+</span></span>
<span id="cb41-18"><a href="probability.html#cb41-18"></a><span class="st">  </span><span class="kw">theme_mf</span>() <span class="op">+</span></span>
<span id="cb41-19"><a href="probability.html#cb41-19"></a><span class="st">  </span><span class="kw">scale_fill_mf</span>() <span class="op">+</span></span>
<span id="cb41-20"><a href="probability.html#cb41-20"></a><span class="st">  </span><span class="kw">labs</span>(<span class="dt">title =</span> <span class="st">&quot;PMF and CDF of Poisson Distribution&quot;</span>,</span>
<span id="cb41-21"><a href="probability.html#cb41-21"></a>       <span class="dt">subtitle =</span> <span class="st">&quot;Poisson(3).&quot;</span>,</span>
<span id="cb41-22"><a href="probability.html#cb41-22"></a>       <span class="dt">x =</span> <span class="st">&quot;Events (x)&quot;</span>,</span>
<span id="cb41-23"><a href="probability.html#cb41-23"></a>       <span class="dt">y =</span> <span class="st">&quot;Density&quot;</span>)</span></code></pre></div>
<p><img src="data-sci_files/figure-html/unnamed-chunk-24-1.png" width="672" /></p>
<p>The expected probability of scoring 2 to 4 goals in a match is</p>
<div class="sourceCode" id="cb42"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb42-1"><a href="probability.html#cb42-1"></a><span class="kw">sum</span>(<span class="kw">dpois</span>(<span class="dt">x =</span> <span class="kw">c</span>(<span class="dv">2</span><span class="op">:</span><span class="dv">4</span>), <span class="dt">lambda =</span> lambda))</span></code></pre></div>
<pre><code>## [1] 0.3874391</code></pre>
<p>Or, using the cumulative probability distribution,</p>
<div class="sourceCode" id="cb44"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb44-1"><a href="probability.html#cb44-1"></a><span class="kw">ppois</span>(<span class="dt">q =</span> <span class="dv">4</span>, <span class="dt">lambda =</span> lambda) <span class="op">-</span><span class="st"> </span><span class="kw">ppois</span>(<span class="dt">q =</span> <span class="dv">1</span>, <span class="dt">lambda =</span> lambda)</span></code></pre></div>
<pre><code>## [1] 0.3874391</code></pre>
<p>How well does the Poisson distribution fit the 2002 World Cup data?</p>
<div class="sourceCode" id="cb46"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb46-1"><a href="probability.html#cb46-1"></a>dat <span class="op">%&gt;%</span></span>
<span id="cb46-2"><a href="probability.html#cb46-2"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">pred =</span> n <span class="op">*</span><span class="st"> </span><span class="kw">dpois</span>(<span class="dt">x =</span> goals, <span class="dt">lambda =</span> lambda)) <span class="op">%&gt;%</span></span>
<span id="cb46-3"><a href="probability.html#cb46-3"></a><span class="st">  </span><span class="kw">rename</span>(<span class="dt">obs =</span> freq) <span class="op">%&gt;%</span></span>
<span id="cb46-4"><a href="probability.html#cb46-4"></a><span class="st">  </span><span class="kw">pivot_longer</span>(<span class="dt">cols =</span> <span class="op">-</span>goals) <span class="op">%&gt;%</span></span>
<span id="cb46-5"><a href="probability.html#cb46-5"></a><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> goals, <span class="dt">y =</span> value, <span class="dt">color =</span> name)) <span class="op">+</span></span>
<span id="cb46-6"><a href="probability.html#cb46-6"></a><span class="st">  </span><span class="kw">geom_point</span>() <span class="op">+</span></span>
<span id="cb46-7"><a href="probability.html#cb46-7"></a><span class="st">  </span><span class="kw">theme_mf</span>() <span class="op">+</span></span>
<span id="cb46-8"><a href="probability.html#cb46-8"></a><span class="st">  </span><span class="kw">scale_color_mf</span>() <span class="op">+</span></span>
<span id="cb46-9"><a href="probability.html#cb46-9"></a><span class="st">  </span><span class="kw">geom_smooth</span>(<span class="dt">se =</span> <span class="ot">FALSE</span>) <span class="op">+</span></span>
<span id="cb46-10"><a href="probability.html#cb46-10"></a><span class="st">  </span><span class="kw">labs</span>(</span>
<span id="cb46-11"><a href="probability.html#cb46-11"></a>    <span class="dt">title =</span> <span class="st">&quot;Poisson Dist: Observed vs Expected&quot;</span>,</span>
<span id="cb46-12"><a href="probability.html#cb46-12"></a>    <span class="dt">color =</span> <span class="st">&quot;&quot;</span>,</span>
<span id="cb46-13"><a href="probability.html#cb46-13"></a>    <span class="dt">y =</span> <span class="st">&quot;frequencey&quot;</span></span>
<span id="cb46-14"><a href="probability.html#cb46-14"></a>  )</span></code></pre></div>
<p><img src="data-sci_files/figure-html/unnamed-chunk-27-1.png" width="672" /></p>
<p>It fits the data pretty good!</p>
<p><span class="math inline">\(Poison(\lambda) \rightarrow Bin(n, \pi)\)</span> when <span class="math inline">\(n\pi = \lambda\)</span> and <span class="math inline">\(n \rightarrow \infty\)</span> and <span class="math inline">\(\pi \rightarrow 0\)</span>. Because the Poisson is limit of the <span class="math inline">\(Bin(n, \pi)\)</span>, it is useful as an approximation to the binomial when <span class="math inline">\(n\)</span> is large (<span class="math inline">\(n&gt;=20\)</span>) and <span class="math inline">\(\pi\)</span> small (<span class="math inline">\(p&lt;=0.05\)</span>).</p>
<p>For example, suppose a baseball player has a p=.03 chance of hitting a homerun. What is the probability of X&gt;=20 homeruns in 500 at-bats? This is a binomial process because the sample size is fixed.</p>
<div class="sourceCode" id="cb47"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb47-1"><a href="probability.html#cb47-1"></a><span class="kw">pbinom</span>(<span class="dt">q =</span> <span class="dv">20</span>, <span class="dt">size =</span> <span class="dv">500</span>, <span class="dt">prob =</span> <span class="fl">0.03</span>, <span class="dt">lower.tail =</span> <span class="ot">FALSE</span>)</span></code></pre></div>
<pre><code>## [1] 0.07979678</code></pre>
<p>But <span class="math inline">\(n\)</span> is large and <span class="math inline">\(\pi\)</span> is small, so the Poisson distribution will work well too.</p>
<div class="sourceCode" id="cb49"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb49-1"><a href="probability.html#cb49-1"></a><span class="kw">ppois</span>(<span class="dt">q =</span> <span class="dv">20</span>, <span class="dt">lambda =</span> <span class="fl">0.03</span> <span class="op">*</span><span class="st"> </span><span class="dv">500</span>, <span class="dt">lower.tail =</span> <span class="ot">FALSE</span>)</span></code></pre></div>
<pre><code>## [1] 0.08297091</code></pre>
<p>What is the distribution of successes from a sample of n = 50 when the probability of success is p = .03?</p>
<div class="sourceCode" id="cb51"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb51-1"><a href="probability.html#cb51-1"></a>n =<span class="st"> </span><span class="dv">500</span></span>
<span id="cb51-2"><a href="probability.html#cb51-2"></a>p =<span class="st"> </span><span class="fl">0.03</span></span>
<span id="cb51-3"><a href="probability.html#cb51-3"></a>x =<span class="st"> </span><span class="dv">0</span><span class="op">:</span><span class="dv">30</span></span>
<span id="cb51-4"><a href="probability.html#cb51-4"></a><span class="kw">data.frame</span>(</span>
<span id="cb51-5"><a href="probability.html#cb51-5"></a>  <span class="dt">events =</span> x, </span>
<span id="cb51-6"><a href="probability.html#cb51-6"></a>  <span class="dt">Poisson =</span> <span class="kw">dpois</span>(<span class="dt">x =</span> x, <span class="dt">lambda =</span> p <span class="op">*</span><span class="st"> </span>n),</span>
<span id="cb51-7"><a href="probability.html#cb51-7"></a>  <span class="dt">Binomial =</span> <span class="kw">dbinom</span>(<span class="dt">x =</span> x, <span class="dt">size =</span> n, <span class="dt">p =</span> p)</span>
<span id="cb51-8"><a href="probability.html#cb51-8"></a>) <span class="op">%&gt;%</span></span>
<span id="cb51-9"><a href="probability.html#cb51-9"></a><span class="st">  </span><span class="kw">pivot_longer</span>(<span class="dt">cols =</span> <span class="op">-</span>events) <span class="op">%&gt;%</span></span>
<span id="cb51-10"><a href="probability.html#cb51-10"></a><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> events, <span class="dt">y =</span> value, <span class="dt">color =</span> name)) <span class="op">+</span></span>
<span id="cb51-11"><a href="probability.html#cb51-11"></a><span class="st">  </span><span class="kw">geom_point</span>() <span class="op">+</span></span>
<span id="cb51-12"><a href="probability.html#cb51-12"></a><span class="st">  </span><span class="kw">theme_mf</span>() <span class="op">+</span></span>
<span id="cb51-13"><a href="probability.html#cb51-13"></a><span class="st">  </span><span class="kw">scale_color_mf</span>() <span class="op">+</span></span>
<span id="cb51-14"><a href="probability.html#cb51-14"></a><span class="st">  </span><span class="kw">labs</span>(<span class="dt">title =</span> <span class="st">&quot;Poisson(15) vs. Bin(500, .03)&quot;</span>,</span>
<span id="cb51-15"><a href="probability.html#cb51-15"></a>       <span class="dt">subtitle =</span> <span class="st">&quot;Poisson approximation to binomial.&quot;</span>,</span>
<span id="cb51-16"><a href="probability.html#cb51-16"></a>       <span class="dt">x =</span> <span class="st">&quot;Events&quot;</span>,</span>
<span id="cb51-17"><a href="probability.html#cb51-17"></a>       <span class="dt">y =</span> <span class="st">&quot;Density&quot;</span>,</span>
<span id="cb51-18"><a href="probability.html#cb51-18"></a>       <span class="dt">color =</span> <span class="st">&quot;&quot;</span>)</span></code></pre></div>
<p><img src="data-sci_files/figure-html/unnamed-chunk-30-1.png" width="480" /></p>
<p>When the observed variance is greater than <span class="math inline">\(\lambda\)</span> (overdispersion), the Negative Binomial distribution can be used instead of Poisson.</p>
<p>Suppose the probability that a drug produces a certain side effect is p = = 0.1% and n = 1,000 patients in a clinical trial receive the drug. What is the probability 0 people experience the side effect?</p>
<p>The expected value is np, 1. The probability of measuring 0 when the expected value is 1 is <code>dpois(x = 0, lambda = 1000 * .001) =</code> 0.3678794.</p>
<p><img src="data-sci_files/figure-html/unnamed-chunk-31-1.png" width="480" /></p>
</div>
<div id="multinomial" class="section level3">
<h3><span class="header-section-number">1.2.4</span> Multinomial</h3>
<p>If <span class="math inline">\(X = (X_1, X_2, \cdots, X_k)\)</span> are the counts of successful events in <span class="math inline">\(n\)</span> identical and independent trials of success probabilities <span class="math inline">\(\pi = (\pi_1, \pi_2, \cdots, \pi_k)\)</span>, then <span class="math inline">\(X\)</span> is a random variable with a multinomial distribution <span class="math inline">\(X \sim Mult(n,\pi)\)</span></p>
<p><span class="math display">\[f(x; n, \pi) = \frac{n!}{x_{1}! x_{2}! \cdots x_{k}!} \pi^{x_1} \pi^{x_2} \cdots \pi^{x_k} \hspace{1cm} x \in \{0, 1, ..., n \}, \hspace{2mm} \pi \in [0, 1]\]</span></p>
<p>with expected values vector <span class="math inline">\(E(X_j) = n\pi_j\)</span> and covariance matrix</p>
<p><span class="math display">\[Var(X) = \begin{bmatrix}n\pi_{1}(1-\pi_{1}) &amp; -n\pi_{1}\pi_{2} &amp; \cdots &amp; -n\pi_{1}\pi_{k}\\
-n\pi_{1}\pi_{2} &amp; n\pi_{2}(1-\pi_{2}) &amp; \cdots &amp; -n\pi_{2}\pi_{k}\\
\vdots &amp; \vdots &amp; \ddots &amp; \vdots\\
-n\pi_{1}\pi_{k} &amp; -n\pi_{2}\pi_{k} &amp; \cdots &amp; n\pi_{k}(1-\pi_{k})
\end{bmatrix}\]</span></p>
<p>so <span class="math inline">\(Var(X_j) = n \pi_j (1 - \pi_j)\)</span> and <span class="math inline">\(cov(X_j, X_k) = -n \pi_j \pi_k\)</span>.</p>
<p>The individual components of a multinomial random vector are binomial and have a binomial distribution, <span class="math inline">\(X_i = Bin(n, \pi_i)\)</span>. Binomial is a special case of multinomial for k = 2.</p>
<p>Suppose a city population is 20% black, 15% Hispanic, and 65% other. From a random sample of <span class="math inline">\(n = 12\)</span> persons, what is the probability of 4 black and 8 other?</p>
<p><span class="math display">\[f(x;\pi) = \frac{12!}{4! 0! 8!} (0.20)^4 (0.15)^0 (0.65)^8 = 0.0252\]</span></p>
<p>Function <code>dmultinom()</code> calculates the multinomial probability.</p>
<div class="sourceCode" id="cb52"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb52-1"><a href="probability.html#cb52-1"></a><span class="kw">dmultinom</span>(<span class="dt">x =</span> <span class="kw">c</span>(<span class="dv">4</span>, <span class="dv">0</span>, <span class="dv">8</span>), <span class="dt">prob =</span> <span class="kw">c</span>(<span class="fl">0.20</span>, <span class="fl">0.15</span>, <span class="fl">0.65</span>))</span></code></pre></div>
<pre><code>## [1] 0.025</code></pre>
<p>To calculate the probability of <em>&lt;= 1</em> black, combine Hispanic and other, then sum the probability of black = 1 and black = 2.</p>
<p><span class="math display">\[f(x;\pi) = \frac{12!}{0! 12!} (0.20)^0 (0.80)^{12} + \frac{12!}{1! 11!} (0.20)^1 (0.80)^{11} = 0.2748\]</span></p>
<div class="sourceCode" id="cb54"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb54-1"><a href="probability.html#cb54-1"></a><span class="kw">dmultinom</span>(<span class="dt">x =</span> <span class="kw">c</span>(<span class="dv">0</span>, <span class="dv">12</span>), <span class="dt">prob =</span> <span class="kw">c</span>(<span class="fl">0.20</span>, <span class="fl">0.80</span>)) <span class="op">+</span><span class="st"> </span></span>
<span id="cb54-2"><a href="probability.html#cb54-2"></a><span class="st">  </span><span class="kw">dmultinom</span>(<span class="dt">x =</span> <span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">11</span>), <span class="dt">prob =</span> <span class="kw">c</span>(<span class="fl">0.20</span>, <span class="fl">0.80</span>))</span></code></pre></div>
<pre><code>## [1] 0.27</code></pre>
</div>
<div id="negative-binomial" class="section level3">
<h3><span class="header-section-number">1.2.5</span> Negative-Binomial</h3>
<p>If <span class="math inline">\(X\)</span> is the count of failure events ocurring prior to reaching <span class="math inline">\(r\)</span> successful events in a sequence of Bernouli trias of success probability <span class="math inline">\(p\)</span>, then <span class="math inline">\(X\)</span> is a random variable with a negative-binomial distribution <span class="math inline">\(X \sim NB(r, p)\)</span>. The probability of <span class="math inline">\(X = x\)</span> failures prior to <span class="math inline">\(r\)</span> successes is</p>
<p><span class="math display">\[f(x;r, p) = {{x + r - 1} \choose {r - 1}} p^r (1-p)^{x}.\]</span></p>
<p>with <span class="math inline">\(E(X) = r (1 - p) / p\)</span> and <span class="math inline">\(Var(X) = r (1-p) / p^2\)</span>.</p>
<p>When the data has overdispersion, model the data with the negative-binomial distribution instead of Poission.</p>
<div id="examples" class="section level4 unnumbered">
<h4>Examples</h4>
<p>An oil company has a <span class="math inline">\(p = 0.20\)</span> chance of striking oil when drilling a well. What is the probability the company drills <span class="math inline">\(x + r = 7\)</span> wells to strike oil <span class="math inline">\(r = 3\)</span> times? Note that the question is formulated as counting total events, <span class="math inline">\(x + r = 7\)</span>, so translate it to total <em>failed</em> events, <span class="math inline">\(x = 4\)</span>.</p>
<p><span class="math display">\[f(x;r, p) = {{4 + 3 - 1} \choose {3 - 1}} (0.20)^3 (1 - 0.20)^4 = 0.049.\]</span></p>
<p>Function <code>dnbinom()</code> calculates the negative-binomial probability. Parameter <code>x</code> equals the number of failures, <span class="math inline">\(x - r\)</span>.</p>
<div class="sourceCode" id="cb56"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb56-1"><a href="probability.html#cb56-1"></a><span class="kw">dnbinom</span>(<span class="dt">x =</span> <span class="dv">4</span>, <span class="dt">size =</span> <span class="dv">3</span>, <span class="dt">prob =</span> <span class="fl">0.2</span>)</span></code></pre></div>
<pre><code>## [1] 0.049</code></pre>
<p>The expected number of failures prior to 3 successes is <span class="math inline">\(E(X) = 3 (1 - 0.20) / 0.20 = 12\)</span> with variance <span class="math inline">\(Var(X) = 3 (1 - 0.20) / 0.20^2 = 60\)</span>. Confirm this with a simulation from n = 10,000 random samples using <code>rnbinom()</code>.</p>
<div class="sourceCode" id="cb58"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb58-1"><a href="probability.html#cb58-1"></a>my_dat &lt;-<span class="st"> </span><span class="kw">rnbinom</span>(<span class="dt">n =</span> <span class="dv">10000</span>, <span class="dt">size =</span> <span class="dv">3</span>, <span class="dt">prob =</span> <span class="fl">0.20</span>)</span>
<span id="cb58-2"><a href="probability.html#cb58-2"></a><span class="kw">mean</span>(my_dat)</span></code></pre></div>
<pre><code>## [1] 12</code></pre>
<div class="sourceCode" id="cb60"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb60-1"><a href="probability.html#cb60-1"></a><span class="kw">var</span>(my_dat)</span></code></pre></div>
<pre><code>## [1] 60</code></pre>
<p><img src="data-sci_files/figure-html/unnamed-chunk-36-1.png" width="576" /></p>
</div>
</div>
<div id="geometric" class="section level3">
<h3><span class="header-section-number">1.2.6</span> Geometric</h3>
<p>If <span class="math inline">\(X\)</span> is the count of Bernoulli trials of success probability <span class="math inline">\(p\)</span> required to achieve the first successful event, then <span class="math inline">\(X\)</span> is a random variable with a geometric distribution <span class="math inline">\(X \sim G(p)\)</span>. The probability of <span class="math inline">\(X = x\)</span> trials is</p>
<p><span class="math display">\[f(x; p) = p(1-p)^{x-1}.\]</span></p>
<p>with <span class="math inline">\(E(X)=\frac{{n}}{{p}}\)</span> and <span class="math inline">\(Var(X) = \frac{(1-p)}{p^2}\)</span>. The probability of <span class="math inline">\(X&lt;=n\)</span> trials is</p>
<p><span class="math display">\[F(X=n) = 1 - (1-p)^n.\]</span></p>
<div id="examples-1" class="section level4 unnumbered">
<h4>Examples</h4>
<p>What is the probability a marketer encounters x = 3 people on the street who did not attend a sporting event before the first success if the population probability is p = 0.20?</p>
<p><span class="math display">\[f(4; 0.20) = 0.20(1-0.20)^{4-1} = 0.102.\]</span></p>
<p>Function <code>dgeom()</code> calculates the geometric distribution probability. Parameter <code>x</code> is the number of <em>failures</em>, not the number of trials.</p>
<div class="sourceCode" id="cb62"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb62-1"><a href="probability.html#cb62-1"></a><span class="kw">dgeom</span>(<span class="dt">x =</span> <span class="dv">3</span>, <span class="dt">prob =</span> <span class="fl">0.20</span>)</span></code></pre></div>
<pre><code>## [1] 0.1</code></pre>
<div class="sourceCode" id="cb64"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb64-1"><a href="probability.html#cb64-1"></a><span class="kw">data.frame</span>(<span class="dt">cnt =</span> <span class="kw">rgeom</span>(<span class="dt">n =</span> <span class="dv">10000</span>, <span class="dt">prob =</span> <span class="fl">0.20</span>)) <span class="op">%&gt;%</span></span>
<span id="cb64-2"><a href="probability.html#cb64-2"></a><span class="st">  </span><span class="kw">count</span>(cnt) <span class="op">%&gt;%</span></span>
<span id="cb64-3"><a href="probability.html#cb64-3"></a><span class="st">  </span><span class="kw">top_n</span>(<span class="dt">n =</span> <span class="dv">15</span>, <span class="dt">wt =</span> n) <span class="op">%&gt;%</span></span>
<span id="cb64-4"><a href="probability.html#cb64-4"></a><span class="st">  </span><span class="kw">ungroup</span>() <span class="op">%&gt;%</span></span>
<span id="cb64-5"><a href="probability.html#cb64-5"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">pct =</span> <span class="kw">round</span>(n <span class="op">/</span><span class="st"> </span><span class="kw">sum</span>(n), <span class="dv">3</span>),</span>
<span id="cb64-6"><a href="probability.html#cb64-6"></a>         <span class="dt">X_eq_x =</span> cnt <span class="op">==</span><span class="st"> </span><span class="dv">3</span>) <span class="op">%&gt;%</span></span>
<span id="cb64-7"><a href="probability.html#cb64-7"></a><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> <span class="kw">as.factor</span>(cnt), <span class="dt">y =</span> n, <span class="dt">fill =</span> X_eq_x, <span class="dt">label =</span> pct)) <span class="op">+</span></span>
<span id="cb64-8"><a href="probability.html#cb64-8"></a><span class="st">  </span><span class="kw">geom_col</span>(<span class="dt">alpha =</span> <span class="fl">0.8</span>) <span class="op">+</span></span>
<span id="cb64-9"><a href="probability.html#cb64-9"></a><span class="st">  </span><span class="kw">scale_fill_mf</span>() <span class="op">+</span></span>
<span id="cb64-10"><a href="probability.html#cb64-10"></a><span class="st">  </span><span class="kw">geom_text</span>(<span class="dt">size =</span> <span class="dv">3</span>) <span class="op">+</span></span>
<span id="cb64-11"><a href="probability.html#cb64-11"></a><span class="st">  </span><span class="kw">theme_mf</span>() <span class="op">+</span></span>
<span id="cb64-12"><a href="probability.html#cb64-12"></a><span class="st">  </span><span class="kw">theme</span>(<span class="dt">legend.position =</span> <span class="st">&quot;none&quot;</span>) <span class="op">+</span></span>
<span id="cb64-13"><a href="probability.html#cb64-13"></a><span class="st">  </span><span class="kw">labs</span>(<span class="dt">title =</span> <span class="st">&quot;Distribution of trials prior to first success&quot;</span>,</span>
<span id="cb64-14"><a href="probability.html#cb64-14"></a>       <span class="dt">subtitle =</span> <span class="kw">paste</span>(<span class="st">&quot;P(X = 3) | X ~ G(.2) = &quot;</span>, <span class="kw">round</span>(<span class="kw">dgeom</span>(<span class="dv">2</span>, <span class="fl">.2</span>), <span class="dv">3</span>)),</span>
<span id="cb64-15"><a href="probability.html#cb64-15"></a>       <span class="dt">x =</span> <span class="st">&quot;Unsuccessful trials&quot;</span>,</span>
<span id="cb64-16"><a href="probability.html#cb64-16"></a>       <span class="dt">y =</span> <span class="st">&quot;Count&quot;</span>,</span>
<span id="cb64-17"><a href="probability.html#cb64-17"></a>       <span class="dt">caption =</span> <span class="st">&quot;simulation of n = 10,000 samples from geometric dist.&quot;</span>) </span></code></pre></div>
<p><img src="data-sci_files/figure-html/unnamed-chunk-38-1.png" width="480" /></p>
<p>What is the probability the marketer fails to find someone who attended a game in x &lt;= 5 trials before finding someone who attended a game on the sixth trial when the population probability is p = 0.20?</p>
<div class="sourceCode" id="cb65"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb65-1"><a href="probability.html#cb65-1"></a>p =<span class="st"> </span><span class="fl">0.20</span></span>
<span id="cb65-2"><a href="probability.html#cb65-2"></a>n =<span class="st"> </span><span class="dv">5</span></span>
<span id="cb65-3"><a href="probability.html#cb65-3"></a><span class="co"># exact</span></span>
<span id="cb65-4"><a href="probability.html#cb65-4"></a><span class="kw">pgeom</span>(<span class="dt">q =</span> n, <span class="dt">prob =</span> p, <span class="dt">lower.tail =</span> <span class="ot">TRUE</span>)</span></code></pre></div>
<pre><code>## [1] 0.74</code></pre>
<div class="sourceCode" id="cb67"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb67-1"><a href="probability.html#cb67-1"></a><span class="co"># simulated</span></span>
<span id="cb67-2"><a href="probability.html#cb67-2"></a><span class="kw">mean</span>(<span class="kw">rgeom</span>(<span class="dt">n =</span> <span class="dv">10000</span>, <span class="dt">prob =</span> p) <span class="op">&lt;=</span><span class="st"> </span>n)</span></code></pre></div>
<pre><code>## [1] 0.74</code></pre>
<p><img src="data-sci_files/figure-html/unnamed-chunk-40-1.png" width="480" /></p>
<p>What is the probability the marketer fails to find someone who attended a game on x &gt;= 5 trials before finding someone who attended a game on the next trial?</p>
<div class="sourceCode" id="cb69"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb69-1"><a href="probability.html#cb69-1"></a>p =<span class="st"> </span><span class="fl">0.20</span></span>
<span id="cb69-2"><a href="probability.html#cb69-2"></a>n =<span class="st"> </span><span class="dv">5</span></span>
<span id="cb69-3"><a href="probability.html#cb69-3"></a><span class="co"># exact</span></span>
<span id="cb69-4"><a href="probability.html#cb69-4"></a><span class="kw">pgeom</span>(<span class="dt">q =</span> n, <span class="dt">prob =</span> p, <span class="dt">lower.tail =</span> <span class="ot">FALSE</span>)</span></code></pre></div>
<pre><code>## [1] 0.26</code></pre>
<div class="sourceCode" id="cb71"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb71-1"><a href="probability.html#cb71-1"></a><span class="co"># simulated</span></span>
<span id="cb71-2"><a href="probability.html#cb71-2"></a><span class="kw">mean</span>(<span class="kw">rgeom</span>(<span class="dt">n =</span> <span class="dv">10000</span>, <span class="dt">prob =</span> p) <span class="op">&gt;</span><span class="st"> </span>n)</span></code></pre></div>
<pre><code>## [1] 0.26</code></pre>
<p><img src="data-sci_files/figure-html/unnamed-chunk-42-1.png" width="480" /></p>
<p>The expected number of trials to achieve the first success is <code>1 / 0.20 =</code> 5, <code>Var(X) = (1 - 0.20) / 0.20^2 =</code> 20?</p>
<div class="sourceCode" id="cb73"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb73-1"><a href="probability.html#cb73-1"></a>p =<span class="st"> </span><span class="fl">0.20</span></span>
<span id="cb73-2"><a href="probability.html#cb73-2"></a><span class="co"># mean</span></span>
<span id="cb73-3"><a href="probability.html#cb73-3"></a><span class="co"># exact</span></span>
<span id="cb73-4"><a href="probability.html#cb73-4"></a><span class="dv">1</span> <span class="op">/</span><span class="st"> </span>p</span></code></pre></div>
<pre><code>## [1] 5</code></pre>
<div class="sourceCode" id="cb75"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb75-1"><a href="probability.html#cb75-1"></a><span class="co"># simulated</span></span>
<span id="cb75-2"><a href="probability.html#cb75-2"></a><span class="kw">mean</span>(<span class="kw">rgeom</span>(<span class="dt">n =</span> <span class="dv">10000</span>, <span class="dt">prob =</span> p)) <span class="op">+</span><span class="st"> </span><span class="dv">1</span></span></code></pre></div>
<pre><code>## [1] 5</code></pre>
<div class="sourceCode" id="cb77"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb77-1"><a href="probability.html#cb77-1"></a><span class="co"># Variance</span></span>
<span id="cb77-2"><a href="probability.html#cb77-2"></a><span class="co"># exact</span></span>
<span id="cb77-3"><a href="probability.html#cb77-3"></a>(<span class="dv">1</span> <span class="op">-</span><span class="st"> </span>p) <span class="op">/</span><span class="st"> </span>p<span class="op">^</span><span class="dv">2</span></span></code></pre></div>
<pre><code>## [1] 20</code></pre>
<div class="sourceCode" id="cb79"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb79-1"><a href="probability.html#cb79-1"></a><span class="co"># simulated</span></span>
<span id="cb79-2"><a href="probability.html#cb79-2"></a><span class="kw">var</span>(<span class="kw">rgeom</span>(<span class="dt">n =</span> <span class="dv">100000</span>, <span class="dt">prob =</span> p))</span></code></pre></div>
<pre><code>## [1] 20</code></pre>
</div>
</div>
<div id="hypergeometric" class="section level3">
<h3><span class="header-section-number">1.2.7</span> Hypergeometric</h3>
<p>If <span class="math inline">\(X = k\)</span> is the count of successful events in a sample of size <span class="math inline">\(n\)</span> <em>without replacement</em> from a population of size <span class="math inline">\(N\)</span> containing <span class="math inline">\(K\)</span> successes, then <span class="math inline">\(X\)</span> is a random variable with a hypergeometric distribution</p>
<p><span class="math display">\[f_X(k|N, K, n) = \frac{{{K}\choose{k}}{{N-K}\choose{n-k}}}{{N}\choose{n}}.\]</span></p>
<p>with <span class="math inline">\(E(X)=n\frac{K}{N}\)</span> and <span class="math inline">\(Var(X) = n\frac{K}{N}\cdot\frac{N-k}{N}\cdot\frac{N-n}{N-1}\)</span>.</p>
<p>The formula follows from the frequency table of the possible outcomes.</p>
<table>
<thead>
<tr class="header">
<th></th>
<th>Sampled</th>
<th>Not Sampled</th>
<th>Total</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>success</td>
<td>k</td>
<td>K-k</td>
<td>K</td>
</tr>
<tr class="even">
<td>non-success</td>
<td>n-k</td>
<td>(N-K)-(n-k)</td>
<td>N-K</td>
</tr>
<tr class="odd">
<td>Total</td>
<td>n</td>
<td>N-n</td>
<td>N</td>
</tr>
</tbody>
</table>
<p>Here is a simple analysis of data from a hypergeometric process. What is the probability of selecting <span class="math inline">\(k = 14\)</span> red marbles from a sample of <span class="math inline">\(n = 20\)</span> taken from an urn containing <span class="math inline">\(K = 70\)</span> red marbles and <span class="math inline">\(N-K = 30\)</span> green marbles?</p>
<p>Function <code>choose()</code> returns the binomial coefficient <span class="math inline">\({{n}\choose{k}} = \frac{n!}{k!(n-k)!}\)</span>.</p>
<div class="sourceCode" id="cb81"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb81-1"><a href="probability.html#cb81-1"></a>k &lt;-<span class="st"> </span><span class="dv">14</span>; n &lt;-<span class="st"> </span><span class="dv">20</span>; N &lt;-<span class="st"> </span><span class="dv">100</span>; K &lt;-<span class="st"> </span><span class="dv">70</span></span>
<span id="cb81-2"><a href="probability.html#cb81-2"></a><span class="kw">choose</span>(K, k) <span class="op">*</span><span class="st"> </span><span class="kw">choose</span>(N<span class="op">-</span>K, n<span class="op">-</span>k) <span class="op">/</span><span class="st"> </span><span class="kw">choose</span>(N, n)</span></code></pre></div>
<pre><code>## [1] 0.21</code></pre>
<p>But of course you would never have to do it that way.</p>
<div class="sourceCode" id="cb83"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb83-1"><a href="probability.html#cb83-1"></a><span class="kw">dhyper</span>(<span class="dt">x =</span> k, <span class="dt">m =</span> K, <span class="dt">n =</span> N<span class="op">-</span>K, <span class="dt">k =</span> n)</span></code></pre></div>
<pre><code>## [1] 0.21</code></pre>
<p>The expected value is 14 and variance is 9.73.</p>
<p><img src="data-sci_files/figure-html/unnamed-chunk-46-1.png" width="672" /></p>
<p>The hypergeometric random variable is similar to the binomial random variable except that it applies to situations of sampling <em>without</em> replacement from a small population. As the population size increases, sampling without replacement converges to sampling <em>with</em> replacement, and the hypergeometric distribution converges to the binomial. What if the total population size had been 250? 500? 1000?</p>
<div class="sourceCode" id="cb85"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb85-1"><a href="probability.html#cb85-1"></a>p &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="dt">x =</span> <span class="dv">1</span><span class="op">:</span><span class="dv">20</span>) <span class="op">%&gt;%</span></span>
<span id="cb85-2"><a href="probability.html#cb85-2"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">density =</span> <span class="kw">dbinom</span>(<span class="dt">x =</span> <span class="dv">1</span><span class="op">:</span><span class="dv">20</span>, <span class="dt">size =</span> n, <span class="dt">prob =</span> K <span class="op">/</span><span class="st"> </span>N)) <span class="op">%&gt;%</span></span>
<span id="cb85-3"><a href="probability.html#cb85-3"></a><span class="st">  </span><span class="kw">ggplot</span>() <span class="op">+</span></span>
<span id="cb85-4"><a href="probability.html#cb85-4"></a><span class="st">  </span><span class="kw">geom_col</span>(<span class="kw">aes</span>(<span class="dt">x =</span> x, <span class="dt">y =</span> density))</span>
<span id="cb85-5"><a href="probability.html#cb85-5"></a>hyper &lt;-<span class="st"> </span><span class="kw">data.frame</span>(</span>
<span id="cb85-6"><a href="probability.html#cb85-6"></a>  <span class="dt">x =</span> <span class="dv">1</span><span class="op">:</span><span class="dv">20</span>,</span>
<span id="cb85-7"><a href="probability.html#cb85-7"></a>  <span class="dt">N_100 =</span> <span class="kw">dhyper</span>(<span class="dt">x =</span> <span class="dv">1</span><span class="op">:</span><span class="dv">20</span>, <span class="dt">m =</span> K<span class="op">*</span><span class="fl">1.0</span>, <span class="dt">n =</span> (N<span class="op">-</span>K)<span class="op">*</span><span class="fl">1.0</span>, <span class="dt">k =</span> n),</span>
<span id="cb85-8"><a href="probability.html#cb85-8"></a>  <span class="dt">N_250 =</span> <span class="kw">dhyper</span>(<span class="dt">x =</span> <span class="dv">1</span><span class="op">:</span><span class="dv">20</span>, <span class="dt">m =</span> K<span class="op">*</span><span class="fl">2.5</span>, <span class="dt">n =</span> (N<span class="op">-</span>K)<span class="op">*</span><span class="fl">2.5</span>, <span class="dt">k =</span> n),</span>
<span id="cb85-9"><a href="probability.html#cb85-9"></a>  <span class="dt">N_500 =</span> <span class="kw">dhyper</span>(<span class="dt">x =</span> <span class="dv">1</span><span class="op">:</span><span class="dv">20</span>, <span class="dt">m =</span> K<span class="op">*</span><span class="fl">5.0</span>, <span class="dt">n =</span> (N<span class="op">-</span>K)<span class="op">*</span><span class="fl">5.0</span>, <span class="dt">k =</span> n)</span>
<span id="cb85-10"><a href="probability.html#cb85-10"></a>) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">pivot_longer</span>(<span class="op">-</span>x)</span>
<span id="cb85-11"><a href="probability.html#cb85-11"></a>p <span class="op">+</span><span class="st"> </span><span class="kw">geom_line</span>(<span class="dt">data =</span> hyper, <span class="kw">aes</span>(<span class="dt">x =</span> x, <span class="dt">y =</span> value, <span class="dt">color =</span> name)) <span class="op">+</span></span>
<span id="cb85-12"><a href="probability.html#cb85-12"></a><span class="st">  </span><span class="kw">labs</span>() <span class="op">+</span></span>
<span id="cb85-13"><a href="probability.html#cb85-13"></a><span class="st">  </span><span class="kw">theme_minimal</span>() <span class="op">+</span></span>
<span id="cb85-14"><a href="probability.html#cb85-14"></a><span class="st">  </span><span class="kw">theme</span>(<span class="dt">legend.position =</span> <span class="st">&quot;top&quot;</span>) <span class="op">+</span></span>
<span id="cb85-15"><a href="probability.html#cb85-15"></a><span class="st">  </span><span class="kw">labs</span>(<span class="dt">title =</span> <span class="st">&quot;P(X = k) when X ~ Hypergeometric(N, .7N, 20)&quot;</span>, <span class="dt">color =</span> <span class="st">&quot;&quot;</span>, <span class="dt">x =</span> <span class="st">&quot;k&quot;</span>)</span></code></pre></div>
<p><img src="data-sci_files/figure-html/unnamed-chunk-47-1.png" width="672" /></p>
</div>
<div id="gamma" class="section level3">
<h3><span class="header-section-number">1.2.8</span> Gamma</h3>
<p>If <span class="math inline">\(X\)</span> is the interval until the <span class="math inline">\(\alpha^{th}\)</span> successful event when the average interval is <span class="math inline">\(\theta\)</span>, then <span class="math inline">\(X\)</span> is a random variable with a gamma distribution <span class="math inline">\(X \sim \Gamma(\alpha, \theta)\)</span>. The probability of an interval of <span class="math inline">\(X = x\)</span> is</p>
<p><span class="math display">\[f(x; \alpha, \theta) = \frac{1}{\Gamma(\alpha)\theta^\alpha}x^{\alpha-1}e^{-x/\theta}.\]</span></p>
<p>where <span class="math inline">\(\Gamma(\alpha) = (1 - \alpha)!\)</span> with <span class="math inline">\(E(X) = \alpha \theta\)</span> and <span class="math inline">\(Var(X) = \alpha \theta^2\)</span>.</p>
<div id="examples-2" class="section level4 unnumbered">
<h4>Examples</h4>
<p>On average, someone sends a money order once per 15 minutes (<span class="math inline">\(\theta = .25\)</span>). What is the probability someone sends <span class="math inline">\(\alpha = 10\)</span> money orders in less than <span class="math inline">\(x = 3\)</span> hours?*</p>
<div class="sourceCode" id="cb86"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb86-1"><a href="probability.html#cb86-1"></a>theta =<span class="st"> </span><span class="fl">0.25</span></span>
<span id="cb86-2"><a href="probability.html#cb86-2"></a>alpha =<span class="st"> </span><span class="dv">10</span></span>
<span id="cb86-3"><a href="probability.html#cb86-3"></a><span class="kw">pgamma</span>(<span class="dt">q =</span> <span class="dv">3</span>, <span class="dt">shape =</span> alpha, <span class="dt">scale =</span> <span class="fl">0.25</span>)</span></code></pre></div>
<pre><code>## [1] 0.76</code></pre>
<div class="sourceCode" id="cb88"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb88-1"><a href="probability.html#cb88-1"></a><span class="kw">data.frame</span>(<span class="dt">x =</span> <span class="dv">0</span><span class="op">:</span><span class="dv">1000</span> <span class="op">/</span><span class="st"> </span><span class="dv">100</span>, <span class="dt">prob =</span> <span class="kw">pgamma</span>(<span class="dt">q =</span> <span class="dv">0</span><span class="op">:</span><span class="dv">1000</span> <span class="op">/</span><span class="st"> </span><span class="dv">100</span>, <span class="dt">shape =</span> alpha, <span class="dt">scale =</span> theta, <span class="dt">lower.tail =</span> <span class="ot">TRUE</span>)) <span class="op">%&gt;%</span></span>
<span id="cb88-2"><a href="probability.html#cb88-2"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">Interval =</span> <span class="kw">ifelse</span>(x <span class="op">&gt;=</span><span class="st"> </span><span class="dv">0</span> <span class="op">&amp;</span><span class="st"> </span>x <span class="op">&lt;=</span><span class="st"> </span><span class="dv">3</span>, <span class="st">&quot;0 to 3&quot;</span>, <span class="st">&quot;other&quot;</span>)) <span class="op">%&gt;%</span></span>
<span id="cb88-3"><a href="probability.html#cb88-3"></a><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> x, <span class="dt">y =</span> prob, <span class="dt">fill =</span> Interval)) <span class="op">+</span></span>
<span id="cb88-4"><a href="probability.html#cb88-4"></a><span class="st">  </span><span class="kw">geom_area</span>(<span class="dt">alpha =</span> <span class="fl">0.9</span>) <span class="op">+</span></span>
<span id="cb88-5"><a href="probability.html#cb88-5"></a><span class="st">  </span><span class="kw">theme_mf</span>() <span class="op">+</span></span>
<span id="cb88-6"><a href="probability.html#cb88-6"></a><span class="st">  </span><span class="kw">scale_fill_mf</span>() <span class="op">+</span></span>
<span id="cb88-7"><a href="probability.html#cb88-7"></a><span class="st">  </span><span class="kw">labs</span>(<span class="dt">title =</span> <span class="st">&quot;X ~ Gam(alpha = 10, theta = .25)&quot;</span>,</span>
<span id="cb88-8"><a href="probability.html#cb88-8"></a>       <span class="dt">subtitle =</span> <span class="st">&quot;Probability of 10 events in X hours when the mean time to an event is .25 hours.&quot;</span>,</span>
<span id="cb88-9"><a href="probability.html#cb88-9"></a>       <span class="dt">x =</span> <span class="st">&quot;Interval (x)&quot;</span>,</span>
<span id="cb88-10"><a href="probability.html#cb88-10"></a>       <span class="dt">y =</span> <span class="st">&quot;pgamma&quot;</span>) </span></code></pre></div>
<p><img src="data-sci_files/figure-html/unnamed-chunk-49-1.png" width="672" /></p>
</div>
</div>
</div>
<div id="cont_dist" class="section level2">
<h2><span class="header-section-number">1.3</span> Continuous Distributions</h2>
<div id="normal" class="section level3">
<h3><span class="header-section-number">1.3.1</span> Normal</h3>
<p>Random variable <span class="math inline">\(X\)</span> is distributed <span class="math inline">\(X \sim N(\mu, \sigma^2)\)</span> if</p>
<p><span class="math display">\[f(X)=\frac{{1}}{{\sigma \sqrt{{2\pi}}}}e^{-.5(\frac{{x-\mu}}{{\sigma}})^2}\]</span>.</p>
<p>Suppose IQ scores are distributed <span class="math inline">\(X \sim N\left(100, 16^2\right)\)</span>.</p>
<p><img src="data-sci_files/figure-html/unnamed-chunk-50-1.png" width="672" /></p>
<div class="sourceCode" id="cb89"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb89-1"><a href="probability.html#cb89-1"></a><span class="kw">pnorm</span>(<span class="dt">q =</span> <span class="dv">90</span>, <span class="dt">mean =</span> <span class="dv">100</span>, <span class="dt">sd =</span> <span class="dv">16</span>, <span class="dt">lower.tail =</span> <span class="ot">TRUE</span>)</span>
<span id="cb89-2"><a href="probability.html#cb89-2"></a><span class="co">## [1] 0.27</span></span></code></pre></div>
<p><img src="data-sci_files/figure-html/unnamed-chunk-52-1.png" width="672" /></p>
<div class="sourceCode" id="cb90"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb90-1"><a href="probability.html#cb90-1"></a><span class="kw">pnorm</span>(<span class="dt">q =</span> <span class="dv">140</span>, <span class="dt">mean =</span> <span class="dv">100</span>, <span class="dt">sd =</span> <span class="dv">16</span>, <span class="dt">lower.tail =</span> <span class="ot">FALSE</span>)</span>
<span id="cb90-2"><a href="probability.html#cb90-2"></a><span class="co">## [1] 0.0062</span></span></code></pre></div>
<p><img src="data-sci_files/figure-html/unnamed-chunk-54-1.png" width="672" /></p>
<div class="sourceCode" id="cb91"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb91-1"><a href="probability.html#cb91-1"></a><span class="kw">pnorm</span>(<span class="dt">q =</span> <span class="dv">114</span>, <span class="dt">mean =</span> <span class="dv">100</span>, <span class="dt">sd =</span> <span class="dv">16</span>, <span class="dt">lower.tail =</span> <span class="ot">TRUE</span>) <span class="op">-</span></span>
<span id="cb91-2"><a href="probability.html#cb91-2"></a><span class="st">  </span><span class="kw">pnorm</span>(<span class="dt">q =</span> <span class="dv">92</span>, <span class="dt">mean =</span> <span class="dv">100</span>, <span class="dt">sd =</span> <span class="dv">16</span>, <span class="dt">lower.tail =</span> <span class="ot">TRUE</span>)</span>
<span id="cb91-3"><a href="probability.html#cb91-3"></a><span class="co">## [1] 0.5</span></span></code></pre></div>
<p><img src="data-sci_files/figure-html/unnamed-chunk-56-1.png" width="672" /></p>
<div class="sourceCode" id="cb92"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb92-1"><a href="probability.html#cb92-1"></a><span class="kw">qnorm</span>(<span class="dt">p =</span> <span class="fl">0.90</span>, <span class="dt">mean =</span> <span class="dv">100</span>, <span class="dt">sd =</span> <span class="dv">16</span>, <span class="dt">lower.tail =</span> <span class="ot">TRUE</span>)</span>
<span id="cb92-2"><a href="probability.html#cb92-2"></a><span class="co">## [1] 121</span></span></code></pre></div>
<p>By the central limit theorem (CLT) the binomial distribution <span class="math inline">\(X \sim B(n,p)\)</span> approaches the normal distribution with mean <span class="math inline">\(\mu = n p\)</span> and variance <span class="math inline">\(\sigma^2=np(1-p)\)</span> as <span class="math inline">\(n \rightarrow \infty\)</span>. The approximation is useful when the expected number of successes and failures is at least 5, <span class="math inline">\(np&gt;=5\)</span> and <span class="math inline">\(n(1-p)&gt;=5\)</span>.</p>
<p>Suppose a measure requires p&gt;=50% popular to pass. A sample of n=1,000 yields x=460 approvals. What is the probability that the overall population approves, P(X)&gt;0.5?</p>
<div class="sourceCode" id="cb93"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb93-1"><a href="probability.html#cb93-1"></a><span class="co"># Exact binomial</span></span>
<span id="cb93-2"><a href="probability.html#cb93-2"></a><span class="kw">pbinom</span>(<span class="dt">q =</span> <span class="dv">460</span>, <span class="dt">size =</span> <span class="dv">1000</span>, <span class="dt">prob =</span> <span class="fl">0.50</span>, <span class="dt">lower.tail =</span> <span class="ot">TRUE</span>)</span>
<span id="cb93-3"><a href="probability.html#cb93-3"></a><span class="co">## [1] 0.0062</span></span>
<span id="cb93-4"><a href="probability.html#cb93-4"></a></span>
<span id="cb93-5"><a href="probability.html#cb93-5"></a><span class="co"># Normal approximation</span></span>
<span id="cb93-6"><a href="probability.html#cb93-6"></a><span class="kw">pnorm</span>(<span class="dt">q =</span> <span class="dv">460</span>, <span class="dt">mean =</span> <span class="fl">0.50</span> <span class="op">*</span><span class="st"> </span><span class="dv">1000</span>, <span class="dt">sd =</span> <span class="kw">sqrt</span>(<span class="dv">1000</span> <span class="op">*</span><span class="st"> </span><span class="fl">0.50</span> <span class="op">*</span><span class="st"> </span>(<span class="dv">1</span> <span class="op">-</span><span class="st"> </span><span class="fl">0.50</span>)), <span class="dt">lower.tail =</span> <span class="ot">TRUE</span>)</span>
<span id="cb93-7"><a href="probability.html#cb93-7"></a><span class="co">## [1] 0.0057</span></span></code></pre></div>
<p><img src="data-sci_files/figure-html/unnamed-chunk-59-1.png" width="672" /></p>
<p>By the central limit theorem (CLT) the Poisson distribution <span class="math inline">\(x~P(\lambda)\)</span> approaches the normal distribution with mean <span class="math inline">\(\mu = \lambda\)</span> and variance <span class="math inline">\(\sigma^2 = \lambda\)</span> as <span class="math inline">\(n \rightarrow \infty\)</span>. The approximation is useful for large values of <span class="math inline">\(\lambda\)</span>.</p>
<p>Suppose the annual number of earthquakes registering at least 2.5 on the Richter Scale and having an epicenter within 40 miles of downtown Memphis follows a Poisson distribution with mean <span class="math inline">\(\lambda=6.5\)</span>. What is the probability that at least <span class="math inline">\(x&gt;=9\)</span> such earthquakes will strike next year?</p>
<div class="sourceCode" id="cb94"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb94-1"><a href="probability.html#cb94-1"></a><span class="co"># Exact Poisson</span></span>
<span id="cb94-2"><a href="probability.html#cb94-2"></a><span class="kw">ppois</span>(<span class="dt">q =</span> <span class="dv">9</span> <span class="op">-</span><span class="st"> </span><span class="dv">1</span>, <span class="dt">lambda =</span> <span class="fl">6.5</span>, <span class="dt">lower.tail =</span> <span class="ot">FALSE</span>)</span>
<span id="cb94-3"><a href="probability.html#cb94-3"></a><span class="co">## [1] 0.21</span></span>
<span id="cb94-4"><a href="probability.html#cb94-4"></a></span>
<span id="cb94-5"><a href="probability.html#cb94-5"></a><span class="co"># Normal approximation</span></span>
<span id="cb94-6"><a href="probability.html#cb94-6"></a><span class="kw">pnorm</span>(<span class="dt">q =</span> <span class="dv">9</span> <span class="op">-</span><span class="st"> </span><span class="fl">0.5</span>, <span class="dt">mean =</span> <span class="fl">6.5</span>, <span class="dt">sd =</span> <span class="kw">sqrt</span>(<span class="fl">6.5</span>), <span class="dt">lower.tail =</span> <span class="ot">FALSE</span>)</span>
<span id="cb94-7"><a href="probability.html#cb94-7"></a><span class="co">## [1] 0.22</span></span></code></pre></div>
<p><img src="data-sci_files/figure-html/unnamed-chunk-61-1.png" width="672" /></p>
<p>Estimate the population from the sample using the CLT. Suppose a person’s blood pressure typically measures <span class="math inline">\(160 \pm 20\)</span> mm. If one takes n=5 blood pressure readings, what is the probability the average will be &lt;=150?*</p>
<div class="sourceCode" id="cb95"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb95-1"><a href="probability.html#cb95-1"></a><span class="kw">pnorm</span>(<span class="dt">q =</span> <span class="dv">150</span>, <span class="dt">mean =</span> <span class="dv">160</span>, <span class="dt">sd =</span> <span class="dv">20</span> <span class="op">/</span><span class="st"> </span><span class="kw">sqrt</span>(<span class="dv">5</span>), <span class="dt">lower.tail =</span> <span class="ot">TRUE</span>)</span>
<span id="cb95-2"><a href="probability.html#cb95-2"></a><span class="co">## [1] 0.13</span></span></code></pre></div>
<div id="shapiro-wilk-test" class="section level4">
<h4><span class="header-section-number">1.3.1.1</span> Shapiro-Wilk Test</h4>
<p>The Shapiro-Wilk test is a test of whether a random variable is normally distributed. It uses test statistic</p>
<p><span class="math display">\[W = \frac{\left(\sum_{i=1}^n a_i x_{(i)}\right)^2}{\left(\sum_{(i=1)}^n x_i-\bar{x}\right)^2}\]</span>
where <span class="math inline">\(x_{(i)}\)</span> is the ith smallest number in the sample and <span class="math inline">\(a_i\)</span> are coefficients calculated as <span class="math inline">\(\left(m^TV^{-1}\right)/C\)</span> where <span class="math inline">\(V\)</span> is the covariance matrix and <span class="math inline">\(m\)</span> and <span class="math inline">\(C\)</span> are vector norms.</p>
<p>The test uses <span class="math inline">\(H_0\)</span> of normality, so the <em>p</em>-value is the probability of rejecting normality. As an example, Shapiro-Wilk rejects normality for a small sample of 10 from the binomial distribution, but does not reject it from a larger sample of 30.</p>
<div class="sourceCode" id="cb96"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb96-1"><a href="probability.html#cb96-1"></a><span class="kw">shapiro.test</span>(<span class="kw">rbinom</span>(<span class="dv">100</span>, <span class="dv">10</span>, <span class="fl">.3</span>))</span>
<span id="cb96-2"><a href="probability.html#cb96-2"></a><span class="co">## </span></span>
<span id="cb96-3"><a href="probability.html#cb96-3"></a><span class="co">##  Shapiro-Wilk normality test</span></span>
<span id="cb96-4"><a href="probability.html#cb96-4"></a><span class="co">## </span></span>
<span id="cb96-5"><a href="probability.html#cb96-5"></a><span class="co">## data:  rbinom(100, 10, 0.3)</span></span>
<span id="cb96-6"><a href="probability.html#cb96-6"></a><span class="co">## W = 0.9, p-value = 0.0001</span></span>
<span id="cb96-7"><a href="probability.html#cb96-7"></a><span class="kw">shapiro.test</span>(<span class="kw">rbinom</span>(<span class="dv">100</span>, <span class="dv">30</span>, <span class="fl">.3</span>))</span>
<span id="cb96-8"><a href="probability.html#cb96-8"></a><span class="co">## </span></span>
<span id="cb96-9"><a href="probability.html#cb96-9"></a><span class="co">##  Shapiro-Wilk normality test</span></span>
<span id="cb96-10"><a href="probability.html#cb96-10"></a><span class="co">## </span></span>
<span id="cb96-11"><a href="probability.html#cb96-11"></a><span class="co">## data:  rbinom(100, 30, 0.3)</span></span>
<span id="cb96-12"><a href="probability.html#cb96-12"></a><span class="co">## W = 1, p-value = 0.1</span></span></code></pre></div>
</div>
</div>
<div id="chi-squared" class="section level3">
<h3><span class="header-section-number">1.3.2</span> Chi-Squared</h3>
<p>Random variable <span class="math inline">\(X\)</span> is distributed <span class="math inline">\(X \sim \chi^2_k\)</span> if</p>
<p><span class="math display">\[f(X)=\frac{1}{2^{k/2}\Gamma (k/2)} x^{k/2-1} e^{-x/2}\]</span></p>
<p>with <span class="math inline">\(E(X)=k\)</span> and <span class="math inline">\(Var(X) = 2k\)</span>.</p>
<p>Suppose a researcher crosses tall cut-leaf tomatoes with dwarf potato-leaf tomatoes, then classifies the (<em>n</em> = 1,611) offspring phenotypes. The four phenotypes are expected to occur with relative frequencies 9:3:3:1. What is the probability of observing frequencies 926, 288, 293, 104?</p>
<div class="sourceCode" id="cb97"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb97-1"><a href="probability.html#cb97-1"></a>cell_names &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;tall cut-leaf&quot;</span>, <span class="st">&quot;tall potato-leaf&quot;</span>, <span class="st">&quot;dwarf cut-leaf&quot;</span>, <span class="st">&quot;dwarf potato-leaf&quot;</span>)</span>
<span id="cb97-2"><a href="probability.html#cb97-2"></a></span>
<span id="cb97-3"><a href="probability.html#cb97-3"></a>o &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="dv">926</span>, <span class="dv">288</span>, <span class="dv">293</span>, <span class="dv">104</span>)</span>
<span id="cb97-4"><a href="probability.html#cb97-4"></a><span class="kw">names</span>(o) &lt;-<span class="st"> </span>cell_names</span>
<span id="cb97-5"><a href="probability.html#cb97-5"></a></span>
<span id="cb97-6"><a href="probability.html#cb97-6"></a>pi &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="dv">9</span>, <span class="dv">3</span>, <span class="dv">3</span>, <span class="dv">1</span>) <span class="op">/</span><span class="st"> </span>(<span class="dv">9</span> <span class="op">+</span><span class="st"> </span><span class="dv">3</span> <span class="op">+</span><span class="st"> </span><span class="dv">3</span> <span class="op">+</span><span class="st"> </span><span class="dv">1</span>)</span>
<span id="cb97-7"><a href="probability.html#cb97-7"></a>e &lt;-<span class="st"> </span><span class="kw">sum</span>(o) <span class="op">*</span><span class="st"> </span>pi</span>
<span id="cb97-8"><a href="probability.html#cb97-8"></a><span class="kw">names</span>(e) &lt;-<span class="st"> </span>cell_names</span></code></pre></div>
<div class="sourceCode" id="cb98"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb98-1"><a href="probability.html#cb98-1"></a>(dof &lt;-<span class="st"> </span><span class="kw">length</span>(o) <span class="op">-</span><span class="st"> </span><span class="dv">1</span>)</span></code></pre></div>
<pre><code>## [1] 3</code></pre>
<div class="sourceCode" id="cb100"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb100-1"><a href="probability.html#cb100-1"></a>(x2 &lt;-<span class="st"> </span><span class="kw">sum</span>((o <span class="op">-</span><span class="st"> </span>e)<span class="op">^</span><span class="dv">2</span> <span class="op">/</span><span class="st"> </span>e))</span></code></pre></div>
<pre><code>## [1] 1.5</code></pre>
<div class="sourceCode" id="cb102"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb102-1"><a href="probability.html#cb102-1"></a>(p_value &lt;-<span class="st"> </span><span class="kw">pchisq</span>(<span class="dt">q =</span> x2, <span class="dt">df =</span> dof, <span class="dt">lower.tail =</span> <span class="ot">FALSE</span>))</span></code></pre></div>
<pre><code>## [1] 0.69</code></pre>
<p>Or simulate this by taking the mean of 10,000 random trials.</p>
<div class="sourceCode" id="cb104"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb104-1"><a href="probability.html#cb104-1"></a><span class="kw">mean</span>(<span class="kw">rchisq</span>(<span class="dt">n =</span> <span class="dv">10000</span>, <span class="dt">df =</span> dof) <span class="op">&gt;=</span><span class="st"> </span>x2)</span></code></pre></div>
<pre><code>## [1] 0.69</code></pre>
<div class="sourceCode" id="cb106"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb106-1"><a href="probability.html#cb106-1"></a><span class="kw">data.frame</span>(<span class="dt">x =</span> <span class="dv">0</span><span class="op">:</span><span class="dv">100</span> <span class="op">/</span><span class="st"> </span><span class="dv">10</span>) <span class="op">%&gt;%</span></span>
<span id="cb106-2"><a href="probability.html#cb106-2"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">density =</span> <span class="kw">pchisq</span>(x, <span class="dt">df =</span> dof, <span class="dt">lower.tail =</span> <span class="ot">FALSE</span>),</span>
<span id="cb106-3"><a href="probability.html#cb106-3"></a>         <span class="dt">cdf =</span> <span class="kw">if_else</span>(x <span class="op">&gt;</span><span class="st"> </span>x2, density, <span class="kw">as.numeric</span>(<span class="ot">NA</span>))) <span class="op">%&gt;%</span></span>
<span id="cb106-4"><a href="probability.html#cb106-4"></a><span class="st">  </span><span class="kw">ggplot</span>() <span class="op">+</span></span>
<span id="cb106-5"><a href="probability.html#cb106-5"></a><span class="st">  </span><span class="kw">geom_line</span>(<span class="kw">aes</span>(<span class="dt">x =</span> x, <span class="dt">y =</span> density)) <span class="op">+</span></span>
<span id="cb106-6"><a href="probability.html#cb106-6"></a><span class="st">  </span><span class="kw">geom_area</span>(<span class="kw">aes</span>(<span class="dt">x =</span> x, <span class="dt">y =</span> cdf), <span class="dt">alpha =</span> <span class="fl">0.3</span>) <span class="op">+</span></span>
<span id="cb106-7"><a href="probability.html#cb106-7"></a><span class="st">  </span><span class="kw">theme_minimal</span>() <span class="op">+</span></span>
<span id="cb106-8"><a href="probability.html#cb106-8"></a><span class="st">  </span><span class="kw">labs</span>(<span class="dt">title =</span> <span class="st">&quot;P(X^2 &gt; 1.47) when X ~ ChiSq(3)&quot;</span>)</span></code></pre></div>
<p><img src="data-sci_files/figure-html/unnamed-chunk-67-1.png" width="672" /></p>
<p>How large would <span class="math inline">\(X^2\)</span> have to be to conclude the observed were not in agreement with expectations?</p>
<div class="sourceCode" id="cb107"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb107-1"><a href="probability.html#cb107-1"></a><span class="kw">qchisq</span>(<span class="dt">p =</span> <span class="fl">.05</span>, <span class="dt">df =</span> <span class="dv">3</span>, <span class="dt">lower.tail =</span> <span class="ot">FALSE</span>)</span></code></pre></div>
<pre><code>## [1] 7.8</code></pre>
</div>
</div>
<div id="join-distributions" class="section level2">
<h2><span class="header-section-number">1.4</span> Join Distributions</h2>
</div>
<div id="likelihood" class="section level2">
<h2><span class="header-section-number">1.5</span> Likelihood</h2>
<p>The <em>likelihood function</em> is the likelihood of a parameter <span class="math inline">\(\theta\)</span> given an observed value of the random variable <span class="math inline">\(X\)</span>. The likelihood function is identical to the probability distribution function, except that it reverses which variable is considered fixed. E.g., the binomial <em>probability</em> distribution expresses the probability that <span class="math inline">\(X = x\)</span> given the success probability <span class="math inline">\(\theta = \pi\)</span>.</p>
<p><span class="math display">\[f(x|\pi) = \frac{n!}{x!(n-x)!} \pi^x (1-\pi)^{n-x}.\]</span></p>
<p>The corresponding <em>likelihood</em> function expresses the probability that <span class="math inline">\(\pi = p\)</span> given the observed value <span class="math inline">\(x\)</span>.</p>
<p><span class="math display">\[L(p|x) = \frac{n!}{x!(n-x)!} p^x (1-p)^{n-x}.\]</span></p>
<p>You usually want to know the value of <span class="math inline">\(\theta\)</span> at the <em>maximum</em> of the likelihood function. When taking derivatives, any multiplicative constant is irrevelant and can be discarded. So for the binomial distribution, the likelihood function for <span class="math inline">\(\pi\)</span> may instead be expressed as</p>
<p><span class="math display">\[L(p|x) \propto p^x (1-p)^{n-x}\]</span></p>
<p>Calculating the maximum is usually simplified using the <em>log-likelihood</em>, <span class="math inline">\(l(\theta|x) = \log L(\theta|x)\)</span>. For the binomial distribution, <span class="math inline">\(l(p|x) = x \log p + (n - x) \log (1 - p)\)</span>. Frequently you derive loglikelihood from a sample. The overall likelihood is the product of the individual likelihoods, and the overall loglikelihood is the log of the overall likelihood.</p>
<p><span class="math display">\[l(\theta|x) = \log \prod_{i=1}^n f(x_i|\theta)\]</span></p>
<p>Here are plots of the binomial log-likelihood of <span class="math inline">\(pi\)</span> for several values of <span class="math inline">\(X\)</span> from a sample of size <span class="math inline">\(n = 5\)</span>.</p>
<p><img src="data-sci_files/figure-html/unnamed-chunk-69-1.png" width="480" /></p>
<p>As the total sample size <span class="math inline">\(n\)</span> grows, the loglikelihood function becomes more sharply peaked around its maximum, and becomes nearly quadratic (i.e. a parabola, if there is a single parameter). Here is the same plot with <span class="math inline">\(n = 500\)</span>.</p>
<p><img src="data-sci_files/figure-html/unnamed-chunk-70-1.png" width="480" /></p>
<p>The value of <span class="math inline">\(\theta\)</span> that maximizes <span class="math inline">\(l\)</span> (and <span class="math inline">\(L\)</span>) is the <em>maximum-likelihood estimator</em> (MLE) of <span class="math inline">\(\theta\)</span>, <span class="math inline">\(\hat{\theta}\)</span>. E.g., suppose you have an experiment of <span class="math inline">\(n = 5\)</span> Bernoulli trials <span class="math inline">\(\left(X \sim Bin(5, \pi) \right)\)</span> with and <span class="math inline">\(X = 3\)</span> successful events. A plot of <span class="math inline">\(L(p|x) = p^3(1 - p)^2\)</span> shows the MLE is at <span class="math inline">\(p = 0.6\)</span>.</p>
<p><img src="data-sci_files/figure-html/unnamed-chunk-71-1.png" width="480" /></p>
<p>This approach is called <em>maximum-likelihood</em> estimation. MLE usually involves setting the derivatives to zero and solving for <span class="math inline">\(theta\)</span>.</p>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="index.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="contingency-tables.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["data-sci.pdf", "data-sci.epub"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
