<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>9.5 Gradient Boosting | My Data Science Notes</title>
  <meta name="description" content="This is a compendium of notes from classes, tutorials, etc. that I reference from time to time." />
  <meta name="generator" content="bookdown 0.19 and GitBook 2.6.7" />

  <meta property="og:title" content="9.5 Gradient Boosting | My Data Science Notes" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="This is a compendium of notes from classes, tutorials, etc. that I reference from time to time." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="9.5 Gradient Boosting | My Data Science Notes" />
  
  <meta name="twitter:description" content="This is a compendium of notes from classes, tutorials, etc. that I reference from time to time." />
  

<meta name="author" content="Michael Foley" />


<meta name="date" content="2020-06-29" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="random-forests.html"/>
<link rel="next" href="summary.html"/>
<script src="assets/jquery-2.2.3/jquery.min.js"></script>
<link href="assets/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="assets/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="assets/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="assets/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="assets/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="assets/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="assets/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<script src="assets/accessible-code-block-0.0.1/empty-anchor.js"></script>


<style type="text/css">
code.sourceCode > span { display: inline-block; line-height: 1.25; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">My Data Science Notes</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Intro</a></li>
<li class="chapter" data-level="1" data-path="probability.html"><a href="probability.html"><i class="fa fa-check"></i><b>1</b> Probability</a><ul>
<li class="chapter" data-level="1.1" data-path="principles.html"><a href="principles.html"><i class="fa fa-check"></i><b>1.1</b> Principles</a></li>
<li class="chapter" data-level="1.2" data-path="disc-dist.html"><a href="disc-dist.html"><i class="fa fa-check"></i><b>1.2</b> Discrete Distributions</a><ul>
<li class="chapter" data-level="1.2.1" data-path="disc-dist.html"><a href="disc-dist.html#bernoulli"><i class="fa fa-check"></i><b>1.2.1</b> Bernoulli</a></li>
<li class="chapter" data-level="1.2.2" data-path="disc-dist.html"><a href="disc-dist.html#binomial"><i class="fa fa-check"></i><b>1.2.2</b> Binomial</a></li>
<li class="chapter" data-level="1.2.3" data-path="disc-dist.html"><a href="disc-dist.html#poission"><i class="fa fa-check"></i><b>1.2.3</b> Poission</a></li>
<li class="chapter" data-level="1.2.4" data-path="disc-dist.html"><a href="disc-dist.html#multinomial"><i class="fa fa-check"></i><b>1.2.4</b> Multinomial</a></li>
<li class="chapter" data-level="1.2.5" data-path="disc-dist.html"><a href="disc-dist.html#negative-binomial"><i class="fa fa-check"></i><b>1.2.5</b> Negative-Binomial</a></li>
<li class="chapter" data-level="1.2.6" data-path="disc-dist.html"><a href="disc-dist.html#geometric"><i class="fa fa-check"></i><b>1.2.6</b> Geometric</a></li>
<li class="chapter" data-level="1.2.7" data-path="disc-dist.html"><a href="disc-dist.html#hypergeometric"><i class="fa fa-check"></i><b>1.2.7</b> Hypergeometric</a></li>
<li class="chapter" data-level="1.2.8" data-path="disc-dist.html"><a href="disc-dist.html#gamma"><i class="fa fa-check"></i><b>1.2.8</b> Gamma</a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="cont-dist.html"><a href="cont-dist.html"><i class="fa fa-check"></i><b>1.3</b> Continuous Distributions</a><ul>
<li class="chapter" data-level="1.3.1" data-path="cont-dist.html"><a href="cont-dist.html#normal"><i class="fa fa-check"></i><b>1.3.1</b> Normal</a></li>
</ul></li>
<li class="chapter" data-level="1.4" data-path="join-distributions.html"><a href="join-distributions.html"><i class="fa fa-check"></i><b>1.4</b> Join Distributions</a></li>
<li class="chapter" data-level="1.5" data-path="likelihood.html"><a href="likelihood.html"><i class="fa fa-check"></i><b>1.5</b> Likelihood</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="discrete-analysis.html"><a href="discrete-analysis.html"><i class="fa fa-check"></i><b>2</b> Categorical Analysis - Nonmodel</a><ul>
<li class="chapter" data-level="2.1" data-path="chi-square-test.html"><a href="chi-square-test.html"><i class="fa fa-check"></i><b>2.1</b> Chi-Square Test</a></li>
<li class="chapter" data-level="2.2" data-path="one-way-tables.html"><a href="one-way-tables.html"><i class="fa fa-check"></i><b>2.2</b> One-Way Tables</a><ul>
<li class="chapter" data-level="2.2.1" data-path="one-way-tables.html"><a href="one-way-tables.html#chi-square-goodness-of-fit-test"><i class="fa fa-check"></i><b>2.2.1</b> Chi-Square Goodness-of-Fit Test</a></li>
<li class="chapter" data-level="2.2.2" data-path="one-way-tables.html"><a href="one-way-tables.html#proportion-test"><i class="fa fa-check"></i><b>2.2.2</b> Proportion Test</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="two-way-tables.html"><a href="two-way-tables.html"><i class="fa fa-check"></i><b>2.3</b> Two-Way Tables</a><ul>
<li class="chapter" data-level="2.3.1" data-path="two-way-tables.html"><a href="two-way-tables.html#chi-square-independence-test"><i class="fa fa-check"></i><b>2.3.1</b> Chi-Square Independence Test</a></li>
<li class="chapter" data-level="2.3.2" data-path="two-way-tables.html"><a href="two-way-tables.html#residuals-analysis"><i class="fa fa-check"></i><b>2.3.2</b> Residuals Analysis</a></li>
<li class="chapter" data-level="2.3.3" data-path="two-way-tables.html"><a href="two-way-tables.html#difference-in-proportions"><i class="fa fa-check"></i><b>2.3.3</b> Difference in Proportions</a></li>
<li class="chapter" data-level="2.3.4" data-path="two-way-tables.html"><a href="two-way-tables.html#relative-risk"><i class="fa fa-check"></i><b>2.3.4</b> Relative Risk</a></li>
<li class="chapter" data-level="2.3.5" data-path="two-way-tables.html"><a href="two-way-tables.html#odds-ratio"><i class="fa fa-check"></i><b>2.3.5</b> Odds Ratio</a></li>
<li class="chapter" data-level="2.3.6" data-path="two-way-tables.html"><a href="two-way-tables.html#partitioning-chi-square"><i class="fa fa-check"></i><b>2.3.6</b> Partitioning Chi-Square</a></li>
<li class="chapter" data-level="2.3.7" data-path="two-way-tables.html"><a href="two-way-tables.html#correlation"><i class="fa fa-check"></i><b>2.3.7</b> Correlation</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="k-way-tables.html"><a href="k-way-tables.html"><i class="fa fa-check"></i><b>2.4</b> K-Way Tables</a><ul>
<li class="chapter" data-level="2.4.1" data-path="k-way-tables.html"><a href="k-way-tables.html#odds-ratio-1"><i class="fa fa-check"></i><b>2.4.1</b> Odds Ratio</a></li>
<li class="chapter" data-level="2.4.2" data-path="k-way-tables.html"><a href="k-way-tables.html#chi-square-independence-test-1"><i class="fa fa-check"></i><b>2.4.2</b> Chi-Square Independence Test</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="continuous-analysis.html"><a href="continuous-analysis.html"><i class="fa fa-check"></i><b>3</b> Continuous Variable Analysis</a><ul>
<li class="chapter" data-level="3.0.1" data-path="continuous-analysis.html"><a href="continuous-analysis.html#correlation-1"><i class="fa fa-check"></i><b>3.0.1</b> Correlation</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="experiment-design.html"><a href="experiment-design.html"><i class="fa fa-check"></i><b>4</b> Experiment Design</a><ul>
<li class="chapter" data-level="4.1" data-path="single-factor.html"><a href="single-factor.html"><i class="fa fa-check"></i><b>4.1</b> Single Factor</a></li>
<li class="chapter" data-level="4.2" data-path="blocking.html"><a href="blocking.html"><i class="fa fa-check"></i><b>4.2</b> Blocking</a></li>
<li class="chapter" data-level="4.3" data-path="nested.html"><a href="nested.html"><i class="fa fa-check"></i><b>4.3</b> Nested</a></li>
<li class="chapter" data-level="4.4" data-path="split-plot.html"><a href="split-plot.html"><i class="fa fa-check"></i><b>4.4</b> Split Plot</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="part-2-supervised-machine-learning.html"><a href="part-2-supervised-machine-learning.html"><i class="fa fa-check"></i>PART 2: Supervised Machine Learning</a><ul>
<li class="chapter" data-level="4.5" data-path="linear-regression-model.html"><a href="linear-regression-model.html"><i class="fa fa-check"></i><b>4.5</b> Linear Regression Model</a></li>
<li class="chapter" data-level="4.6" data-path="parameter-estimation.html"><a href="parameter-estimation.html"><i class="fa fa-check"></i><b>4.6</b> Parameter Estimation</a></li>
<li class="chapter" data-level="4.7" data-path="model-assumptions.html"><a href="model-assumptions.html"><i class="fa fa-check"></i><b>4.7</b> Model Assumptions</a><ul>
<li class="chapter" data-level="4.7.1" data-path="model-assumptions.html"><a href="model-assumptions.html#linearity"><i class="fa fa-check"></i><b>4.7.1</b> Linearity</a></li>
<li class="chapter" data-level="4.7.2" data-path="model-assumptions.html"><a href="model-assumptions.html#multicollinearity"><i class="fa fa-check"></i><b>4.7.2</b> Multicollinearity</a></li>
<li class="chapter" data-level="4.7.3" data-path="model-assumptions.html"><a href="model-assumptions.html#normality"><i class="fa fa-check"></i><b>4.7.3</b> Normality</a></li>
<li class="chapter" data-level="4.7.4" data-path="model-assumptions.html"><a href="model-assumptions.html#equal-variances"><i class="fa fa-check"></i><b>4.7.4</b> Equal Variances</a></li>
</ul></li>
<li class="chapter" data-level="4.8" data-path="prediction.html"><a href="prediction.html"><i class="fa fa-check"></i><b>4.8</b> Prediction</a></li>
<li class="chapter" data-level="4.9" data-path="inference.html"><a href="inference.html"><i class="fa fa-check"></i><b>4.9</b> Inference</a><ul>
<li class="chapter" data-level="4.9.1" data-path="inference.html"><a href="inference.html#t-test"><i class="fa fa-check"></i><b>4.9.1</b> <em>t</em>-Test</a></li>
<li class="chapter" data-level="4.9.2" data-path="inference.html"><a href="inference.html#f-test"><i class="fa fa-check"></i><b>4.9.2</b> <em>F</em>-Test</a></li>
</ul></li>
<li class="chapter" data-level="4.10" data-path="interpretation.html"><a href="interpretation.html"><i class="fa fa-check"></i><b>4.10</b> Interpretation</a></li>
<li class="chapter" data-level="4.11" data-path="model-validation.html"><a href="model-validation.html"><i class="fa fa-check"></i><b>4.11</b> Model Validation</a><ul>
<li class="chapter" data-level="4.11.1" data-path="model-validation.html"><a href="model-validation.html#accuracy-metrics"><i class="fa fa-check"></i><b>4.11.1</b> Accuracy Metrics</a></li>
<li class="chapter" data-level="4.11.2" data-path="model-validation.html"><a href="model-validation.html#cross-validation"><i class="fa fa-check"></i><b>4.11.2</b> Cross-Validation</a></li>
<li class="chapter" data-level="4.11.3" data-path="model-validation.html"><a href="model-validation.html#gain-curve"><i class="fa fa-check"></i><b>4.11.3</b> Gain Curve</a></li>
</ul></li>
<li class="chapter" data-level="4.12" data-path="reference.html"><a href="reference.html"><i class="fa fa-check"></i><b>4.12</b> Reference</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="generalized-linear-models.html"><a href="generalized-linear-models.html"><i class="fa fa-check"></i><b>5</b> Generalized Linear Models</a><ul>
<li class="chapter" data-level="5.1" data-path="logistic-regression.html"><a href="logistic-regression.html"><i class="fa fa-check"></i><b>5.1</b> Logistic Regression</a></li>
<li class="chapter" data-level="5.2" data-path="multinomial-logistic-regression.html"><a href="multinomial-logistic-regression.html"><i class="fa fa-check"></i><b>5.2</b> Multinomial Logistic Regression</a></li>
<li class="chapter" data-level="5.3" data-path="ordinal-logistic-regression.html"><a href="ordinal-logistic-regression.html"><i class="fa fa-check"></i><b>5.3</b> Ordinal Logistic Regression</a><ul>
<li class="chapter" data-level="5.3.1" data-path="ordinal-logistic-regression.html"><a href="ordinal-logistic-regression.html#assumptions"><i class="fa fa-check"></i><b>5.3.1</b> Assumptions</a></li>
<li class="chapter" data-level="5.3.2" data-path="ordinal-logistic-regression.html"><a href="ordinal-logistic-regression.html#modeling"><i class="fa fa-check"></i><b>5.3.2</b> Modeling</a></li>
<li class="chapter" data-level="5.3.3" data-path="ordinal-logistic-regression.html"><a href="ordinal-logistic-regression.html#case-study"><i class="fa fa-check"></i><b>5.3.3</b> Case Study</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="poisson-regression.html"><a href="poisson-regression.html"><i class="fa fa-check"></i><b>5.4</b> Poisson Regression</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="multivariate-statistical-analysis.html"><a href="multivariate-statistical-analysis.html"><i class="fa fa-check"></i><b>6</b> Multivariate Statistical Analysis</a><ul>
<li class="chapter" data-level="6.1" data-path="background.html"><a href="background.html"><i class="fa fa-check"></i><b>6.1</b> Background</a></li>
<li class="chapter" data-level="6.2" data-path="manova.html"><a href="manova.html"><i class="fa fa-check"></i><b>6.2</b> MANOVA</a></li>
<li class="chapter" data-level="6.3" data-path="repeated-measures.html"><a href="repeated-measures.html"><i class="fa fa-check"></i><b>6.3</b> Repeated Measures</a></li>
<li class="chapter" data-level="6.4" data-path="lda.html"><a href="lda.html"><i class="fa fa-check"></i><b>6.4</b> LDA</a></li>
<li class="chapter" data-level="6.5" data-path="pca.html"><a href="pca.html"><i class="fa fa-check"></i><b>6.5</b> PCA</a></li>
<li class="chapter" data-level="6.6" data-path="factor-analysis.html"><a href="factor-analysis.html"><i class="fa fa-check"></i><b>6.6</b> Factor Analysis</a></li>
<li class="chapter" data-level="6.7" data-path="canonical-correlation.html"><a href="canonical-correlation.html"><i class="fa fa-check"></i><b>6.7</b> Canonical Correlation</a></li>
<li class="chapter" data-level="6.8" data-path="cluster-analysis.html"><a href="cluster-analysis.html"><i class="fa fa-check"></i><b>6.8</b> Cluster Analysis</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="classification.html"><a href="classification.html"><i class="fa fa-check"></i><b>7</b> Classification</a></li>
<li class="chapter" data-level="8" data-path="regularization.html"><a href="regularization.html"><i class="fa fa-check"></i><b>8</b> Regularization</a><ul>
<li class="chapter" data-level="8.1" data-path="ridge.html"><a href="ridge.html"><i class="fa fa-check"></i><b>8.1</b> Ridge</a></li>
<li class="chapter" data-level="8.2" data-path="lasso.html"><a href="lasso.html"><i class="fa fa-check"></i><b>8.2</b> Lasso</a></li>
<li class="chapter" data-level="8.3" data-path="elastic-net.html"><a href="elastic-net.html"><i class="fa fa-check"></i><b>8.3</b> Elastic Net</a></li>
<li class="chapter" data-level="" data-path="model-summary.html"><a href="model-summary.html"><i class="fa fa-check"></i>Model Summary</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="decision-trees.html"><a href="decision-trees.html"><i class="fa fa-check"></i><b>9</b> Decision Trees</a><ul>
<li class="chapter" data-level="9.1" data-path="classification-tree.html"><a href="classification-tree.html"><i class="fa fa-check"></i><b>9.1</b> Classification Tree</a><ul>
<li class="chapter" data-level="9.1.1" data-path="classification-tree.html"><a href="classification-tree.html#holdout-performance"><i class="fa fa-check"></i><b>9.1.1</b> Holdout Performance</a></li>
<li class="chapter" data-level="9.1.2" data-path="classification-tree.html"><a href="classification-tree.html#caret-approach"><i class="fa fa-check"></i><b>9.1.2</b> Caret Approach</a></li>
</ul></li>
<li class="chapter" data-level="9.2" data-path="regression-tree.html"><a href="regression-tree.html"><i class="fa fa-check"></i><b>9.2</b> Regression Tree</a><ul>
<li class="chapter" data-level="9.2.1" data-path="regression-tree.html"><a href="regression-tree.html#caret-approach-1"><i class="fa fa-check"></i><b>9.2.1</b> Caret Approach</a></li>
</ul></li>
<li class="chapter" data-level="9.3" data-path="bagging.html"><a href="bagging.html"><i class="fa fa-check"></i><b>9.3</b> Bagging</a></li>
<li class="chapter" data-level="9.4" data-path="random-forests.html"><a href="random-forests.html"><i class="fa fa-check"></i><b>9.4</b> Random Forests</a></li>
<li class="chapter" data-level="9.5" data-path="gradient-boosting.html"><a href="gradient-boosting.html"><i class="fa fa-check"></i><b>9.5</b> Gradient Boosting</a></li>
<li class="chapter" data-level="9.6" data-path="summary.html"><a href="summary.html"><i class="fa fa-check"></i><b>9.6</b> Summary</a></li>
<li class="chapter" data-level="9.7" data-path="reference-1.html"><a href="reference-1.html"><i class="fa fa-check"></i><b>9.7</b> Reference</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="non-linear-models.html"><a href="non-linear-models.html"><i class="fa fa-check"></i><b>10</b> Non-linear Models</a><ul>
<li class="chapter" data-level="10.1" data-path="splines.html"><a href="splines.html"><i class="fa fa-check"></i><b>10.1</b> Splines</a></li>
<li class="chapter" data-level="10.2" data-path="mars.html"><a href="mars.html"><i class="fa fa-check"></i><b>10.2</b> MARS</a></li>
<li class="chapter" data-level="10.3" data-path="gam.html"><a href="gam.html"><i class="fa fa-check"></i><b>10.3</b> GAM</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="support-vector-machines.html"><a href="support-vector-machines.html"><i class="fa fa-check"></i><b>11</b> Support Vector Machines</a><ul>
<li class="chapter" data-level="11.1" data-path="maximal-margin-classifier.html"><a href="maximal-margin-classifier.html"><i class="fa fa-check"></i><b>11.1</b> Maximal Margin Classifier</a></li>
<li class="chapter" data-level="11.2" data-path="support-vector-classifier.html"><a href="support-vector-classifier.html"><i class="fa fa-check"></i><b>11.2</b> Support Vector Classifier</a></li>
<li class="chapter" data-level="11.3" data-path="support-vector-machines-1.html"><a href="support-vector-machines-1.html"><i class="fa fa-check"></i><b>11.3</b> Support Vector Machines</a></li>
<li class="chapter" data-level="11.4" data-path="example-19.html"><a href="example-19.html"><i class="fa fa-check"></i><b>11.4</b> Example</a></li>
<li class="chapter" data-level="11.5" data-path="using-caret.html"><a href="using-caret.html"><i class="fa fa-check"></i><b>11.5</b> Using Caret</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="principal-components-analysis.html"><a href="principal-components-analysis.html"><i class="fa fa-check"></i><b>12</b> Principal Components Analysis</a></li>
<li class="chapter" data-level="13" data-path="text-mining.html"><a href="text-mining.html"><i class="fa fa-check"></i><b>13</b> Text Mining</a><ul>
<li class="chapter" data-level="13.1" data-path="n-grams.html"><a href="n-grams.html"><i class="fa fa-check"></i><b>13.1</b> N-Grams</a></li>
<li class="chapter" data-level="13.2" data-path="converting-to-and-from-non-tidy-formats.html"><a href="converting-to-and-from-non-tidy-formats.html"><i class="fa fa-check"></i><b>13.2</b> Converting to and from non-tidy formats</a></li>
<li class="chapter" data-level="13.3" data-path="example-20.html"><a href="example-20.html"><i class="fa fa-check"></i><b>13.3</b> Example</a></li>
<li class="chapter" data-level="13.4" data-path="stringr-package.html"><a href="stringr-package.html"><i class="fa fa-check"></i><b>13.4</b> stringr package</a></li>
<li class="chapter" data-level="13.5" data-path="regular-expressions.html"><a href="regular-expressions.html"><i class="fa fa-check"></i><b>13.5</b> Regular Expressions</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="survival-analysis.html"><a href="survival-analysis.html"><i class="fa fa-check"></i><b>14</b> Survival Analysis</a><ul>
<li class="chapter" data-level="14.1" data-path="basic-concepts.html"><a href="basic-concepts.html"><i class="fa fa-check"></i><b>14.1</b> Basic Concepts</a></li>
<li class="chapter" data-level="14.2" data-path="survival-curve-estimation.html"><a href="survival-curve-estimation.html"><i class="fa fa-check"></i><b>14.2</b> Survival Curve Estimation</a><ul>
<li class="chapter" data-level="14.2.1" data-path="survival-curve-estimation.html"><a href="survival-curve-estimation.html#kaplan-meier"><i class="fa fa-check"></i><b>14.2.1</b> Kaplan-Meier</a></li>
<li class="chapter" data-level="14.2.2" data-path="survival-curve-estimation.html"><a href="survival-curve-estimation.html#weibull"><i class="fa fa-check"></i><b>14.2.2</b> Weibull</a></li>
<li class="chapter" data-level="14.2.3" data-path="survival-curve-estimation.html"><a href="survival-curve-estimation.html#cox"><i class="fa fa-check"></i><b>14.2.3</b> Cox</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="" data-path="appendix.html"><a href="appendix.html"><i class="fa fa-check"></i>Appendix</a><ul>
<li class="chapter" data-level="" data-path="publishing-to-bookdown.html"><a href="publishing-to-bookdown.html"><i class="fa fa-check"></i>Publishing to BookDown</a></li>
<li class="chapter" data-level="" data-path="shiny-apps.html"><a href="shiny-apps.html"><i class="fa fa-check"></i>Shiny Apps</a></li>
<li class="chapter" data-level="" data-path="packages.html"><a href="packages.html"><i class="fa fa-check"></i>Packages</a><ul>
<li class="chapter" data-level="" data-path="packages.html"><a href="packages.html#create-a-package"><i class="fa fa-check"></i>Create a package</a></li>
<li class="chapter" data-level="14.2.4" data-path="packages.html"><a href="packages.html#document-functions-with-roxygen"><i class="fa fa-check"></i><b>14.2.4</b> Document Functions with roxygen</a></li>
<li class="chapter" data-level="" data-path="packages.html"><a href="packages.html#create-data"><i class="fa fa-check"></i>Create Data</a></li>
<li class="chapter" data-level="" data-path="packages.html"><a href="packages.html#create-vignette"><i class="fa fa-check"></i>Create Vignette</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">My Data Science Notes</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="gradient-boosting" class="section level2">
<h2><span class="header-section-number">9.5</span> Gradient Boosting</h2>
<p><strong>Note</strong>: I learned gradient boosting from <a href="https://explained.ai/gradient-boosting/L2-loss.html">explained.ai</a>.</p>
<p>Gradient boosting machine (GBM) is an additive modeling algorithm that gradually builds a composite model by iteratively adding <em>M</em> weak sub-models based on the performance of the prior iteration’s composite,</p>
<p><span class="math display">\[F_M(x) = \sum_m^M f_m(x).\]</span></p>
<p>The idea is to fit a weak model, then replace the response values with the residuals from that model, and fit another model. Adding the residual prediction model to the original response prediction model produces a more accurate model. GBM repeats this process over and over, running new models to predict the residuals of the previous composite models, and adding the results to produce new composites. With each iteration, the model becomes stronger and stronger. The successive trees are usually weighted to slow down the learning rate. “Shrinkage” reduces the influence of each individual tree and leaves space for future trees to improve the model.</p>
<p><span class="math display">\[F_M(x) = f_0 + \eta\sum_{m = 1}^M f_m(x).\]</span></p>
<p>The smaller the learning rate, <span class="math inline">\(\eta\)</span>, the larger the number of trees, <span class="math inline">\(M\)</span>. <span class="math inline">\(\eta\)</span> and <span class="math inline">\(M\)</span> are hyperparameters. Other constraints to the trees are usually applied as additional hyperparameters, including, tree depth, number of nodes, minimum observations per split, and minimum improvement to loss.</p>
<p>The name “gradient boosting” refers to the <em>boosting</em> of a model with a <em>gradient</em>. Each round of training builds a <em>weak learner</em> and uses the residuals to calculate a gradient, the partial derivative of the loss function. Gradient boosting “descends the gradient” to adjust the model parameters to reduce the error in the next round of training.</p>
<p>In the case of classification problems, the loss function is the log-loss; for regression problems, the loss function is mean squared error. GBM continues until it reaches maximum number of trees or an acceptable error level.</p>
<div id="gradient-boosting-classification-example" class="section level4">
<h4><span class="header-section-number">9.5.0.1</span> Gradient Boosting Classification Example</h4>
<p>I’ll predict <code>Purchase</code> from the <code>OJ</code> data set again, this time using the GBM method by specifying <code>method = "gbm"</code>. <code>gbm</code> has the following tuneable hyperparameters (see <code>modelLookup("gbm")</code>).</p>
<ul>
<li><code>n.trees</code>: number of boosting iterations, <span class="math inline">\(M\)</span></li>
<li><code>interaction.depth</code>: maximum tree depth</li>
<li><code>shrinkage</code>: shrinkage, <span class="math inline">\(\eta\)</span></li>
<li><code>n.minobsinnode</code>: mimimum terminal node size</li>
</ul>
<p>I’ll use <code>tuneLength = 5</code>.</p>
<div class="sourceCode" id="cb113"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb113-1"><a href="gradient-boosting.html#cb113-1"></a><span class="kw">set.seed</span>(<span class="dv">1234</span>)</span>
<span id="cb113-2"><a href="gradient-boosting.html#cb113-2"></a>oj_mdl_gbm &lt;-<span class="st"> </span><span class="kw">train</span>(</span>
<span id="cb113-3"><a href="gradient-boosting.html#cb113-3"></a>   Purchase <span class="op">~</span><span class="st"> </span>., </span>
<span id="cb113-4"><a href="gradient-boosting.html#cb113-4"></a>   <span class="dt">data =</span> oj_train, </span>
<span id="cb113-5"><a href="gradient-boosting.html#cb113-5"></a>   <span class="dt">method =</span> <span class="st">&quot;gbm&quot;</span>,</span>
<span id="cb113-6"><a href="gradient-boosting.html#cb113-6"></a>   <span class="dt">tuneLength =</span> <span class="dv">5</span>,</span>
<span id="cb113-7"><a href="gradient-boosting.html#cb113-7"></a>   <span class="dt">trControl =</span> oj_trControl</span>
<span id="cb113-8"><a href="gradient-boosting.html#cb113-8"></a>)</span></code></pre></div>
<pre><code>## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1        1.2729             nan     0.1000    0.0296
##      2        1.2250             nan     0.1000    0.0250
##      3        1.1846             nan     0.1000    0.0221
##      4        1.1479             nan     0.1000    0.0178
##      5        1.1188             nan     0.1000    0.0128
##      6        1.0930             nan     0.1000    0.0130
##      7        1.0696             nan     0.1000    0.0114
##      8        1.0507             nan     0.1000    0.0089
##      9        1.0328             nan     0.1000    0.0072
##     10        1.0187             nan     0.1000    0.0066
##     20        0.9193             nan     0.1000    0.0025
##     40        0.8234             nan     0.1000    0.0005
##     60        0.7858             nan     0.1000   -0.0010
##     80        0.7666             nan     0.1000   -0.0010
##    100        0.7579             nan     0.1000   -0.0001
##    120        0.7509             nan     0.1000   -0.0007
##    140        0.7447             nan     0.1000   -0.0005
##    160        0.7394             nan     0.1000   -0.0002
##    180        0.7338             nan     0.1000   -0.0001
##    200        0.7292             nan     0.1000   -0.0007
##    220        0.7259             nan     0.1000   -0.0005
##    240        0.7222             nan     0.1000   -0.0009
##    250        0.7204             nan     0.1000   -0.0012
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1        1.2662             nan     0.1000    0.0349
##      2        1.2068             nan     0.1000    0.0266
##      3        1.1624             nan     0.1000    0.0230
##      4        1.1230             nan     0.1000    0.0186
##      5        1.0876             nan     0.1000    0.0180
##      6        1.0556             nan     0.1000    0.0141
##      7        1.0268             nan     0.1000    0.0124
##      8        1.0002             nan     0.1000    0.0105
##      9        0.9802             nan     0.1000    0.0075
##     10        0.9601             nan     0.1000    0.0093
##     20        0.8410             nan     0.1000    0.0039
##     40        0.7669             nan     0.1000   -0.0003
##     60        0.7387             nan     0.1000   -0.0013
##     80        0.7202             nan     0.1000   -0.0020
##    100        0.7076             nan     0.1000   -0.0011
##    120        0.6892             nan     0.1000   -0.0009
##    140        0.6762             nan     0.1000   -0.0013
##    160        0.6680             nan     0.1000   -0.0008
##    180        0.6605             nan     0.1000   -0.0015
##    200        0.6519             nan     0.1000   -0.0008
##    220        0.6418             nan     0.1000   -0.0015
##    240        0.6328             nan     0.1000   -0.0007
##    250        0.6306             nan     0.1000   -0.0018
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1        1.2535             nan     0.1000    0.0377
##      2        1.1930             nan     0.1000    0.0311
##      3        1.1360             nan     0.1000    0.0252
##      4        1.0891             nan     0.1000    0.0196
##      5        1.0520             nan     0.1000    0.0159
##      6        1.0180             nan     0.1000    0.0147
##      7        0.9846             nan     0.1000    0.0133
##      8        0.9553             nan     0.1000    0.0139
##      9        0.9336             nan     0.1000    0.0105
##     10        0.9150             nan     0.1000    0.0058
##     20        0.7989             nan     0.1000    0.0020
##     40        0.7300             nan     0.1000   -0.0018
##     60        0.6912             nan     0.1000   -0.0007
##     80        0.6669             nan     0.1000   -0.0006
##    100        0.6481             nan     0.1000   -0.0014
##    120        0.6275             nan     0.1000   -0.0015
##    140        0.6114             nan     0.1000   -0.0009
##    160        0.5970             nan     0.1000   -0.0016
##    180        0.5868             nan     0.1000   -0.0011
##    200        0.5727             nan     0.1000   -0.0013
##    220        0.5586             nan     0.1000   -0.0018
##    240        0.5432             nan     0.1000   -0.0008
##    250        0.5374             nan     0.1000   -0.0010
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1        1.2593             nan     0.1000    0.0373
##      2        1.1862             nan     0.1000    0.0307
##      3        1.1262             nan     0.1000    0.0268
##      4        1.0792             nan     0.1000    0.0196
##      5        1.0320             nan     0.1000    0.0197
##      6        0.9935             nan     0.1000    0.0172
##      7        0.9620             nan     0.1000    0.0143
##      8        0.9358             nan     0.1000    0.0093
##      9        0.9112             nan     0.1000    0.0097
##     10        0.8911             nan     0.1000    0.0094
##     20        0.7721             nan     0.1000    0.0022
##     40        0.6974             nan     0.1000   -0.0018
##     60        0.6568             nan     0.1000   -0.0015
##     80        0.6273             nan     0.1000   -0.0020
##    100        0.6055             nan     0.1000   -0.0009
##    120        0.5835             nan     0.1000   -0.0011
##    140        0.5657             nan     0.1000   -0.0018
##    160        0.5468             nan     0.1000   -0.0020
##    180        0.5339             nan     0.1000   -0.0021
##    200        0.5208             nan     0.1000   -0.0004
##    220        0.5108             nan     0.1000   -0.0026
##    240        0.5002             nan     0.1000   -0.0008
##    250        0.4910             nan     0.1000   -0.0019
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1        1.2498             nan     0.1000    0.0406
##      2        1.1806             nan     0.1000    0.0325
##      3        1.1216             nan     0.1000    0.0288
##      4        1.0715             nan     0.1000    0.0212
##      5        1.0283             nan     0.1000    0.0182
##      6        0.9935             nan     0.1000    0.0146
##      7        0.9629             nan     0.1000    0.0111
##      8        0.9352             nan     0.1000    0.0105
##      9        0.9068             nan     0.1000    0.0093
##     10        0.8816             nan     0.1000    0.0086
##     20        0.7662             nan     0.1000    0.0025
##     40        0.6844             nan     0.1000   -0.0017
##     60        0.6381             nan     0.1000   -0.0028
##     80        0.6018             nan     0.1000   -0.0020
##    100        0.5710             nan     0.1000   -0.0018
##    120        0.5402             nan     0.1000   -0.0021
##    140        0.5137             nan     0.1000   -0.0022
##    160        0.4950             nan     0.1000   -0.0015
##    180        0.4810             nan     0.1000   -0.0012
##    200        0.4687             nan     0.1000   -0.0029
##    220        0.4559             nan     0.1000   -0.0025
##    240        0.4427             nan     0.1000   -0.0019
##    250        0.4369             nan     0.1000   -0.0015
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1        1.2817             nan     0.1000    0.0283
##      2        1.2326             nan     0.1000    0.0242
##      3        1.1940             nan     0.1000    0.0154
##      4        1.1582             nan     0.1000    0.0172
##      5        1.1267             nan     0.1000    0.0137
##      6        1.1022             nan     0.1000    0.0106
##      7        1.0821             nan     0.1000    0.0101
##      8        1.0624             nan     0.1000    0.0077
##      9        1.0468             nan     0.1000    0.0071
##     10        1.0325             nan     0.1000    0.0053
##     20        0.9318             nan     0.1000    0.0031
##     40        0.8366             nan     0.1000   -0.0005
##     60        0.7998             nan     0.1000   -0.0009
##     80        0.7815             nan     0.1000   -0.0003
##    100        0.7719             nan     0.1000   -0.0008
##    120        0.7656             nan     0.1000    0.0000
##    140        0.7608             nan     0.1000   -0.0021
##    160        0.7543             nan     0.1000   -0.0006
##    180        0.7508             nan     0.1000   -0.0007
##    200        0.7451             nan     0.1000   -0.0004
##    220        0.7407             nan     0.1000   -0.0003
##    240        0.7366             nan     0.1000   -0.0008
##    250        0.7351             nan     0.1000   -0.0005
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1        1.2694             nan     0.1000    0.0342
##      2        1.2132             nan     0.1000    0.0270
##      3        1.1673             nan     0.1000    0.0193
##      4        1.1268             nan     0.1000    0.0172
##      5        1.0943             nan     0.1000    0.0149
##      6        1.0633             nan     0.1000    0.0143
##      7        1.0323             nan     0.1000    0.0114
##      8        1.0081             nan     0.1000    0.0104
##      9        0.9849             nan     0.1000    0.0097
##     10        0.9682             nan     0.1000    0.0076
##     20        0.8555             nan     0.1000    0.0019
##     40        0.7751             nan     0.1000    0.0004
##     60        0.7477             nan     0.1000   -0.0007
##     80        0.7317             nan     0.1000   -0.0003
##    100        0.7192             nan     0.1000   -0.0011
##    120        0.7046             nan     0.1000   -0.0024
##    140        0.6923             nan     0.1000   -0.0013
##    160        0.6820             nan     0.1000   -0.0010
##    180        0.6706             nan     0.1000   -0.0011
##    200        0.6575             nan     0.1000   -0.0004
##    220        0.6481             nan     0.1000   -0.0018
##    240        0.6418             nan     0.1000   -0.0019
##    250        0.6370             nan     0.1000   -0.0009
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1        1.2589             nan     0.1000    0.0367
##      2        1.1957             nan     0.1000    0.0314
##      3        1.1433             nan     0.1000    0.0247
##      4        1.1035             nan     0.1000    0.0175
##      5        1.0668             nan     0.1000    0.0178
##      6        1.0274             nan     0.1000    0.0182
##      7        0.9992             nan     0.1000    0.0109
##      8        0.9724             nan     0.1000    0.0112
##      9        0.9481             nan     0.1000    0.0101
##     10        0.9292             nan     0.1000    0.0067
##     20        0.8146             nan     0.1000    0.0007
##     40        0.7401             nan     0.1000   -0.0012
##     60        0.7061             nan     0.1000   -0.0009
##     80        0.6831             nan     0.1000   -0.0017
##    100        0.6580             nan     0.1000   -0.0013
##    120        0.6439             nan     0.1000   -0.0028
##    140        0.6297             nan     0.1000   -0.0019
##    160        0.6157             nan     0.1000   -0.0010
##    180        0.6035             nan     0.1000   -0.0012
##    200        0.5892             nan     0.1000   -0.0014
##    220        0.5762             nan     0.1000   -0.0008
##    240        0.5697             nan     0.1000   -0.0016
##    250        0.5648             nan     0.1000   -0.0013
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1        1.2583             nan     0.1000    0.0336
##      2        1.1935             nan     0.1000    0.0295
##      3        1.1363             nan     0.1000    0.0271
##      4        1.0833             nan     0.1000    0.0234
##      5        1.0470             nan     0.1000    0.0183
##      6        1.0131             nan     0.1000    0.0151
##      7        0.9860             nan     0.1000    0.0109
##      8        0.9597             nan     0.1000    0.0098
##      9        0.9378             nan     0.1000    0.0101
##     10        0.9137             nan     0.1000    0.0096
##     20        0.7863             nan     0.1000    0.0010
##     40        0.7127             nan     0.1000   -0.0010
##     60        0.6731             nan     0.1000   -0.0031
##     80        0.6418             nan     0.1000   -0.0012
##    100        0.6154             nan     0.1000   -0.0020
##    120        0.5964             nan     0.1000   -0.0031
##    140        0.5777             nan     0.1000   -0.0007
##    160        0.5601             nan     0.1000   -0.0012
##    180        0.5441             nan     0.1000   -0.0020
##    200        0.5316             nan     0.1000   -0.0018
##    220        0.5188             nan     0.1000   -0.0021
##    240        0.5068             nan     0.1000   -0.0022
##    250        0.5020             nan     0.1000   -0.0013
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1        1.2438             nan     0.1000    0.0389
##      2        1.1756             nan     0.1000    0.0314
##      3        1.1166             nan     0.1000    0.0262
##      4        1.0687             nan     0.1000    0.0208
##      5        1.0259             nan     0.1000    0.0158
##      6        0.9881             nan     0.1000    0.0152
##      7        0.9600             nan     0.1000    0.0114
##      8        0.9341             nan     0.1000    0.0100
##      9        0.9111             nan     0.1000    0.0103
##     10        0.8920             nan     0.1000    0.0055
##     20        0.7743             nan     0.1000   -0.0000
##     40        0.6857             nan     0.1000   -0.0025
##     60        0.6370             nan     0.1000   -0.0013
##     80        0.6043             nan     0.1000   -0.0013
##    100        0.5774             nan     0.1000   -0.0023
##    120        0.5563             nan     0.1000   -0.0022
##    140        0.5316             nan     0.1000   -0.0016
##    160        0.5145             nan     0.1000   -0.0035
##    180        0.4996             nan     0.1000   -0.0023
##    200        0.4842             nan     0.1000   -0.0027
##    220        0.4674             nan     0.1000   -0.0013
##    240        0.4538             nan     0.1000   -0.0021
##    250        0.4457             nan     0.1000   -0.0020
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1        1.2744             nan     0.1000    0.0326
##      2        1.2253             nan     0.1000    0.0260
##      3        1.1785             nan     0.1000    0.0210
##      4        1.1409             nan     0.1000    0.0170
##      5        1.1052             nan     0.1000    0.0158
##      6        1.0771             nan     0.1000    0.0128
##      7        1.0544             nan     0.1000    0.0107
##      8        1.0328             nan     0.1000    0.0096
##      9        1.0138             nan     0.1000    0.0057
##     10        0.9978             nan     0.1000    0.0068
##     20        0.8883             nan     0.1000    0.0025
##     40        0.7959             nan     0.1000   -0.0004
##     60        0.7558             nan     0.1000    0.0003
##     80        0.7390             nan     0.1000   -0.0003
##    100        0.7288             nan     0.1000   -0.0008
##    120        0.7215             nan     0.1000   -0.0009
##    140        0.7147             nan     0.1000   -0.0012
##    160        0.7091             nan     0.1000   -0.0016
##    180        0.7057             nan     0.1000   -0.0012
##    200        0.7021             nan     0.1000   -0.0008
##    220        0.6978             nan     0.1000   -0.0012
##    240        0.6948             nan     0.1000   -0.0009
##    250        0.6928             nan     0.1000   -0.0018
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1        1.2654             nan     0.1000    0.0358
##      2        1.2003             nan     0.1000    0.0312
##      3        1.1508             nan     0.1000    0.0239
##      4        1.1085             nan     0.1000    0.0196
##      5        1.0690             nan     0.1000    0.0172
##      6        1.0403             nan     0.1000    0.0149
##      7        1.0097             nan     0.1000    0.0129
##      8        0.9834             nan     0.1000    0.0118
##      9        0.9615             nan     0.1000    0.0101
##     10        0.9417             nan     0.1000    0.0068
##     20        0.8167             nan     0.1000    0.0036
##     40        0.7389             nan     0.1000   -0.0002
##     60        0.7116             nan     0.1000   -0.0009
##     80        0.6908             nan     0.1000   -0.0004
##    100        0.6771             nan     0.1000   -0.0004
##    120        0.6624             nan     0.1000   -0.0006
##    140        0.6511             nan     0.1000   -0.0013
##    160        0.6426             nan     0.1000   -0.0007
##    180        0.6335             nan     0.1000   -0.0013
##    200        0.6221             nan     0.1000   -0.0012
##    220        0.6123             nan     0.1000   -0.0021
##    240        0.6031             nan     0.1000   -0.0017
##    250        0.5995             nan     0.1000   -0.0011
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1        1.2554             nan     0.1000    0.0395
##      2        1.1886             nan     0.1000    0.0295
##      3        1.1308             nan     0.1000    0.0266
##      4        1.0790             nan     0.1000    0.0228
##      5        1.0361             nan     0.1000    0.0193
##      6        0.9993             nan     0.1000    0.0156
##      7        0.9707             nan     0.1000    0.0113
##      8        0.9435             nan     0.1000    0.0116
##      9        0.9230             nan     0.1000    0.0083
##     10        0.8951             nan     0.1000    0.0114
##     20        0.7665             nan     0.1000    0.0008
##     40        0.7004             nan     0.1000   -0.0025
##     60        0.6702             nan     0.1000   -0.0011
##     80        0.6485             nan     0.1000   -0.0010
##    100        0.6296             nan     0.1000   -0.0016
##    120        0.6095             nan     0.1000   -0.0029
##    140        0.5934             nan     0.1000   -0.0012
##    160        0.5812             nan     0.1000   -0.0012
##    180        0.5656             nan     0.1000   -0.0016
##    200        0.5523             nan     0.1000   -0.0017
##    220        0.5426             nan     0.1000   -0.0016
##    240        0.5316             nan     0.1000   -0.0009
##    250        0.5270             nan     0.1000   -0.0010
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1        1.2505             nan     0.1000    0.0437
##      2        1.1741             nan     0.1000    0.0374
##      3        1.1163             nan     0.1000    0.0252
##      4        1.0636             nan     0.1000    0.0243
##      5        1.0153             nan     0.1000    0.0190
##      6        0.9820             nan     0.1000    0.0148
##      7        0.9452             nan     0.1000    0.0141
##      8        0.9207             nan     0.1000    0.0094
##      9        0.8964             nan     0.1000    0.0106
##     10        0.8735             nan     0.1000    0.0083
##     20        0.7543             nan     0.1000    0.0016
##     40        0.6815             nan     0.1000   -0.0017
##     60        0.6381             nan     0.1000   -0.0024
##     80        0.6108             nan     0.1000   -0.0015
##    100        0.5869             nan     0.1000   -0.0020
##    120        0.5637             nan     0.1000   -0.0021
##    140        0.5481             nan     0.1000   -0.0020
##    160        0.5262             nan     0.1000   -0.0023
##    180        0.5072             nan     0.1000   -0.0016
##    200        0.4947             nan     0.1000   -0.0025
##    220        0.4799             nan     0.1000   -0.0011
##    240        0.4691             nan     0.1000   -0.0018
##    250        0.4627             nan     0.1000   -0.0017
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1        1.2448             nan     0.1000    0.0450
##      2        1.1726             nan     0.1000    0.0307
##      3        1.1134             nan     0.1000    0.0289
##      4        1.0543             nan     0.1000    0.0220
##      5        1.0142             nan     0.1000    0.0184
##      6        0.9726             nan     0.1000    0.0195
##      7        0.9416             nan     0.1000    0.0134
##      8        0.9152             nan     0.1000    0.0121
##      9        0.8898             nan     0.1000    0.0110
##     10        0.8655             nan     0.1000    0.0096
##     20        0.7372             nan     0.1000    0.0006
##     40        0.6572             nan     0.1000   -0.0009
##     60        0.6154             nan     0.1000   -0.0005
##     80        0.5848             nan     0.1000   -0.0022
##    100        0.5515             nan     0.1000   -0.0018
##    120        0.5248             nan     0.1000   -0.0024
##    140        0.5051             nan     0.1000   -0.0029
##    160        0.4820             nan     0.1000   -0.0012
##    180        0.4647             nan     0.1000   -0.0016
##    200        0.4459             nan     0.1000   -0.0019
##    220        0.4280             nan     0.1000   -0.0027
##    240        0.4156             nan     0.1000   -0.0023
##    250        0.4068             nan     0.1000   -0.0005
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1        1.2762             nan     0.1000    0.0308
##      2        1.2245             nan     0.1000    0.0249
##      3        1.1864             nan     0.1000    0.0196
##      4        1.1519             nan     0.1000    0.0155
##      5        1.1237             nan     0.1000    0.0136
##      6        1.0939             nan     0.1000    0.0111
##      7        1.0738             nan     0.1000    0.0090
##      8        1.0531             nan     0.1000    0.0100
##      9        1.0340             nan     0.1000    0.0067
##     10        1.0186             nan     0.1000    0.0081
##     20        0.9204             nan     0.1000    0.0022
##     40        0.8343             nan     0.1000    0.0003
##     60        0.7959             nan     0.1000   -0.0000
##     80        0.7758             nan     0.1000    0.0001
##    100        0.7682             nan     0.1000   -0.0001
##    120        0.7605             nan     0.1000   -0.0005
##    140        0.7558             nan     0.1000   -0.0009
##    160        0.7511             nan     0.1000   -0.0010
##    180        0.7480             nan     0.1000   -0.0013
##    200        0.7441             nan     0.1000   -0.0010
##    220        0.7406             nan     0.1000   -0.0003
##    240        0.7378             nan     0.1000   -0.0005
##    250        0.7360             nan     0.1000   -0.0012
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1        1.2682             nan     0.1000    0.0308
##      2        1.2098             nan     0.1000    0.0304
##      3        1.1625             nan     0.1000    0.0205
##      4        1.1229             nan     0.1000    0.0208
##      5        1.0891             nan     0.1000    0.0173
##      6        1.0589             nan     0.1000    0.0140
##      7        1.0296             nan     0.1000    0.0138
##      8        1.0048             nan     0.1000    0.0106
##      9        0.9807             nan     0.1000    0.0101
##     10        0.9610             nan     0.1000    0.0081
##     20        0.8458             nan     0.1000    0.0033
##     40        0.7726             nan     0.1000   -0.0009
##     60        0.7425             nan     0.1000   -0.0015
##     80        0.7215             nan     0.1000   -0.0009
##    100        0.7074             nan     0.1000   -0.0001
##    120        0.6962             nan     0.1000   -0.0011
##    140        0.6862             nan     0.1000   -0.0006
##    160        0.6760             nan     0.1000   -0.0018
##    180        0.6656             nan     0.1000   -0.0017
##    200        0.6589             nan     0.1000   -0.0020
##    220        0.6525             nan     0.1000   -0.0008
##    240        0.6443             nan     0.1000   -0.0018
##    250        0.6380             nan     0.1000   -0.0027
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1        1.2605             nan     0.1000    0.0383
##      2        1.1943             nan     0.1000    0.0307
##      3        1.1408             nan     0.1000    0.0262
##      4        1.1000             nan     0.1000    0.0199
##      5        1.0583             nan     0.1000    0.0188
##      6        1.0235             nan     0.1000    0.0148
##      7        0.9881             nan     0.1000    0.0154
##      8        0.9603             nan     0.1000    0.0093
##      9        0.9385             nan     0.1000    0.0077
##     10        0.9217             nan     0.1000    0.0064
##     20        0.8050             nan     0.1000    0.0008
##     40        0.7371             nan     0.1000   -0.0016
##     60        0.7033             nan     0.1000   -0.0011
##     80        0.6772             nan     0.1000   -0.0016
##    100        0.6570             nan     0.1000   -0.0008
##    120        0.6413             nan     0.1000   -0.0016
##    140        0.6280             nan     0.1000   -0.0010
##    160        0.6108             nan     0.1000   -0.0011
##    180        0.5963             nan     0.1000   -0.0017
##    200        0.5846             nan     0.1000   -0.0019
##    220        0.5687             nan     0.1000   -0.0014
##    240        0.5584             nan     0.1000   -0.0016
##    250        0.5534             nan     0.1000   -0.0008
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1        1.2540             nan     0.1000    0.0417
##      2        1.1819             nan     0.1000    0.0335
##      3        1.1257             nan     0.1000    0.0243
##      4        1.0775             nan     0.1000    0.0199
##      5        1.0352             nan     0.1000    0.0193
##      6        0.9973             nan     0.1000    0.0156
##      7        0.9709             nan     0.1000    0.0113
##      8        0.9455             nan     0.1000    0.0102
##      9        0.9206             nan     0.1000    0.0102
##     10        0.8977             nan     0.1000    0.0099
##     20        0.7806             nan     0.1000    0.0023
##     40        0.7057             nan     0.1000   -0.0022
##     60        0.6621             nan     0.1000   -0.0014
##     80        0.6314             nan     0.1000   -0.0012
##    100        0.6089             nan     0.1000   -0.0032
##    120        0.5900             nan     0.1000   -0.0012
##    140        0.5680             nan     0.1000   -0.0025
##    160        0.5463             nan     0.1000   -0.0009
##    180        0.5336             nan     0.1000   -0.0025
##    200        0.5166             nan     0.1000   -0.0020
##    220        0.5015             nan     0.1000   -0.0015
##    240        0.4869             nan     0.1000   -0.0015
##    250        0.4803             nan     0.1000   -0.0026
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1        1.2480             nan     0.1000    0.0440
##      2        1.1726             nan     0.1000    0.0316
##      3        1.1131             nan     0.1000    0.0243
##      4        1.0572             nan     0.1000    0.0226
##      5        1.0135             nan     0.1000    0.0177
##      6        0.9761             nan     0.1000    0.0146
##      7        0.9457             nan     0.1000    0.0141
##      8        0.9156             nan     0.1000    0.0098
##      9        0.8948             nan     0.1000    0.0078
##     10        0.8754             nan     0.1000    0.0077
##     20        0.7648             nan     0.1000   -0.0002
##     40        0.6878             nan     0.1000   -0.0013
##     60        0.6439             nan     0.1000   -0.0013
##     80        0.6061             nan     0.1000   -0.0035
##    100        0.5768             nan     0.1000   -0.0001
##    120        0.5497             nan     0.1000   -0.0021
##    140        0.5269             nan     0.1000   -0.0021
##    160        0.5087             nan     0.1000   -0.0030
##    180        0.4924             nan     0.1000   -0.0023
##    200        0.4748             nan     0.1000   -0.0014
##    220        0.4589             nan     0.1000   -0.0026
##    240        0.4443             nan     0.1000   -0.0009
##    250        0.4391             nan     0.1000   -0.0016
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1        1.2817             nan     0.1000    0.0286
##      2        1.2318             nan     0.1000    0.0196
##      3        1.1833             nan     0.1000    0.0207
##      4        1.1473             nan     0.1000    0.0169
##      5        1.1172             nan     0.1000    0.0141
##      6        1.0908             nan     0.1000    0.0125
##      7        1.0682             nan     0.1000    0.0104
##      8        1.0447             nan     0.1000    0.0083
##      9        1.0267             nan     0.1000    0.0073
##     10        1.0134             nan     0.1000    0.0065
##     20        0.9106             nan     0.1000    0.0022
##     40        0.8243             nan     0.1000   -0.0005
##     60        0.7839             nan     0.1000   -0.0004
##     80        0.7633             nan     0.1000   -0.0011
##    100        0.7528             nan     0.1000   -0.0016
##    120        0.7453             nan     0.1000   -0.0006
##    140        0.7409             nan     0.1000   -0.0007
##    160        0.7368             nan     0.1000   -0.0009
##    180        0.7326             nan     0.1000   -0.0010
##    200        0.7280             nan     0.1000   -0.0006
##    220        0.7245             nan     0.1000   -0.0007
##    240        0.7211             nan     0.1000   -0.0010
##    250        0.7192             nan     0.1000   -0.0007
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1        1.2650             nan     0.1000    0.0342
##      2        1.1992             nan     0.1000    0.0264
##      3        1.1480             nan     0.1000    0.0224
##      4        1.1119             nan     0.1000    0.0158
##      5        1.0761             nan     0.1000    0.0157
##      6        1.0450             nan     0.1000    0.0129
##      7        1.0179             nan     0.1000    0.0101
##      8        0.9971             nan     0.1000    0.0076
##      9        0.9718             nan     0.1000    0.0112
##     10        0.9508             nan     0.1000    0.0090
##     20        0.8388             nan     0.1000    0.0019
##     40        0.7541             nan     0.1000   -0.0003
##     60        0.7289             nan     0.1000   -0.0023
##     80        0.7074             nan     0.1000   -0.0013
##    100        0.6927             nan     0.1000   -0.0009
##    120        0.6829             nan     0.1000   -0.0020
##    140        0.6734             nan     0.1000   -0.0022
##    160        0.6632             nan     0.1000   -0.0015
##    180        0.6523             nan     0.1000   -0.0007
##    200        0.6429             nan     0.1000   -0.0007
##    220        0.6336             nan     0.1000   -0.0015
##    240        0.6272             nan     0.1000   -0.0014
##    250        0.6229             nan     0.1000   -0.0009
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1        1.2552             nan     0.1000    0.0378
##      2        1.1847             nan     0.1000    0.0326
##      3        1.1324             nan     0.1000    0.0271
##      4        1.0835             nan     0.1000    0.0228
##      5        1.0472             nan     0.1000    0.0176
##      6        1.0118             nan     0.1000    0.0148
##      7        0.9811             nan     0.1000    0.0165
##      8        0.9578             nan     0.1000    0.0087
##      9        0.9327             nan     0.1000    0.0110
##     10        0.9076             nan     0.1000    0.0085
##     20        0.7927             nan     0.1000    0.0013
##     40        0.7215             nan     0.1000    0.0001
##     60        0.6949             nan     0.1000   -0.0024
##     80        0.6675             nan     0.1000   -0.0010
##    100        0.6476             nan     0.1000   -0.0018
##    120        0.6315             nan     0.1000   -0.0020
##    140        0.6128             nan     0.1000   -0.0014
##    160        0.5951             nan     0.1000   -0.0011
##    180        0.5790             nan     0.1000   -0.0014
##    200        0.5655             nan     0.1000   -0.0015
##    220        0.5529             nan     0.1000   -0.0013
##    240        0.5408             nan     0.1000   -0.0015
##    250        0.5335             nan     0.1000   -0.0009
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1        1.2493             nan     0.1000    0.0414
##      2        1.1784             nan     0.1000    0.0338
##      3        1.1202             nan     0.1000    0.0274
##      4        1.0722             nan     0.1000    0.0237
##      5        1.0327             nan     0.1000    0.0167
##      6        0.9953             nan     0.1000    0.0173
##      7        0.9607             nan     0.1000    0.0155
##      8        0.9356             nan     0.1000    0.0098
##      9        0.9078             nan     0.1000    0.0104
##     10        0.8864             nan     0.1000    0.0082
##     20        0.7682             nan     0.1000    0.0017
##     40        0.6961             nan     0.1000   -0.0020
##     60        0.6554             nan     0.1000   -0.0022
##     80        0.6206             nan     0.1000   -0.0008
##    100        0.5969             nan     0.1000   -0.0018
##    120        0.5720             nan     0.1000   -0.0021
##    140        0.5518             nan     0.1000   -0.0018
##    160        0.5346             nan     0.1000   -0.0028
##    180        0.5219             nan     0.1000   -0.0011
##    200        0.5061             nan     0.1000   -0.0017
##    220        0.4920             nan     0.1000   -0.0015
##    240        0.4776             nan     0.1000   -0.0021
##    250        0.4705             nan     0.1000   -0.0026
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1        1.2467             nan     0.1000    0.0423
##      2        1.1749             nan     0.1000    0.0334
##      3        1.1120             nan     0.1000    0.0250
##      4        1.0588             nan     0.1000    0.0251
##      5        1.0142             nan     0.1000    0.0200
##      6        0.9777             nan     0.1000    0.0139
##      7        0.9459             nan     0.1000    0.0115
##      8        0.9176             nan     0.1000    0.0111
##      9        0.8922             nan     0.1000    0.0111
##     10        0.8699             nan     0.1000    0.0083
##     20        0.7529             nan     0.1000    0.0010
##     40        0.6714             nan     0.1000   -0.0007
##     60        0.6188             nan     0.1000   -0.0022
##     80        0.5867             nan     0.1000   -0.0028
##    100        0.5628             nan     0.1000   -0.0023
##    120        0.5400             nan     0.1000   -0.0029
##    140        0.5213             nan     0.1000   -0.0032
##    160        0.5009             nan     0.1000   -0.0021
##    180        0.4833             nan     0.1000   -0.0013
##    200        0.4646             nan     0.1000   -0.0024
##    220        0.4499             nan     0.1000   -0.0020
##    240        0.4308             nan     0.1000   -0.0016
##    250        0.4217             nan     0.1000   -0.0019
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1        1.2762             nan     0.1000    0.0307
##      2        1.2237             nan     0.1000    0.0252
##      3        1.1895             nan     0.1000    0.0156
##      4        1.1525             nan     0.1000    0.0173
##      5        1.1218             nan     0.1000    0.0137
##      6        1.0958             nan     0.1000    0.0129
##      7        1.0752             nan     0.1000    0.0098
##      8        1.0572             nan     0.1000    0.0081
##      9        1.0382             nan     0.1000    0.0091
##     10        1.0194             nan     0.1000    0.0062
##     20        0.9202             nan     0.1000    0.0026
##     40        0.8290             nan     0.1000    0.0005
##     60        0.7926             nan     0.1000   -0.0007
##     80        0.7742             nan     0.1000   -0.0010
##    100        0.7654             nan     0.1000   -0.0003
##    120        0.7614             nan     0.1000   -0.0009
##    140        0.7548             nan     0.1000   -0.0006
##    160        0.7494             nan     0.1000   -0.0010
##    180        0.7440             nan     0.1000   -0.0007
##    200        0.7406             nan     0.1000   -0.0005
##    220        0.7374             nan     0.1000   -0.0010
##    240        0.7342             nan     0.1000   -0.0011
##    250        0.7331             nan     0.1000   -0.0012
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1        1.2627             nan     0.1000    0.0328
##      2        1.2039             nan     0.1000    0.0274
##      3        1.1596             nan     0.1000    0.0202
##      4        1.1186             nan     0.1000    0.0184
##      5        1.0835             nan     0.1000    0.0165
##      6        1.0516             nan     0.1000    0.0159
##      7        1.0272             nan     0.1000    0.0104
##      8        1.0067             nan     0.1000    0.0110
##      9        0.9845             nan     0.1000    0.0084
##     10        0.9642             nan     0.1000    0.0094
##     20        0.8460             nan     0.1000    0.0021
##     40        0.7620             nan     0.1000   -0.0010
##     60        0.7353             nan     0.1000   -0.0011
##     80        0.7187             nan     0.1000   -0.0004
##    100        0.7038             nan     0.1000   -0.0020
##    120        0.6912             nan     0.1000   -0.0018
##    140        0.6767             nan     0.1000   -0.0012
##    160        0.6672             nan     0.1000   -0.0008
##    180        0.6574             nan     0.1000   -0.0014
##    200        0.6477             nan     0.1000   -0.0006
##    220        0.6382             nan     0.1000   -0.0019
##    240        0.6308             nan     0.1000    0.0000
##    250        0.6260             nan     0.1000   -0.0004
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1        1.2518             nan     0.1000    0.0382
##      2        1.1870             nan     0.1000    0.0317
##      3        1.1397             nan     0.1000    0.0236
##      4        1.0970             nan     0.1000    0.0193
##      5        1.0549             nan     0.1000    0.0177
##      6        1.0165             nan     0.1000    0.0175
##      7        0.9884             nan     0.1000    0.0134
##      8        0.9611             nan     0.1000    0.0102
##      9        0.9392             nan     0.1000    0.0079
##     10        0.9213             nan     0.1000    0.0071
##     20        0.8017             nan     0.1000    0.0002
##     40        0.7286             nan     0.1000   -0.0015
##     60        0.6916             nan     0.1000   -0.0018
##     80        0.6702             nan     0.1000   -0.0025
##    100        0.6508             nan     0.1000   -0.0010
##    120        0.6274             nan     0.1000   -0.0014
##    140        0.6171             nan     0.1000   -0.0015
##    160        0.6021             nan     0.1000   -0.0031
##    180        0.5842             nan     0.1000   -0.0015
##    200        0.5677             nan     0.1000   -0.0017
##    220        0.5545             nan     0.1000   -0.0018
##    240        0.5422             nan     0.1000   -0.0006
##    250        0.5393             nan     0.1000   -0.0023
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1        1.2508             nan     0.1000    0.0416
##      2        1.1876             nan     0.1000    0.0319
##      3        1.1345             nan     0.1000    0.0268
##      4        1.0859             nan     0.1000    0.0231
##      5        1.0477             nan     0.1000    0.0145
##      6        1.0147             nan     0.1000    0.0142
##      7        0.9757             nan     0.1000    0.0150
##      8        0.9465             nan     0.1000    0.0117
##      9        0.9224             nan     0.1000    0.0086
##     10        0.9007             nan     0.1000    0.0076
##     20        0.7826             nan     0.1000    0.0011
##     40        0.7046             nan     0.1000    0.0001
##     60        0.6675             nan     0.1000   -0.0010
##     80        0.6397             nan     0.1000   -0.0010
##    100        0.6105             nan     0.1000   -0.0010
##    120        0.5894             nan     0.1000   -0.0011
##    140        0.5678             nan     0.1000   -0.0015
##    160        0.5573             nan     0.1000   -0.0019
##    180        0.5361             nan     0.1000   -0.0006
##    200        0.5163             nan     0.1000   -0.0016
##    220        0.5013             nan     0.1000   -0.0012
##    240        0.4892             nan     0.1000   -0.0018
##    250        0.4826             nan     0.1000   -0.0006
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1        1.2508             nan     0.1000    0.0385
##      2        1.1781             nan     0.1000    0.0328
##      3        1.1201             nan     0.1000    0.0278
##      4        1.0647             nan     0.1000    0.0234
##      5        1.0222             nan     0.1000    0.0166
##      6        0.9885             nan     0.1000    0.0131
##      7        0.9619             nan     0.1000    0.0105
##      8        0.9382             nan     0.1000    0.0108
##      9        0.9133             nan     0.1000    0.0090
##     10        0.8955             nan     0.1000    0.0069
##     20        0.7667             nan     0.1000    0.0001
##     40        0.6844             nan     0.1000   -0.0025
##     60        0.6404             nan     0.1000   -0.0005
##     80        0.6008             nan     0.1000   -0.0030
##    100        0.5677             nan     0.1000   -0.0019
##    120        0.5438             nan     0.1000   -0.0020
##    140        0.5229             nan     0.1000   -0.0021
##    160        0.5044             nan     0.1000   -0.0032
##    180        0.4825             nan     0.1000   -0.0019
##    200        0.4665             nan     0.1000   -0.0016
##    220        0.4503             nan     0.1000   -0.0010
##    240        0.4358             nan     0.1000   -0.0013
##    250        0.4267             nan     0.1000   -0.0017
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1        1.2724             nan     0.1000    0.0297
##      2        1.2244             nan     0.1000    0.0229
##      3        1.1857             nan     0.1000    0.0198
##      4        1.1477             nan     0.1000    0.0177
##      5        1.1169             nan     0.1000    0.0136
##      6        1.0859             nan     0.1000    0.0124
##      7        1.0609             nan     0.1000    0.0110
##      8        1.0412             nan     0.1000    0.0097
##      9        1.0249             nan     0.1000    0.0078
##     10        1.0118             nan     0.1000    0.0062
##     20        0.9127             nan     0.1000    0.0028
##     40        0.8179             nan     0.1000    0.0001
##     60        0.7791             nan     0.1000   -0.0004
##     80        0.7582             nan     0.1000   -0.0005
##    100        0.7503             nan     0.1000   -0.0011
##    120        0.7446             nan     0.1000   -0.0012
##    140        0.7367             nan     0.1000   -0.0005
##    160        0.7331             nan     0.1000   -0.0004
##    180        0.7284             nan     0.1000   -0.0006
##    200        0.7230             nan     0.1000   -0.0011
##    220        0.7177             nan     0.1000   -0.0010
##    240        0.7139             nan     0.1000   -0.0007
##    250        0.7117             nan     0.1000   -0.0009
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1        1.2735             nan     0.1000    0.0321
##      2        1.2098             nan     0.1000    0.0280
##      3        1.1616             nan     0.1000    0.0247
##      4        1.1171             nan     0.1000    0.0207
##      5        1.0819             nan     0.1000    0.0149
##      6        1.0509             nan     0.1000    0.0129
##      7        1.0189             nan     0.1000    0.0142
##      8        0.9928             nan     0.1000    0.0116
##      9        0.9769             nan     0.1000    0.0067
##     10        0.9561             nan     0.1000    0.0069
##     20        0.8347             nan     0.1000    0.0032
##     40        0.7568             nan     0.1000   -0.0007
##     60        0.7246             nan     0.1000   -0.0028
##     80        0.7083             nan     0.1000   -0.0028
##    100        0.6912             nan     0.1000   -0.0008
##    120        0.6766             nan     0.1000   -0.0004
##    140        0.6637             nan     0.1000   -0.0010
##    160        0.6531             nan     0.1000   -0.0003
##    180        0.6431             nan     0.1000   -0.0007
##    200        0.6329             nan     0.1000   -0.0017
##    220        0.6258             nan     0.1000   -0.0016
##    240        0.6164             nan     0.1000   -0.0014
##    250        0.6141             nan     0.1000   -0.0013
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1        1.2531             nan     0.1000    0.0330
##      2        1.1935             nan     0.1000    0.0295
##      3        1.1325             nan     0.1000    0.0290
##      4        1.0852             nan     0.1000    0.0231
##      5        1.0476             nan     0.1000    0.0185
##      6        1.0160             nan     0.1000    0.0132
##      7        0.9835             nan     0.1000    0.0129
##      8        0.9597             nan     0.1000    0.0096
##      9        0.9335             nan     0.1000    0.0106
##     10        0.9156             nan     0.1000    0.0068
##     20        0.7979             nan     0.1000    0.0008
##     40        0.7258             nan     0.1000   -0.0013
##     60        0.6903             nan     0.1000   -0.0007
##     80        0.6607             nan     0.1000   -0.0002
##    100        0.6382             nan     0.1000   -0.0014
##    120        0.6213             nan     0.1000   -0.0015
##    140        0.6018             nan     0.1000   -0.0014
##    160        0.5865             nan     0.1000   -0.0011
##    180        0.5724             nan     0.1000   -0.0006
##    200        0.5610             nan     0.1000   -0.0015
##    220        0.5495             nan     0.1000   -0.0017
##    240        0.5368             nan     0.1000   -0.0019
##    250        0.5320             nan     0.1000   -0.0023
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1        1.2513             nan     0.1000    0.0428
##      2        1.1807             nan     0.1000    0.0294
##      3        1.1249             nan     0.1000    0.0272
##      4        1.0785             nan     0.1000    0.0195
##      5        1.0329             nan     0.1000    0.0183
##      6        1.0004             nan     0.1000    0.0136
##      7        0.9728             nan     0.1000    0.0113
##      8        0.9416             nan     0.1000    0.0149
##      9        0.9110             nan     0.1000    0.0093
##     10        0.8887             nan     0.1000    0.0091
##     20        0.7692             nan     0.1000   -0.0001
##     40        0.6928             nan     0.1000   -0.0013
##     60        0.6541             nan     0.1000   -0.0014
##     80        0.6260             nan     0.1000   -0.0010
##    100        0.5998             nan     0.1000   -0.0022
##    120        0.5754             nan     0.1000   -0.0017
##    140        0.5532             nan     0.1000   -0.0014
##    160        0.5348             nan     0.1000   -0.0029
##    180        0.5153             nan     0.1000   -0.0014
##    200        0.4980             nan     0.1000   -0.0013
##    220        0.4855             nan     0.1000   -0.0008
##    240        0.4754             nan     0.1000   -0.0021
##    250        0.4694             nan     0.1000   -0.0016
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1        1.2475             nan     0.1000    0.0425
##      2        1.1759             nan     0.1000    0.0344
##      3        1.1233             nan     0.1000    0.0223
##      4        1.0717             nan     0.1000    0.0187
##      5        1.0297             nan     0.1000    0.0189
##      6        0.9918             nan     0.1000    0.0166
##      7        0.9597             nan     0.1000    0.0156
##      8        0.9278             nan     0.1000    0.0129
##      9        0.9033             nan     0.1000    0.0097
##     10        0.8799             nan     0.1000    0.0095
##     20        0.7574             nan     0.1000   -0.0001
##     40        0.6716             nan     0.1000   -0.0023
##     60        0.6282             nan     0.1000   -0.0013
##     80        0.5979             nan     0.1000   -0.0028
##    100        0.5737             nan     0.1000   -0.0008
##    120        0.5512             nan     0.1000   -0.0021
##    140        0.5289             nan     0.1000   -0.0020
##    160        0.5000             nan     0.1000   -0.0017
##    180        0.4823             nan     0.1000   -0.0028
##    200        0.4611             nan     0.1000   -0.0043
##    220        0.4439             nan     0.1000   -0.0019
##    240        0.4286             nan     0.1000   -0.0013
##    250        0.4205             nan     0.1000   -0.0019
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1        1.2742             nan     0.1000    0.0296
##      2        1.2281             nan     0.1000    0.0207
##      3        1.1808             nan     0.1000    0.0210
##      4        1.1405             nan     0.1000    0.0146
##      5        1.1119             nan     0.1000    0.0136
##      6        1.0888             nan     0.1000    0.0120
##      7        1.0655             nan     0.1000    0.0108
##      8        1.0464             nan     0.1000    0.0060
##      9        1.0310             nan     0.1000    0.0052
##     10        1.0123             nan     0.1000    0.0085
##     20        0.9188             nan     0.1000    0.0021
##     40        0.8232             nan     0.1000    0.0010
##     60        0.7849             nan     0.1000    0.0000
##     80        0.7707             nan     0.1000   -0.0004
##    100        0.7590             nan     0.1000   -0.0005
##    120        0.7527             nan     0.1000   -0.0010
##    140        0.7481             nan     0.1000   -0.0008
##    160        0.7426             nan     0.1000   -0.0017
##    180        0.7386             nan     0.1000   -0.0008
##    200        0.7339             nan     0.1000   -0.0005
##    220        0.7290             nan     0.1000   -0.0004
##    240        0.7250             nan     0.1000   -0.0003
##    250        0.7238             nan     0.1000   -0.0009
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1        1.2693             nan     0.1000    0.0317
##      2        1.2097             nan     0.1000    0.0254
##      3        1.1595             nan     0.1000    0.0221
##      4        1.1196             nan     0.1000    0.0177
##      5        1.0830             nan     0.1000    0.0162
##      6        1.0516             nan     0.1000    0.0137
##      7        1.0214             nan     0.1000    0.0118
##      8        0.9989             nan     0.1000    0.0114
##      9        0.9786             nan     0.1000    0.0086
##     10        0.9619             nan     0.1000    0.0070
##     20        0.8441             nan     0.1000    0.0022
##     40        0.7603             nan     0.1000    0.0005
##     60        0.7335             nan     0.1000   -0.0010
##     80        0.7190             nan     0.1000   -0.0008
##    100        0.6995             nan     0.1000   -0.0007
##    120        0.6880             nan     0.1000   -0.0011
##    140        0.6790             nan     0.1000   -0.0011
##    160        0.6647             nan     0.1000   -0.0011
##    180        0.6549             nan     0.1000   -0.0012
##    200        0.6461             nan     0.1000    0.0002
##    220        0.6386             nan     0.1000   -0.0008
##    240        0.6317             nan     0.1000   -0.0012
##    250        0.6281             nan     0.1000   -0.0010
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1        1.2640             nan     0.1000    0.0358
##      2        1.1969             nan     0.1000    0.0308
##      3        1.1371             nan     0.1000    0.0270
##      4        1.0927             nan     0.1000    0.0229
##      5        1.0577             nan     0.1000    0.0180
##      6        1.0214             nan     0.1000    0.0158
##      7        0.9897             nan     0.1000    0.0146
##      8        0.9667             nan     0.1000    0.0103
##      9        0.9406             nan     0.1000    0.0113
##     10        0.9180             nan     0.1000    0.0068
##     20        0.7990             nan     0.1000    0.0016
##     40        0.7272             nan     0.1000   -0.0017
##     60        0.6907             nan     0.1000   -0.0022
##     80        0.6700             nan     0.1000   -0.0014
##    100        0.6504             nan     0.1000   -0.0011
##    120        0.6350             nan     0.1000   -0.0018
##    140        0.6234             nan     0.1000   -0.0019
##    160        0.6082             nan     0.1000   -0.0014
##    180        0.5987             nan     0.1000   -0.0034
##    200        0.5848             nan     0.1000   -0.0022
##    220        0.5746             nan     0.1000   -0.0025
##    240        0.5639             nan     0.1000   -0.0018
##    250        0.5565             nan     0.1000   -0.0003
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1        1.2558             nan     0.1000    0.0387
##      2        1.1883             nan     0.1000    0.0309
##      3        1.1313             nan     0.1000    0.0259
##      4        1.0867             nan     0.1000    0.0220
##      5        1.0448             nan     0.1000    0.0210
##      6        1.0088             nan     0.1000    0.0154
##      7        0.9775             nan     0.1000    0.0152
##      8        0.9428             nan     0.1000    0.0118
##      9        0.9179             nan     0.1000    0.0092
##     10        0.8962             nan     0.1000    0.0090
##     20        0.7825             nan     0.1000    0.0013
##     40        0.7073             nan     0.1000   -0.0023
##     60        0.6686             nan     0.1000   -0.0027
##     80        0.6423             nan     0.1000   -0.0014
##    100        0.6154             nan     0.1000   -0.0029
##    120        0.5965             nan     0.1000   -0.0012
##    140        0.5753             nan     0.1000   -0.0015
##    160        0.5601             nan     0.1000   -0.0019
##    180        0.5447             nan     0.1000   -0.0017
##    200        0.5315             nan     0.1000   -0.0012
##    220        0.5192             nan     0.1000   -0.0019
##    240        0.5022             nan     0.1000   -0.0015
##    250        0.4979             nan     0.1000   -0.0020
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1        1.2433             nan     0.1000    0.0391
##      2        1.1705             nan     0.1000    0.0324
##      3        1.1103             nan     0.1000    0.0279
##      4        1.0628             nan     0.1000    0.0183
##      5        1.0198             nan     0.1000    0.0182
##      6        0.9854             nan     0.1000    0.0126
##      7        0.9561             nan     0.1000    0.0118
##      8        0.9272             nan     0.1000    0.0122
##      9        0.9025             nan     0.1000    0.0084
##     10        0.8811             nan     0.1000    0.0073
##     20        0.7568             nan     0.1000    0.0016
##     40        0.6802             nan     0.1000   -0.0015
##     60        0.6427             nan     0.1000   -0.0018
##     80        0.6116             nan     0.1000   -0.0025
##    100        0.5804             nan     0.1000   -0.0025
##    120        0.5581             nan     0.1000   -0.0016
##    140        0.5340             nan     0.1000   -0.0013
##    160        0.5115             nan     0.1000   -0.0024
##    180        0.4936             nan     0.1000   -0.0025
##    200        0.4790             nan     0.1000   -0.0016
##    220        0.4646             nan     0.1000   -0.0014
##    240        0.4497             nan     0.1000   -0.0019
##    250        0.4417             nan     0.1000   -0.0023
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1        1.2763             nan     0.1000    0.0311
##      2        1.2274             nan     0.1000    0.0247
##      3        1.1846             nan     0.1000    0.0193
##      4        1.1482             nan     0.1000    0.0174
##      5        1.1193             nan     0.1000    0.0126
##      6        1.0906             nan     0.1000    0.0107
##      7        1.0706             nan     0.1000    0.0090
##      8        1.0499             nan     0.1000    0.0084
##      9        1.0323             nan     0.1000    0.0073
##     10        1.0162             nan     0.1000    0.0062
##     20        0.9200             nan     0.1000    0.0018
##     40        0.8283             nan     0.1000    0.0011
##     60        0.7906             nan     0.1000    0.0001
##     80        0.7758             nan     0.1000   -0.0013
##    100        0.7668             nan     0.1000   -0.0001
##    120        0.7594             nan     0.1000   -0.0006
##    140        0.7563             nan     0.1000   -0.0011
##    160        0.7528             nan     0.1000   -0.0003
##    180        0.7490             nan     0.1000   -0.0008
##    200        0.7429             nan     0.1000   -0.0003
##    220        0.7378             nan     0.1000   -0.0009
##    240        0.7346             nan     0.1000   -0.0012
##    250        0.7317             nan     0.1000   -0.0009
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1        1.2643             nan     0.1000    0.0325
##      2        1.2094             nan     0.1000    0.0251
##      3        1.1601             nan     0.1000    0.0231
##      4        1.1150             nan     0.1000    0.0206
##      5        1.0822             nan     0.1000    0.0159
##      6        1.0496             nan     0.1000    0.0142
##      7        1.0238             nan     0.1000    0.0113
##      8        0.9958             nan     0.1000    0.0115
##      9        0.9767             nan     0.1000    0.0070
##     10        0.9586             nan     0.1000    0.0066
##     20        0.8444             nan     0.1000    0.0030
##     40        0.7691             nan     0.1000    0.0003
##     60        0.7425             nan     0.1000   -0.0016
##     80        0.7204             nan     0.1000    0.0000
##    100        0.7076             nan     0.1000   -0.0016
##    120        0.6923             nan     0.1000   -0.0015
##    140        0.6812             nan     0.1000   -0.0010
##    160        0.6730             nan     0.1000   -0.0010
##    180        0.6633             nan     0.1000   -0.0011
##    200        0.6530             nan     0.1000   -0.0016
##    220        0.6440             nan     0.1000   -0.0007
##    240        0.6342             nan     0.1000   -0.0008
##    250        0.6291             nan     0.1000   -0.0005
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1        1.2609             nan     0.1000    0.0393
##      2        1.1974             nan     0.1000    0.0318
##      3        1.1398             nan     0.1000    0.0239
##      4        1.0909             nan     0.1000    0.0216
##      5        1.0540             nan     0.1000    0.0178
##      6        1.0179             nan     0.1000    0.0156
##      7        0.9858             nan     0.1000    0.0134
##      8        0.9578             nan     0.1000    0.0105
##      9        0.9392             nan     0.1000    0.0080
##     10        0.9187             nan     0.1000    0.0094
##     20        0.8029             nan     0.1000    0.0003
##     40        0.7280             nan     0.1000   -0.0006
##     60        0.6966             nan     0.1000   -0.0014
##     80        0.6696             nan     0.1000   -0.0015
##    100        0.6510             nan     0.1000   -0.0014
##    120        0.6336             nan     0.1000   -0.0007
##    140        0.6195             nan     0.1000   -0.0010
##    160        0.6058             nan     0.1000   -0.0017
##    180        0.5919             nan     0.1000   -0.0004
##    200        0.5793             nan     0.1000   -0.0006
##    220        0.5709             nan     0.1000   -0.0012
##    240        0.5592             nan     0.1000   -0.0013
##    250        0.5541             nan     0.1000   -0.0019
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1        1.2519             nan     0.1000    0.0412
##      2        1.1837             nan     0.1000    0.0334
##      3        1.1256             nan     0.1000    0.0275
##      4        1.0792             nan     0.1000    0.0198
##      5        1.0409             nan     0.1000    0.0173
##      6        1.0113             nan     0.1000    0.0118
##      7        0.9773             nan     0.1000    0.0149
##      8        0.9492             nan     0.1000    0.0113
##      9        0.9259             nan     0.1000    0.0085
##     10        0.9026             nan     0.1000    0.0082
##     20        0.7905             nan     0.1000    0.0018
##     40        0.7084             nan     0.1000   -0.0012
##     60        0.6664             nan     0.1000   -0.0013
##     80        0.6278             nan     0.1000   -0.0010
##    100        0.6054             nan     0.1000   -0.0017
##    120        0.5855             nan     0.1000   -0.0015
##    140        0.5667             nan     0.1000   -0.0011
##    160        0.5493             nan     0.1000   -0.0014
##    180        0.5302             nan     0.1000   -0.0025
##    200        0.5133             nan     0.1000   -0.0013
##    220        0.4994             nan     0.1000   -0.0017
##    240        0.4872             nan     0.1000   -0.0015
##    250        0.4796             nan     0.1000   -0.0015
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1        1.2560             nan     0.1000    0.0382
##      2        1.1882             nan     0.1000    0.0328
##      3        1.1247             nan     0.1000    0.0294
##      4        1.0700             nan     0.1000    0.0239
##      5        1.0237             nan     0.1000    0.0193
##      6        0.9914             nan     0.1000    0.0133
##      7        0.9628             nan     0.1000    0.0120
##      8        0.9349             nan     0.1000    0.0090
##      9        0.9092             nan     0.1000    0.0067
##     10        0.8910             nan     0.1000    0.0062
##     20        0.7725             nan     0.1000    0.0020
##     40        0.6814             nan     0.1000   -0.0020
##     60        0.6337             nan     0.1000   -0.0020
##     80        0.5988             nan     0.1000   -0.0020
##    100        0.5675             nan     0.1000   -0.0012
##    120        0.5419             nan     0.1000   -0.0020
##    140        0.5210             nan     0.1000   -0.0012
##    160        0.5011             nan     0.1000   -0.0023
##    180        0.4834             nan     0.1000   -0.0023
##    200        0.4674             nan     0.1000   -0.0014
##    220        0.4517             nan     0.1000   -0.0019
##    240        0.4409             nan     0.1000   -0.0019
##    250        0.4344             nan     0.1000   -0.0018
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1        1.2715             nan     0.1000    0.0331
##      2        1.2172             nan     0.1000    0.0265
##      3        1.1717             nan     0.1000    0.0218
##      4        1.1340             nan     0.1000    0.0169
##      5        1.1041             nan     0.1000    0.0128
##      6        1.0732             nan     0.1000    0.0129
##      7        1.0504             nan     0.1000    0.0107
##      8        1.0272             nan     0.1000    0.0096
##      9        1.0078             nan     0.1000    0.0079
##     10        0.9909             nan     0.1000    0.0058
##     20        0.8935             nan     0.1000    0.0022
##     40        0.8028             nan     0.1000   -0.0001
##     60        0.7589             nan     0.1000   -0.0011
##     80        0.7387             nan     0.1000   -0.0003
##    100        0.7263             nan     0.1000   -0.0002
##    120        0.7215             nan     0.1000   -0.0007
##    140        0.7171             nan     0.1000   -0.0006
##    160        0.7135             nan     0.1000   -0.0014
##    180        0.7071             nan     0.1000   -0.0012
##    200        0.7025             nan     0.1000   -0.0007
##    220        0.6974             nan     0.1000   -0.0006
##    240        0.6949             nan     0.1000   -0.0010
##    250        0.6936             nan     0.1000   -0.0008
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1        1.2589             nan     0.1000    0.0361
##      2        1.1977             nan     0.1000    0.0276
##      3        1.1441             nan     0.1000    0.0265
##      4        1.1042             nan     0.1000    0.0196
##      5        1.0621             nan     0.1000    0.0167
##      6        1.0261             nan     0.1000    0.0141
##      7        1.0012             nan     0.1000    0.0116
##      8        0.9734             nan     0.1000    0.0109
##      9        0.9478             nan     0.1000    0.0095
##     10        0.9294             nan     0.1000    0.0086
##     20        0.8129             nan     0.1000    0.0034
##     40        0.7275             nan     0.1000   -0.0007
##     60        0.7015             nan     0.1000    0.0002
##     80        0.6844             nan     0.1000   -0.0010
##    100        0.6700             nan     0.1000   -0.0016
##    120        0.6543             nan     0.1000   -0.0010
##    140        0.6461             nan     0.1000   -0.0006
##    160        0.6361             nan     0.1000   -0.0009
##    180        0.6258             nan     0.1000   -0.0006
##    200        0.6156             nan     0.1000   -0.0023
##    220        0.6062             nan     0.1000   -0.0017
##    240        0.5951             nan     0.1000   -0.0011
##    250        0.5933             nan     0.1000   -0.0019
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1        1.2560             nan     0.1000    0.0380
##      2        1.1901             nan     0.1000    0.0320
##      3        1.1322             nan     0.1000    0.0268
##      4        1.0833             nan     0.1000    0.0224
##      5        1.0430             nan     0.1000    0.0179
##      6        1.0024             nan     0.1000    0.0188
##      7        0.9656             nan     0.1000    0.0154
##      8        0.9387             nan     0.1000    0.0111
##      9        0.9127             nan     0.1000    0.0103
##     10        0.8870             nan     0.1000    0.0101
##     20        0.7604             nan     0.1000    0.0014
##     40        0.6862             nan     0.1000   -0.0010
##     60        0.6558             nan     0.1000   -0.0011
##     80        0.6373             nan     0.1000   -0.0020
##    100        0.6167             nan     0.1000   -0.0028
##    120        0.5995             nan     0.1000   -0.0007
##    140        0.5854             nan     0.1000   -0.0014
##    160        0.5702             nan     0.1000   -0.0013
##    180        0.5597             nan     0.1000   -0.0024
##    200        0.5458             nan     0.1000   -0.0017
##    220        0.5299             nan     0.1000   -0.0007
##    240        0.5210             nan     0.1000   -0.0017
##    250        0.5158             nan     0.1000   -0.0021
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1        1.2540             nan     0.1000    0.0396
##      2        1.1751             nan     0.1000    0.0348
##      3        1.1172             nan     0.1000    0.0243
##      4        1.0668             nan     0.1000    0.0216
##      5        1.0185             nan     0.1000    0.0230
##      6        0.9814             nan     0.1000    0.0176
##      7        0.9460             nan     0.1000    0.0161
##      8        0.9120             nan     0.1000    0.0127
##      9        0.8872             nan     0.1000    0.0112
##     10        0.8636             nan     0.1000    0.0100
##     20        0.7438             nan     0.1000    0.0006
##     40        0.6630             nan     0.1000   -0.0007
##     60        0.6264             nan     0.1000   -0.0014
##     80        0.5998             nan     0.1000   -0.0014
##    100        0.5756             nan     0.1000   -0.0012
##    120        0.5593             nan     0.1000   -0.0016
##    140        0.5415             nan     0.1000   -0.0006
##    160        0.5199             nan     0.1000   -0.0020
##    180        0.5069             nan     0.1000   -0.0014
##    200        0.4916             nan     0.1000   -0.0020
##    220        0.4795             nan     0.1000   -0.0025
##    240        0.4676             nan     0.1000   -0.0019
##    250        0.4592             nan     0.1000   -0.0012
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1        1.2474             nan     0.1000    0.0402
##      2        1.1733             nan     0.1000    0.0343
##      3        1.1026             nan     0.1000    0.0290
##      4        1.0494             nan     0.1000    0.0228
##      5        1.0054             nan     0.1000    0.0192
##      6        0.9667             nan     0.1000    0.0177
##      7        0.9356             nan     0.1000    0.0141
##      8        0.9057             nan     0.1000    0.0125
##      9        0.8742             nan     0.1000    0.0129
##     10        0.8514             nan     0.1000    0.0093
##     20        0.7278             nan     0.1000    0.0014
##     40        0.6492             nan     0.1000   -0.0019
##     60        0.6081             nan     0.1000   -0.0021
##     80        0.5711             nan     0.1000   -0.0018
##    100        0.5428             nan     0.1000   -0.0033
##    120        0.5211             nan     0.1000   -0.0030
##    140        0.4982             nan     0.1000   -0.0013
##    160        0.4759             nan     0.1000   -0.0007
##    180        0.4587             nan     0.1000   -0.0015
##    200        0.4430             nan     0.1000   -0.0010
##    220        0.4284             nan     0.1000   -0.0008
##    240        0.4158             nan     0.1000   -0.0012
##    250        0.4072             nan     0.1000   -0.0029
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1        1.2614             nan     0.1000    0.0341
##      2        1.1926             nan     0.1000    0.0318
##      3        1.1367             nan     0.1000    0.0262
##      4        1.0951             nan     0.1000    0.0204
##      5        1.0568             nan     0.1000    0.0181
##      6        1.0211             nan     0.1000    0.0187
##      7        0.9907             nan     0.1000    0.0123
##      8        0.9627             nan     0.1000    0.0122
##      9        0.9379             nan     0.1000    0.0116
##     10        0.9161             nan     0.1000    0.0089
##     20        0.7971             nan     0.1000    0.0007
##     40        0.7338             nan     0.1000   -0.0030
##     60        0.7006             nan     0.1000   -0.0009
##     80        0.6799             nan     0.1000   -0.0011
##    100        0.6613             nan     0.1000   -0.0015
##    120        0.6434             nan     0.1000   -0.0003
##    140        0.6228             nan     0.1000   -0.0006
##    160        0.6101             nan     0.1000   -0.0006
##    180        0.5951             nan     0.1000   -0.0015
##    200        0.5828             nan     0.1000   -0.0009</code></pre>
<div class="sourceCode" id="cb115"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb115-1"><a href="gradient-boosting.html#cb115-1"></a>oj_mdl_gbm</span></code></pre></div>
<pre><code>## Stochastic Gradient Boosting 
## 
## 857 samples
##  17 predictor
##   2 classes: &#39;CH&#39;, &#39;MM&#39; 
## 
## No pre-processing
## Resampling: Cross-Validated (10 fold) 
## Summary of sample sizes: 772, 772, 771, 770, 771, 771, ... 
## Resampling results across tuning parameters:
## 
##   interaction.depth  n.trees  Accuracy   Kappa    
##   1                   50      0.8097901  0.5929519
##   1                  100      0.8215001  0.6195920
##   1                  150      0.8273414  0.6327182
##   1                  200      0.8249884  0.6276335
##   1                  250      0.8191879  0.6145884
##   2                   50      0.8261376  0.6300827
##   2                  100      0.8238530  0.6252885
##   2                  150      0.8179977  0.6127957
##   2                  200      0.8203236  0.6180661
##   2                  250      0.8133195  0.6047832
##   3                   50      0.8262060  0.6313198
##   3                  100      0.8261923  0.6328516
##   3                  150      0.8203242  0.6196244
##   3                  200      0.8285045  0.6365233
##   3                  250      0.8214730  0.6220406
##   4                   50      0.8109532  0.6005857
##   4                  100      0.8214733  0.6219633
##   4                  150      0.8202695  0.6209094
##   4                  200      0.8179576  0.6148779
##   4                  250      0.8086139  0.5957869
##   5                   50      0.8226632  0.6245795
##   5                  100      0.8109805  0.5990268
##   5                  150      0.8133609  0.6058617
##   5                  200      0.8063157  0.5905055
##   5                  250      0.8040172  0.5867695
## 
## Tuning parameter &#39;shrinkage&#39; was held constant at a value of 0.1
## 
## Tuning parameter &#39;n.minobsinnode&#39; was held constant at a value of 10
## Accuracy was used to select the optimal model using the largest value.
## The final values used for the model were n.trees = 200, interaction.depth =
##  3, shrinkage = 0.1 and n.minobsinnode = 10.</code></pre>
<p><code>train()</code> tuned <code>n.trees</code> ($M) and <code>interaction.depth</code>, holding <code>shrinkage = 0.1</code> (), and <code>n.minobsinnode = 10</code>. The optimal hyperparameter values were <code>n.trees = 200</code>, and <code>interaction.depth = 3</code>.</p>
<p>You can see from the tuning plot that accuracy is maximized at <span class="math inline">\(M=200\)</span> for tree depth of 3, but <span class="math inline">\(M=150\)</span> with tree depth of 1 worked nearly as well.</p>
<div class="sourceCode" id="cb117"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb117-1"><a href="gradient-boosting.html#cb117-1"></a><span class="kw">plot</span>(oj_mdl_gbm)</span></code></pre></div>
<p><img src="data-sci_files/figure-html/unnamed-chunk-60-1.png" width="672" /></p>
<p>Let’s see how the model performed on the holdout set.</p>
<div class="sourceCode" id="cb118"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb118-1"><a href="gradient-boosting.html#cb118-1"></a>oj_preds_gbm &lt;-<span class="st"> </span><span class="kw">bind_cols</span>(</span>
<span id="cb118-2"><a href="gradient-boosting.html#cb118-2"></a>   <span class="kw">predict</span>(oj_mdl_gbm, <span class="dt">newdata =</span> oj_test, <span class="dt">type =</span> <span class="st">&quot;prob&quot;</span>),</span>
<span id="cb118-3"><a href="gradient-boosting.html#cb118-3"></a>   <span class="dt">Predicted =</span> <span class="kw">predict</span>(oj_mdl_gbm, <span class="dt">newdata =</span> oj_test, <span class="dt">type =</span> <span class="st">&quot;raw&quot;</span>),</span>
<span id="cb118-4"><a href="gradient-boosting.html#cb118-4"></a>   <span class="dt">Actual =</span> oj_test<span class="op">$</span>Purchase</span>
<span id="cb118-5"><a href="gradient-boosting.html#cb118-5"></a>)</span>
<span id="cb118-6"><a href="gradient-boosting.html#cb118-6"></a></span>
<span id="cb118-7"><a href="gradient-boosting.html#cb118-7"></a>oj_cm_gbm &lt;-<span class="st"> </span><span class="kw">confusionMatrix</span>(oj_preds_gbm<span class="op">$</span>Predicted, <span class="dt">reference =</span> oj_preds_gbm<span class="op">$</span>Actual)</span>
<span id="cb118-8"><a href="gradient-boosting.html#cb118-8"></a>oj_cm_gbm</span></code></pre></div>
<pre><code>## Confusion Matrix and Statistics
## 
##           Reference
## Prediction  CH  MM
##         CH 114  16
##         MM  16  67
##                                           
##                Accuracy : 0.8498          
##                  95% CI : (0.7946, 0.8949)
##     No Information Rate : 0.6103          
##     P-Value [Acc &gt; NIR] : 1.778e-14       
##                                           
##                   Kappa : 0.6842          
##                                           
##  Mcnemar&#39;s Test P-Value : 1               
##                                           
##             Sensitivity : 0.8769          
##             Specificity : 0.8072          
##          Pos Pred Value : 0.8769          
##          Neg Pred Value : 0.8072          
##              Prevalence : 0.6103          
##          Detection Rate : 0.5352          
##    Detection Prevalence : 0.6103          
##       Balanced Accuracy : 0.8421          
##                                           
##        &#39;Positive&#39; Class : CH              
## </code></pre>
<p>GBM improved upon boosting and random forest with accuracy of 0.8498.</p>
<div class="sourceCode" id="cb120"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb120-1"><a href="gradient-boosting.html#cb120-1"></a>mdl_auc &lt;-<span class="st"> </span>Metrics<span class="op">::</span><span class="kw">auc</span>(<span class="dt">actual =</span> oj_preds_gbm<span class="op">$</span>Actual <span class="op">==</span><span class="st"> &quot;CH&quot;</span>, oj_preds_bag<span class="op">$</span>CH)</span>
<span id="cb120-2"><a href="gradient-boosting.html#cb120-2"></a>yardstick<span class="op">::</span><span class="kw">roc_curve</span>(oj_preds_gbm, Actual, CH) <span class="op">%&gt;%</span></span>
<span id="cb120-3"><a href="gradient-boosting.html#cb120-3"></a><span class="st">  </span><span class="kw">autoplot</span>() <span class="op">+</span></span>
<span id="cb120-4"><a href="gradient-boosting.html#cb120-4"></a><span class="st">  </span><span class="kw">labs</span>(</span>
<span id="cb120-5"><a href="gradient-boosting.html#cb120-5"></a>    <span class="dt">title =</span> <span class="st">&quot;OJ GBM ROC Curve&quot;</span>,</span>
<span id="cb120-6"><a href="gradient-boosting.html#cb120-6"></a>    <span class="dt">subtitle =</span> <span class="kw">paste0</span>(<span class="st">&quot;AUC = &quot;</span>, <span class="kw">round</span>(mdl_auc, <span class="dv">4</span>))</span>
<span id="cb120-7"><a href="gradient-boosting.html#cb120-7"></a>  )</span></code></pre></div>
<p><img src="data-sci_files/figure-html/unnamed-chunk-62-1.png" width="672" /></p>
<div class="sourceCode" id="cb121"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb121-1"><a href="gradient-boosting.html#cb121-1"></a>yardstick<span class="op">::</span><span class="kw">gain_curve</span>(oj_preds_gbm, Actual, CH) <span class="op">%&gt;%</span></span>
<span id="cb121-2"><a href="gradient-boosting.html#cb121-2"></a><span class="st">  </span><span class="kw">autoplot</span>() <span class="op">+</span></span>
<span id="cb121-3"><a href="gradient-boosting.html#cb121-3"></a><span class="st">  </span><span class="kw">labs</span>(<span class="dt">title =</span> <span class="st">&quot;OJ GBM Gain Curve&quot;</span>)</span></code></pre></div>
<p><img src="data-sci_files/figure-html/unnamed-chunk-62-2.png" width="672" /></p>
<div class="sourceCode" id="cb122"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb122-1"><a href="gradient-boosting.html#cb122-1"></a><span class="kw">plot</span>(<span class="kw">varImp</span>(oj_mdl_bag), <span class="dt">main=</span><span class="st">&quot;Variable Importance with Bagging&quot;</span>)</span></code></pre></div>
<p><img src="data-sci_files/figure-html/unnamed-chunk-62-3.png" width="672" /></p>
<div class="sourceCode" id="cb123"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb123-1"><a href="gradient-boosting.html#cb123-1"></a>scoreboard &lt;-<span class="st"> </span><span class="kw">rbind</span>(</span>
<span id="cb123-2"><a href="gradient-boosting.html#cb123-2"></a>   scoreboard,</span>
<span id="cb123-3"><a href="gradient-boosting.html#cb123-3"></a>   <span class="kw">data.frame</span>(<span class="dt">model =</span> <span class="st">&quot;GBM&quot;</span>, <span class="dt">Acc =</span> <span class="kw">round</span>(oj_cm_gbm<span class="op">$</span>overall[<span class="st">&quot;Accuracy&quot;</span>], <span class="dv">5</span>))</span>
<span id="cb123-4"><a href="gradient-boosting.html#cb123-4"></a>)</span>
<span id="cb123-5"><a href="gradient-boosting.html#cb123-5"></a>scoreboard <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">arrange</span>(<span class="kw">desc</span>(Acc))</span></code></pre></div>
<pre><code>##                      model     Acc
## Accuracy      Manual Class 0.85915
## Accuracy4              GBM 0.84977
## Accuracy1 Caret w/tuneGrid 0.84507
## Accuracy2          Bagging 0.84507
## Accuracy3    Random Forest 0.82629</code></pre>
</div>
<div id="gradient-boosting-regression-example" class="section level4">
<h4><span class="header-section-number">9.5.0.2</span> Gradient Boosting Regression Example</h4>
<p>I’ll predict <code>Sales</code> from the <code>Carseats</code> data set again, this time using the bagging method by specifying <code>method = "gbm"</code></p>
<div class="sourceCode" id="cb125"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb125-1"><a href="gradient-boosting.html#cb125-1"></a><span class="kw">set.seed</span>(<span class="dv">1234</span>)</span>
<span id="cb125-2"><a href="gradient-boosting.html#cb125-2"></a>garbage &lt;-<span class="st"> </span><span class="kw">capture.output</span>(</span>
<span id="cb125-3"><a href="gradient-boosting.html#cb125-3"></a>cs_mdl_gbm &lt;-<span class="st"> </span><span class="kw">train</span>(</span>
<span id="cb125-4"><a href="gradient-boosting.html#cb125-4"></a>   Sales <span class="op">~</span><span class="st"> </span>., </span>
<span id="cb125-5"><a href="gradient-boosting.html#cb125-5"></a>   <span class="dt">data =</span> cs_train, </span>
<span id="cb125-6"><a href="gradient-boosting.html#cb125-6"></a>   <span class="dt">method =</span> <span class="st">&quot;gbm&quot;</span>,</span>
<span id="cb125-7"><a href="gradient-boosting.html#cb125-7"></a>   <span class="dt">tuneLength =</span> <span class="dv">5</span>,</span>
<span id="cb125-8"><a href="gradient-boosting.html#cb125-8"></a>   <span class="dt">trControl =</span> cs_trControl</span>
<span id="cb125-9"><a href="gradient-boosting.html#cb125-9"></a>))</span>
<span id="cb125-10"><a href="gradient-boosting.html#cb125-10"></a>cs_mdl_gbm</span></code></pre></div>
<pre><code>## Stochastic Gradient Boosting 
## 
## 321 samples
##  10 predictor
## 
## No pre-processing
## Resampling: Cross-Validated (10 fold) 
## Summary of sample sizes: 289, 289, 289, 289, 289, 289, ... 
## Resampling results across tuning parameters:
## 
##   interaction.depth  n.trees  RMSE      Rsquared   MAE      
##   1                   50      1.842468  0.6718370  1.4969754
##   1                  100      1.516967  0.7823612  1.2407807
##   1                  150      1.309295  0.8277888  1.0639501
##   1                  200      1.216079  0.8429002  0.9866820
##   1                  250      1.161540  0.8488463  0.9384418
##   2                   50      1.527454  0.7801995  1.2207991
##   2                  100      1.240990  0.8381156  1.0063802
##   2                  150      1.187603  0.8415216  0.9616681
##   2                  200      1.174303  0.8425011  0.9527720
##   2                  250      1.172116  0.8403490  0.9500902
##   3                   50      1.390969  0.8071393  1.1316570
##   3                  100      1.227525  0.8321632  0.9888203
##   3                  150      1.201264  0.8345775  0.9694065
##   3                  200      1.214462  0.8282833  0.9761625
##   3                  250      1.232145  0.8221405  0.9882254
##   4                   50      1.341893  0.8128778  1.0949502
##   4                  100      1.252282  0.8230712  0.9907410
##   4                  150      1.243045  0.8229433  0.9860813
##   4                  200      1.258093  0.8162033  0.9947218
##   4                  250      1.271058  0.8114156  1.0144873
##   5                   50      1.318251  0.8128033  1.0552929
##   5                  100      1.250053  0.8226441  0.9958713
##   5                  150      1.248402  0.8214824  0.9888330
##   5                  200      1.263445  0.8158033  1.0106345
##   5                  250      1.273024  0.8124672  1.0213099
## 
## Tuning parameter &#39;shrinkage&#39; was held constant at a value of 0.1
## 
## Tuning parameter &#39;n.minobsinnode&#39; was held constant at a value of 10
## RMSE was used to select the optimal model using the smallest value.
## The final values used for the model were n.trees = 250, interaction.depth =
##  1, shrinkage = 0.1 and n.minobsinnode = 10.</code></pre>
<p>The optimal tuning parameters were at <span class="math inline">\(M = 250\)</span> and <code>interation.depth = 1</code>.</p>
<div class="sourceCode" id="cb127"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb127-1"><a href="gradient-boosting.html#cb127-1"></a><span class="kw">plot</span>(cs_mdl_gbm)</span></code></pre></div>
<p><img src="data-sci_files/figure-html/unnamed-chunk-64-1.png" width="672" /></p>
<p>Here is the holdout set peformance.</p>
<div class="sourceCode" id="cb128"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb128-1"><a href="gradient-boosting.html#cb128-1"></a>cs_preds_gbm &lt;-<span class="st"> </span><span class="kw">bind_cols</span>(</span>
<span id="cb128-2"><a href="gradient-boosting.html#cb128-2"></a>   <span class="dt">Predicted =</span> <span class="kw">predict</span>(cs_mdl_gbm, <span class="dt">newdata =</span> cs_test),</span>
<span id="cb128-3"><a href="gradient-boosting.html#cb128-3"></a>   <span class="dt">Actual =</span> cs_test<span class="op">$</span>Sales</span>
<span id="cb128-4"><a href="gradient-boosting.html#cb128-4"></a>)</span>
<span id="cb128-5"><a href="gradient-boosting.html#cb128-5"></a></span>
<span id="cb128-6"><a href="gradient-boosting.html#cb128-6"></a><span class="co"># Model over-predicts at low end of Sales and under-predicts at high end</span></span>
<span id="cb128-7"><a href="gradient-boosting.html#cb128-7"></a>cs_preds_gbm <span class="op">%&gt;%</span></span>
<span id="cb128-8"><a href="gradient-boosting.html#cb128-8"></a><span class="st">   </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> Actual, <span class="dt">y =</span> Predicted)) <span class="op">+</span></span>
<span id="cb128-9"><a href="gradient-boosting.html#cb128-9"></a><span class="st">   </span><span class="kw">geom_point</span>(<span class="dt">alpha =</span> <span class="fl">0.6</span>, <span class="dt">color =</span> <span class="st">&quot;cadetblue&quot;</span>) <span class="op">+</span></span>
<span id="cb128-10"><a href="gradient-boosting.html#cb128-10"></a><span class="st">   </span><span class="kw">geom_smooth</span>(<span class="dt">method =</span> <span class="st">&quot;loess&quot;</span>, <span class="dt">formula =</span> <span class="st">&quot;y ~ x&quot;</span>) <span class="op">+</span></span>
<span id="cb128-11"><a href="gradient-boosting.html#cb128-11"></a><span class="st">   </span><span class="kw">geom_abline</span>(<span class="dt">intercept =</span> <span class="dv">0</span>, <span class="dt">slope =</span> <span class="dv">1</span>, <span class="dt">linetype =</span> <span class="dv">2</span>) <span class="op">+</span></span>
<span id="cb128-12"><a href="gradient-boosting.html#cb128-12"></a><span class="st">   </span><span class="kw">labs</span>(<span class="dt">title =</span> <span class="st">&quot;Carseats GBM, Predicted vs Actual&quot;</span>)</span></code></pre></div>
<p><img src="data-sci_files/figure-html/unnamed-chunk-65-1.png" width="672" /></p>
<p>The RMSE is 1.438 - the best of the bunch.</p>
<div class="sourceCode" id="cb129"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb129-1"><a href="gradient-boosting.html#cb129-1"></a><span class="co"># RMSE of 1.7184 is better than bagging&#39;s 1.9185.</span></span>
<span id="cb129-2"><a href="gradient-boosting.html#cb129-2"></a>cs_rmse_gbm &lt;-<span class="st"> </span><span class="kw">RMSE</span>(<span class="dt">pred =</span> cs_preds_gbm<span class="op">$</span>Predicted, <span class="dt">obs =</span> cs_preds_gbm<span class="op">$</span>Actual)</span>
<span id="cb129-3"><a href="gradient-boosting.html#cb129-3"></a></span>
<span id="cb129-4"><a href="gradient-boosting.html#cb129-4"></a>scoreboard_r &lt;-<span class="st"> </span><span class="kw">rbind</span>(</span>
<span id="cb129-5"><a href="gradient-boosting.html#cb129-5"></a>   scoreboard_r,</span>
<span id="cb129-6"><a href="gradient-boosting.html#cb129-6"></a>   <span class="kw">data.frame</span>(<span class="dt">model =</span> <span class="st">&quot;GBM&quot;</span>, <span class="dt">RMSE =</span> <span class="kw">round</span>(cs_rmse_gbm, <span class="dv">5</span>))</span>
<span id="cb129-7"><a href="gradient-boosting.html#cb129-7"></a>)</span>
<span id="cb129-8"><a href="gradient-boosting.html#cb129-8"></a>scoreboard_r <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">arrange</span>(RMSE)</span></code></pre></div>
<pre><code>##              model    RMSE
## 1              GBM 1.43806
## 2    Random Forest 1.71836
## 3          Bagging 1.91847
## 4 Caret w/tuneGrid 2.29833
## 5     Manual ANOVA 2.36320</code></pre>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="random-forests.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="summary.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="assets/gitbook-2.6.7/js/app.min.js"></script>
<script src="assets/gitbook-2.6.7/js/lunr.js"></script>
<script src="assets/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="assets/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="assets/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="assets/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="assets/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="assets/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="assets/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["data-sci.pdf", "data-sci.epub"],
"toc": {
"collapse": "subsection"
},
"toolbar": {
"position": "static"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
