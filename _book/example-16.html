<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>13.4 Example | My Data Science Notes</title>
  <meta name="description" content="This is a compendium of notes from classes, tutorials, etc. that I reference from time to time." />
  <meta name="generator" content="bookdown 0.18 and GitBook 2.6.7" />

  <meta property="og:title" content="13.4 Example | My Data Science Notes" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="This is a compendium of notes from classes, tutorials, etc. that I reference from time to time." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="13.4 Example | My Data Science Notes" />
  
  <meta name="twitter:description" content="This is a compendium of notes from classes, tutorials, etc. that I reference from time to time." />
  

<meta name="author" content="Michael Foley" />


<meta name="date" content="2020-04-28" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="support-vector-machines-1.html"/>
<link rel="next" href="using-caret.html"/>
<script src="assets/jquery-2.2.3/jquery.min.js"></script>
<link href="assets/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="assets/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="assets/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="assets/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="assets/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="assets/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="assets/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />











<style type="text/css">
code.sourceCode > span { display: inline-block; line-height: 1.25; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">My Data Science Notes</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Intro</a></li>
<li class="chapter" data-level="1" data-path="probability.html"><a href="probability.html"><i class="fa fa-check"></i><b>1</b> Probability</a><ul>
<li class="chapter" data-level="1.1" data-path="principles.html"><a href="principles.html"><i class="fa fa-check"></i><b>1.1</b> Principles</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="disc-dist.html"><a href="disc-dist.html"><i class="fa fa-check"></i><b>2</b> Discrete Distributions</a><ul>
<li class="chapter" data-level="2.1" data-path="bernoulli.html"><a href="bernoulli.html"><i class="fa fa-check"></i><b>2.1</b> Bernoulli</a></li>
<li class="chapter" data-level="2.2" data-path="binomial.html"><a href="binomial.html"><i class="fa fa-check"></i><b>2.2</b> Binomial</a></li>
<li class="chapter" data-level="2.3" data-path="poission.html"><a href="poission.html"><i class="fa fa-check"></i><b>2.3</b> Poission</a></li>
<li class="chapter" data-level="2.4" data-path="multinomial.html"><a href="multinomial.html"><i class="fa fa-check"></i><b>2.4</b> Multinomial</a></li>
<li class="chapter" data-level="2.5" data-path="negative-binomial.html"><a href="negative-binomial.html"><i class="fa fa-check"></i><b>2.5</b> Negative-Binomial</a></li>
<li class="chapter" data-level="2.6" data-path="geometric.html"><a href="geometric.html"><i class="fa fa-check"></i><b>2.6</b> Geometric</a></li>
<li class="chapter" data-level="2.7" data-path="hypergeometric.html"><a href="hypergeometric.html"><i class="fa fa-check"></i><b>2.7</b> Hypergeometric</a></li>
<li class="chapter" data-level="2.8" data-path="gamma.html"><a href="gamma.html"><i class="fa fa-check"></i><b>2.8</b> Gamma</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="cont-dist.html"><a href="cont-dist.html"><i class="fa fa-check"></i><b>3</b> Continuous Distributions</a><ul>
<li class="chapter" data-level="3.1" data-path="normal.html"><a href="normal.html"><i class="fa fa-check"></i><b>3.1</b> Normal</a><ul>
<li class="chapter" data-level="3.1.1" data-path="normal.html"><a href="normal.html#example-2"><i class="fa fa-check"></i><b>3.1.1</b> Example</a></li>
<li class="chapter" data-level="3.1.2" data-path="normal.html"><a href="normal.html#example-3"><i class="fa fa-check"></i><b>3.1.2</b> Example</a></li>
<li class="chapter" data-level="3.1.3" data-path="normal.html"><a href="normal.html#example-4"><i class="fa fa-check"></i><b>3.1.3</b> Example</a></li>
<li class="chapter" data-level="3.1.4" data-path="normal.html"><a href="normal.html#normal-approximation-to-binomial"><i class="fa fa-check"></i><b>3.1.4</b> Normal Approximation to Binomial</a></li>
<li class="chapter" data-level="3.1.5" data-path="normal.html"><a href="normal.html#example-5"><i class="fa fa-check"></i><b>3.1.5</b> Example</a></li>
<li class="chapter" data-level="3.1.6" data-path="normal.html"><a href="normal.html#example-6"><i class="fa fa-check"></i><b>3.1.6</b> Example</a></li>
<li class="chapter" data-level="3.1.7" data-path="normal.html"><a href="normal.html#from-sample-to-population"><i class="fa fa-check"></i><b>3.1.7</b> From Sample to Population</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="join-distributions.html"><a href="join-distributions.html"><i class="fa fa-check"></i><b>3.2</b> Join Distributions</a></li>
<li class="chapter" data-level="3.3" data-path="likelihood.html"><a href="likelihood.html"><i class="fa fa-check"></i><b>3.3</b> Likelihood</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="discrete-analysis.html"><a href="discrete-analysis.html"><i class="fa fa-check"></i><b>4</b> Categorical Analysis - Nonmodel</a><ul>
<li class="chapter" data-level="4.1" data-path="chi-square-test.html"><a href="chi-square-test.html"><i class="fa fa-check"></i><b>4.1</b> Chi-Square Test</a></li>
<li class="chapter" data-level="4.2" data-path="one-way-tables.html"><a href="one-way-tables.html"><i class="fa fa-check"></i><b>4.2</b> One-Way Tables</a><ul>
<li class="chapter" data-level="4.2.1" data-path="one-way-tables.html"><a href="one-way-tables.html#chi-square-goodness-of-fit-test"><i class="fa fa-check"></i><b>4.2.1</b> Chi-Square Goodness-of-Fit Test</a></li>
<li class="chapter" data-level="4.2.2" data-path="one-way-tables.html"><a href="one-way-tables.html#proportion-test"><i class="fa fa-check"></i><b>4.2.2</b> Proportion Test</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="two-way-tables.html"><a href="two-way-tables.html"><i class="fa fa-check"></i><b>4.3</b> Two-Way Tables</a><ul>
<li class="chapter" data-level="4.3.1" data-path="two-way-tables.html"><a href="two-way-tables.html#chi-square-independence-test"><i class="fa fa-check"></i><b>4.3.1</b> Chi-Square Independence Test</a></li>
<li class="chapter" data-level="4.3.2" data-path="two-way-tables.html"><a href="two-way-tables.html#residuals-analysis"><i class="fa fa-check"></i><b>4.3.2</b> Residuals Analysis</a></li>
<li class="chapter" data-level="4.3.3" data-path="two-way-tables.html"><a href="two-way-tables.html#difference-in-proportions"><i class="fa fa-check"></i><b>4.3.3</b> Difference in Proportions</a></li>
<li class="chapter" data-level="4.3.4" data-path="two-way-tables.html"><a href="two-way-tables.html#relative-risk"><i class="fa fa-check"></i><b>4.3.4</b> Relative Risk</a></li>
<li class="chapter" data-level="4.3.5" data-path="two-way-tables.html"><a href="two-way-tables.html#odds-ratio"><i class="fa fa-check"></i><b>4.3.5</b> Odds Ratio</a></li>
<li class="chapter" data-level="4.3.6" data-path="two-way-tables.html"><a href="two-way-tables.html#partitioning-chi-square"><i class="fa fa-check"></i><b>4.3.6</b> Partitioning Chi-Square</a></li>
<li class="chapter" data-level="4.3.7" data-path="two-way-tables.html"><a href="two-way-tables.html#correlation"><i class="fa fa-check"></i><b>4.3.7</b> Correlation</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="k-way-tables.html"><a href="k-way-tables.html"><i class="fa fa-check"></i><b>4.4</b> K-Way Tables</a><ul>
<li class="chapter" data-level="4.4.1" data-path="k-way-tables.html"><a href="k-way-tables.html#odds-ratio-1"><i class="fa fa-check"></i><b>4.4.1</b> Odds Ratio</a></li>
<li class="chapter" data-level="4.4.2" data-path="k-way-tables.html"><a href="k-way-tables.html#chi-square-independence-test-1"><i class="fa fa-check"></i><b>4.4.2</b> Chi-Square Independence Test</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="continuous-analysis.html"><a href="continuous-analysis.html"><i class="fa fa-check"></i><b>5</b> Continuous Variable Analysis</a><ul>
<li class="chapter" data-level="5.0.1" data-path="continuous-analysis.html"><a href="continuous-analysis.html#correlation-1"><i class="fa fa-check"></i><b>5.0.1</b> Correlation</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="supervised-machine-learning.html"><a href="supervised-machine-learning.html"><i class="fa fa-check"></i>Supervised Machine Learning</a></li>
<li class="chapter" data-level="6" data-path="ordinary-least-squares.html"><a href="ordinary-least-squares.html"><i class="fa fa-check"></i><b>6</b> Ordinary Least Squares</a><ul>
<li class="chapter" data-level="6.1" data-path="linear-regression-model.html"><a href="linear-regression-model.html"><i class="fa fa-check"></i><b>6.1</b> Linear Regression Model</a></li>
<li class="chapter" data-level="6.2" data-path="parameter-estimation.html"><a href="parameter-estimation.html"><i class="fa fa-check"></i><b>6.2</b> Parameter Estimation</a></li>
<li class="chapter" data-level="6.3" data-path="model-assumptions.html"><a href="model-assumptions.html"><i class="fa fa-check"></i><b>6.3</b> Model Assumptions</a><ul>
<li class="chapter" data-level="6.3.1" data-path="model-assumptions.html"><a href="model-assumptions.html#linearity"><i class="fa fa-check"></i><b>6.3.1</b> Linearity</a></li>
<li class="chapter" data-level="6.3.2" data-path="model-assumptions.html"><a href="model-assumptions.html#multicollinearity"><i class="fa fa-check"></i><b>6.3.2</b> Multicollinearity</a></li>
<li class="chapter" data-level="6.3.3" data-path="model-assumptions.html"><a href="model-assumptions.html#normality"><i class="fa fa-check"></i><b>6.3.3</b> Normality</a></li>
<li class="chapter" data-level="6.3.4" data-path="model-assumptions.html"><a href="model-assumptions.html#equal-variances"><i class="fa fa-check"></i><b>6.3.4</b> Equal Variances</a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="prediction.html"><a href="prediction.html"><i class="fa fa-check"></i><b>6.4</b> Prediction</a></li>
<li class="chapter" data-level="6.5" data-path="inference.html"><a href="inference.html"><i class="fa fa-check"></i><b>6.5</b> Inference</a><ul>
<li class="chapter" data-level="6.5.1" data-path="inference.html"><a href="inference.html#t-test"><i class="fa fa-check"></i><b>6.5.1</b> <em>t</em>-Test</a></li>
<li class="chapter" data-level="6.5.2" data-path="inference.html"><a href="inference.html#f-test"><i class="fa fa-check"></i><b>6.5.2</b> <em>F</em>-Test</a></li>
</ul></li>
<li class="chapter" data-level="6.6" data-path="interpretation.html"><a href="interpretation.html"><i class="fa fa-check"></i><b>6.6</b> Interpretation</a></li>
<li class="chapter" data-level="6.7" data-path="model-validation.html"><a href="model-validation.html"><i class="fa fa-check"></i><b>6.7</b> Model Validation</a><ul>
<li class="chapter" data-level="6.7.1" data-path="model-validation.html"><a href="model-validation.html#accuracy-metrics"><i class="fa fa-check"></i><b>6.7.1</b> Accuracy Metrics</a></li>
<li class="chapter" data-level="6.7.2" data-path="model-validation.html"><a href="model-validation.html#cross-validation"><i class="fa fa-check"></i><b>6.7.2</b> Cross-Validation</a></li>
<li class="chapter" data-level="6.7.3" data-path="model-validation.html"><a href="model-validation.html#gain-curve"><i class="fa fa-check"></i><b>6.7.3</b> Gain Curve</a></li>
</ul></li>
<li class="chapter" data-level="6.8" data-path="reference.html"><a href="reference.html"><i class="fa fa-check"></i><b>6.8</b> Reference</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="generalized-linear-models.html"><a href="generalized-linear-models.html"><i class="fa fa-check"></i><b>7</b> Generalized Linear Models</a><ul>
<li class="chapter" data-level="7.1" data-path="logistic-regression.html"><a href="logistic-regression.html"><i class="fa fa-check"></i><b>7.1</b> Logistic Regression</a></li>
<li class="chapter" data-level="7.2" data-path="multinomial-logistic-regression.html"><a href="multinomial-logistic-regression.html"><i class="fa fa-check"></i><b>7.2</b> Multinomial Logistic Regression</a></li>
<li class="chapter" data-level="7.3" data-path="ordinal-logistic-regression.html"><a href="ordinal-logistic-regression.html"><i class="fa fa-check"></i><b>7.3</b> Ordinal Logistic Regression</a><ul>
<li class="chapter" data-level="7.3.1" data-path="ordinal-logistic-regression.html"><a href="ordinal-logistic-regression.html#assumptions"><i class="fa fa-check"></i><b>7.3.1</b> Assumptions</a></li>
<li class="chapter" data-level="7.3.2" data-path="ordinal-logistic-regression.html"><a href="ordinal-logistic-regression.html#modeling"><i class="fa fa-check"></i><b>7.3.2</b> Modeling</a></li>
<li class="chapter" data-level="7.3.3" data-path="ordinal-logistic-regression.html"><a href="ordinal-logistic-regression.html#case-study"><i class="fa fa-check"></i><b>7.3.3</b> Case Study</a></li>
</ul></li>
<li class="chapter" data-level="7.4" data-path="poisson-regression.html"><a href="poisson-regression.html"><i class="fa fa-check"></i><b>7.4</b> Poisson Regression</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="linear-discriminant-analysis.html"><a href="linear-discriminant-analysis.html"><i class="fa fa-check"></i><b>8</b> Linear Discriminant Analysis</a></li>
<li class="chapter" data-level="9" data-path="classification.html"><a href="classification.html"><i class="fa fa-check"></i><b>9</b> Classification</a></li>
<li class="chapter" data-level="10" data-path="regularization.html"><a href="regularization.html"><i class="fa fa-check"></i><b>10</b> Regularization</a></li>
<li class="chapter" data-level="11" data-path="decision-trees.html"><a href="decision-trees.html"><i class="fa fa-check"></i><b>11</b> Decision Trees</a><ul>
<li class="chapter" data-level="11.1" data-path="classification-tree.html"><a href="classification-tree.html"><i class="fa fa-check"></i><b>11.1</b> Classification Tree</a><ul>
<li class="chapter" data-level="11.1.1" data-path="classification-tree.html"><a href="classification-tree.html#confusion-matrix"><i class="fa fa-check"></i><b>11.1.1</b> Confusion Matrix</a></li>
<li class="chapter" data-level="11.1.2" data-path="classification-tree.html"><a href="classification-tree.html#roc-curve"><i class="fa fa-check"></i><b>11.1.2</b> ROC Curve</a></li>
<li class="chapter" data-level="11.1.3" data-path="classification-tree.html"><a href="classification-tree.html#caret-approach"><i class="fa fa-check"></i><b>11.1.3</b> Caret Approach</a></li>
</ul></li>
<li class="chapter" data-level="11.2" data-path="regression-trees.html"><a href="regression-trees.html"><i class="fa fa-check"></i><b>11.2</b> Regression Trees</a><ul>
<li class="chapter" data-level="11.2.1" data-path="regression-trees.html"><a href="regression-trees.html#caret-approach-1"><i class="fa fa-check"></i><b>11.2.1</b> Caret Approach</a></li>
</ul></li>
<li class="chapter" data-level="11.3" data-path="bagging.html"><a href="bagging.html"><i class="fa fa-check"></i><b>11.3</b> Bagging</a></li>
<li class="chapter" data-level="11.4" data-path="random-forests.html"><a href="random-forests.html"><i class="fa fa-check"></i><b>11.4</b> Random Forests</a></li>
<li class="chapter" data-level="11.5" data-path="gradient-boosting.html"><a href="gradient-boosting.html"><i class="fa fa-check"></i><b>11.5</b> Gradient Boosting</a></li>
<li class="chapter" data-level="11.6" data-path="summary.html"><a href="summary.html"><i class="fa fa-check"></i><b>11.6</b> Summary</a></li>
<li class="chapter" data-level="11.7" data-path="reference-1.html"><a href="reference-1.html"><i class="fa fa-check"></i><b>11.7</b> Reference</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="non-linear-models.html"><a href="non-linear-models.html"><i class="fa fa-check"></i><b>12</b> Non-linear Models</a><ul>
<li class="chapter" data-level="12.1" data-path="splines.html"><a href="splines.html"><i class="fa fa-check"></i><b>12.1</b> Splines</a></li>
<li class="chapter" data-level="12.2" data-path="mars.html"><a href="mars.html"><i class="fa fa-check"></i><b>12.2</b> MARS</a></li>
<li class="chapter" data-level="12.3" data-path="gam.html"><a href="gam.html"><i class="fa fa-check"></i><b>12.3</b> GAM</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="support-vector-machines.html"><a href="support-vector-machines.html"><i class="fa fa-check"></i><b>13</b> Support Vector Machines</a><ul>
<li class="chapter" data-level="13.1" data-path="maximal-margin-classifier.html"><a href="maximal-margin-classifier.html"><i class="fa fa-check"></i><b>13.1</b> Maximal Margin Classifier</a></li>
<li class="chapter" data-level="13.2" data-path="support-vector-classifier.html"><a href="support-vector-classifier.html"><i class="fa fa-check"></i><b>13.2</b> Support Vector Classifier</a></li>
<li class="chapter" data-level="13.3" data-path="support-vector-machines-1.html"><a href="support-vector-machines-1.html"><i class="fa fa-check"></i><b>13.3</b> Support Vector Machines</a></li>
<li class="chapter" data-level="13.4" data-path="example-16.html"><a href="example-16.html"><i class="fa fa-check"></i><b>13.4</b> Example</a></li>
<li class="chapter" data-level="13.5" data-path="using-caret.html"><a href="using-caret.html"><i class="fa fa-check"></i><b>13.5</b> Using Caret</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="principal-components-analysis.html"><a href="principal-components-analysis.html"><i class="fa fa-check"></i><b>14</b> Principal Components Analysis</a></li>
<li class="chapter" data-level="15" data-path="clustering.html"><a href="clustering.html"><i class="fa fa-check"></i><b>15</b> Clustering</a></li>
<li class="chapter" data-level="16" data-path="text-mining.html"><a href="text-mining.html"><i class="fa fa-check"></i><b>16</b> Text Mining</a></li>
<li class="chapter" data-level="17" data-path="survival-analysis.html"><a href="survival-analysis.html"><i class="fa fa-check"></i><b>17</b> Survival Analysis</a></li>
<li class="chapter" data-level="" data-path="appendix.html"><a href="appendix.html"><i class="fa fa-check"></i>Appendix</a><ul>
<li class="chapter" data-level="" data-path="publishing-to-bookdown.html"><a href="publishing-to-bookdown.html"><i class="fa fa-check"></i>Publishing to BookDown</a></li>
<li class="chapter" data-level="" data-path="shiny-apps.html"><a href="shiny-apps.html"><i class="fa fa-check"></i>Shiny Apps</a></li>
<li class="chapter" data-level="" data-path="packages.html"><a href="packages.html"><i class="fa fa-check"></i>Packages</a><ul>
<li class="chapter" data-level="" data-path="packages.html"><a href="packages.html#create-a-package"><i class="fa fa-check"></i>Create a package</a></li>
<li class="chapter" data-level="17.0.1" data-path="packages.html"><a href="packages.html#document-functions-with-roxygen"><i class="fa fa-check"></i><b>17.0.1</b> Document Functions with roxygen</a></li>
<li class="chapter" data-level="" data-path="packages.html"><a href="packages.html#create-data"><i class="fa fa-check"></i>Create Data</a></li>
<li class="chapter" data-level="" data-path="packages.html"><a href="packages.html#create-vignette"><i class="fa fa-check"></i>Create Vignette</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">My Data Science Notes</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="example-16" class="section level2">
<h2><span class="header-section-number">13.4</span> Example</h2>
<p>Here is a data set of two classes <span class="math inline">\(y \in [-1, 1]\)</span> described by two features <span class="math inline">\(X1\)</span> and <span class="math inline">\(X2\)</span>.</p>
<div class="sourceCode" id="cb720"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb720-1"><a href="example-16.html#cb720-1"></a><span class="kw">library</span>(tidyverse)</span>
<span id="cb720-2"><a href="example-16.html#cb720-2"></a><span class="kw">set.seed</span>(<span class="dv">1</span>)</span>
<span id="cb720-3"><a href="example-16.html#cb720-3"></a>x &lt;-<span class="st"> </span><span class="kw">matrix</span>(<span class="kw">rnorm</span> (<span class="dv">20</span><span class="op">*</span><span class="dv">2</span>), <span class="dt">ncol=</span><span class="dv">2</span>)</span>
<span id="cb720-4"><a href="example-16.html#cb720-4"></a>y &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="kw">rep</span>(<span class="op">-</span><span class="dv">1</span>, <span class="dv">10</span>), <span class="kw">rep</span>(<span class="dv">1</span>, <span class="dv">10</span>))</span>
<span id="cb720-5"><a href="example-16.html#cb720-5"></a>x[y<span class="op">==</span><span class="dv">1</span>, ] &lt;-<span class="st"> </span>x[y<span class="op">==</span><span class="dv">1</span>, ] <span class="op">+</span><span class="st"> </span><span class="dv">1</span></span>
<span id="cb720-6"><a href="example-16.html#cb720-6"></a>train_data &lt;-<span class="st"> </span><span class="kw">data.frame</span>(x, y)</span>
<span id="cb720-7"><a href="example-16.html#cb720-7"></a>train_data<span class="op">$</span>y &lt;-<span class="st"> </span><span class="kw">as.factor</span>(y)</span></code></pre></div>
<p>A scatter plot reveals whether the classes are linearly separable.</p>
<div class="sourceCode" id="cb721"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb721-1"><a href="example-16.html#cb721-1"></a><span class="kw">ggplot</span>(train_data, <span class="kw">aes</span>(<span class="dt">x =</span> X1, <span class="dt">y =</span> X2, <span class="dt">color =</span> y)) <span class="op">+</span></span>
<span id="cb721-2"><a href="example-16.html#cb721-2"></a><span class="st">  </span><span class="kw">geom_point</span>(<span class="dt">size =</span> <span class="dv">2</span>) <span class="op">+</span></span>
<span id="cb721-3"><a href="example-16.html#cb721-3"></a><span class="st">  </span><span class="kw">labs</span>(<span class="dt">title =</span> <span class="st">&quot;Binary response with two features&quot;</span>) <span class="op">+</span></span>
<span id="cb721-4"><a href="example-16.html#cb721-4"></a><span class="st">  </span><span class="kw">theme</span>(<span class="dt">legend.position =</span> <span class="st">&quot;top&quot;</span>)</span></code></pre></div>
<p><img src="data-sci_files/figure-html/unnamed-chunk-331-1.png" width="672" /></p>
<p>No, they are not linearly separable. Now fit a support vector machine. The <strong>e1071</strong> library implements the SVM algorithm. <code>svm(..., kernel="linear")</code> fits a support vector classifier. Change the kernal to <code>c("polynomial", "radial")</code> for SVM. Try a cost of 10.</p>
<div class="sourceCode" id="cb722"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb722-1"><a href="example-16.html#cb722-1"></a><span class="kw">library</span>(e1071)</span>
<span id="cb722-2"><a href="example-16.html#cb722-2"></a>m &lt;-<span class="st"> </span><span class="kw">svm</span>(</span>
<span id="cb722-3"><a href="example-16.html#cb722-3"></a>  y <span class="op">~</span><span class="st"> </span>., </span>
<span id="cb722-4"><a href="example-16.html#cb722-4"></a>  <span class="dt">data =</span> train_data,</span>
<span id="cb722-5"><a href="example-16.html#cb722-5"></a>  <span class="dt">kernel =</span> <span class="st">&quot;linear&quot;</span>,</span>
<span id="cb722-6"><a href="example-16.html#cb722-6"></a>  <span class="dt">type =</span> <span class="st">&quot;C-classification&quot;</span>,  <span class="co"># (default) for classification</span></span>
<span id="cb722-7"><a href="example-16.html#cb722-7"></a>  <span class="dt">cost =</span> <span class="dv">10</span>,  <span class="co"># default is 1</span></span>
<span id="cb722-8"><a href="example-16.html#cb722-8"></a>  <span class="dt">scale =</span> <span class="ot">FALSE</span>  <span class="co"># do not standardize features</span></span>
<span id="cb722-9"><a href="example-16.html#cb722-9"></a>)</span>
<span id="cb722-10"><a href="example-16.html#cb722-10"></a><span class="kw">plot</span>(m, train_data)</span></code></pre></div>
<p><img src="data-sci_files/figure-html/unnamed-chunk-332-1.png" width="672" /></p>
<p>The support vectors are plotted as “x’s”. There are seven of them.</p>
<div class="sourceCode" id="cb723"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb723-1"><a href="example-16.html#cb723-1"></a>m<span class="op">$</span>index</span></code></pre></div>
<pre><code>## [1]  1  2  5  7 14 16 17</code></pre>
<p>The summary shows adds additional information, including the distribution of the support vector classes.</p>
<div class="sourceCode" id="cb725"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb725-1"><a href="example-16.html#cb725-1"></a><span class="kw">summary</span>(m)</span></code></pre></div>
<pre><code>## 
## Call:
## svm(formula = y ~ ., data = train_data, kernel = &quot;linear&quot;, type = &quot;C-classification&quot;, 
##     cost = 10, scale = FALSE)
## 
## 
## Parameters:
##    SVM-Type:  C-classification 
##  SVM-Kernel:  linear 
##        cost:  10 
## 
## Number of Support Vectors:  7
## 
##  ( 4 3 )
## 
## 
## Number of Classes:  2 
## 
## Levels: 
##  -1 1</code></pre>
<p>The seven support vectors are comprised of four in one class, three in the other. What if we lower the cost of margin violations? This will increase bias and lower variance.</p>
<div class="sourceCode" id="cb727"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb727-1"><a href="example-16.html#cb727-1"></a>m &lt;-<span class="st"> </span><span class="kw">svm</span>(</span>
<span id="cb727-2"><a href="example-16.html#cb727-2"></a>  y <span class="op">~</span><span class="st"> </span>., </span>
<span id="cb727-3"><a href="example-16.html#cb727-3"></a>  <span class="dt">data =</span> train_data,</span>
<span id="cb727-4"><a href="example-16.html#cb727-4"></a>  <span class="dt">kernel =</span> <span class="st">&quot;linear&quot;</span>,</span>
<span id="cb727-5"><a href="example-16.html#cb727-5"></a>  <span class="dt">type =</span> <span class="st">&quot;C-classification&quot;</span>,  </span>
<span id="cb727-6"><a href="example-16.html#cb727-6"></a>  <span class="dt">cost =</span> <span class="fl">0.1</span>,</span>
<span id="cb727-7"><a href="example-16.html#cb727-7"></a>  <span class="dt">scale =</span> <span class="ot">FALSE</span></span>
<span id="cb727-8"><a href="example-16.html#cb727-8"></a>)</span>
<span id="cb727-9"><a href="example-16.html#cb727-9"></a><span class="kw">plot</span>(m, train_data)</span></code></pre></div>
<p><img src="data-sci_files/figure-html/unnamed-chunk-335-1.png" width="672" /></p>
<p>There are many more support vectors now. <em>(In case you hoped to see the linear decision boundary formulation, or at least a graphical representation of the margins, keep hoping. The model is generalized beyond two features, so it evidently does not worry too much about supporting sanitized two-feature demos.)</em></p>
<p>Which cost level yields the <em>best</em> predictive performance on holdout data? Use cross validation to find out. SVM defaults to 10-fold CV. I’ll try seven candidate values for <code>cost</code>.</p>
<div class="sourceCode" id="cb728"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb728-1"><a href="example-16.html#cb728-1"></a><span class="kw">set.seed</span>(<span class="dv">1</span>)</span>
<span id="cb728-2"><a href="example-16.html#cb728-2"></a>m_tune &lt;-<span class="st"> </span><span class="kw">tune</span>(</span>
<span id="cb728-3"><a href="example-16.html#cb728-3"></a>  svm,</span>
<span id="cb728-4"><a href="example-16.html#cb728-4"></a>  y <span class="op">~</span><span class="st"> </span>.,</span>
<span id="cb728-5"><a href="example-16.html#cb728-5"></a>  <span class="dt">data =</span> train_data,</span>
<span id="cb728-6"><a href="example-16.html#cb728-6"></a>  <span class="dt">kernel =</span><span class="st">&quot;linear&quot;</span>,</span>
<span id="cb728-7"><a href="example-16.html#cb728-7"></a>  <span class="dt">ranges =</span> <span class="kw">list</span>(<span class="dt">cost =</span> <span class="kw">c</span>(<span class="fl">0.001</span>, <span class="fl">0.01</span>, <span class="fl">0.1</span>, <span class="dv">1</span>, <span class="dv">5</span>, <span class="dv">10</span>, <span class="dv">100</span>))</span>
<span id="cb728-8"><a href="example-16.html#cb728-8"></a>)</span>
<span id="cb728-9"><a href="example-16.html#cb728-9"></a><span class="kw">summary</span>(m_tune)</span></code></pre></div>
<pre><code>## 
## Parameter tuning of &#39;svm&#39;:
## 
## - sampling method: 10-fold cross validation 
## 
## - best parameters:
##  cost
##   0.1
## 
## - best performance: 0.05 
## 
## - Detailed performance results:
##      cost error dispersion
## 1   0.001  0.55       0.44
## 2   0.010  0.55       0.44
## 3   0.100  0.05       0.16
## 4   1.000  0.15       0.24
## 5   5.000  0.15       0.24
## 6  10.000  0.15       0.24
## 7 100.000  0.15       0.24</code></pre>
<p>The lowest cross-validation error rate is 0.10 with cost = 0.1. <code>tune()</code> saves the best tuning parameter value.</p>
<div class="sourceCode" id="cb730"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb730-1"><a href="example-16.html#cb730-1"></a>m_best &lt;-<span class="st"> </span>m_tune<span class="op">$</span>best.model</span>
<span id="cb730-2"><a href="example-16.html#cb730-2"></a><span class="kw">summary</span>(m_best)</span></code></pre></div>
<pre><code>## 
## Call:
## best.tune(method = svm, train.x = y ~ ., data = train_data, ranges = list(cost = c(0.001, 
##     0.01, 0.1, 1, 5, 10, 100)), kernel = &quot;linear&quot;)
## 
## 
## Parameters:
##    SVM-Type:  C-classification 
##  SVM-Kernel:  linear 
##        cost:  0.1 
## 
## Number of Support Vectors:  16
## 
##  ( 8 8 )
## 
## 
## Number of Classes:  2 
## 
## Levels: 
##  -1 1</code></pre>
<p>There are 16 support vectors, 8 in each class. This is a pretty wide margin.</p>
<div class="sourceCode" id="cb732"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb732-1"><a href="example-16.html#cb732-1"></a><span class="kw">plot</span>(m_best, train_data)</span></code></pre></div>
<p><img src="data-sci_files/figure-html/unnamed-chunk-338-1.png" width="672" /></p>
<p>What if the classes had been linearly separable? Then we could create a maximal margin classifier.</p>
<div class="sourceCode" id="cb733"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb733-1"><a href="example-16.html#cb733-1"></a>train_data_<span class="dv">2</span> &lt;-<span class="st"> </span>train_data <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb733-2"><a href="example-16.html#cb733-2"></a><span class="st">  </span><span class="kw">mutate</span>(</span>
<span id="cb733-3"><a href="example-16.html#cb733-3"></a>    <span class="dt">X1 =</span> X1 <span class="op">+</span><span class="st"> </span><span class="kw">ifelse</span>(y<span class="op">==</span><span class="dv">1</span>, <span class="fl">1.0</span>, <span class="dv">0</span>),</span>
<span id="cb733-4"><a href="example-16.html#cb733-4"></a>    <span class="dt">X2 =</span> X2 <span class="op">+</span><span class="st"> </span><span class="kw">ifelse</span>(y<span class="op">==</span><span class="dv">1</span>, <span class="fl">1.0</span>, <span class="dv">0</span>)</span>
<span id="cb733-5"><a href="example-16.html#cb733-5"></a>  )</span>
<span id="cb733-6"><a href="example-16.html#cb733-6"></a><span class="kw">ggplot</span>(train_data_<span class="dv">2</span>, <span class="kw">aes</span>(<span class="dt">x =</span> X1, <span class="dt">y =</span> X2, <span class="dt">color =</span> y)) <span class="op">+</span></span>
<span id="cb733-7"><a href="example-16.html#cb733-7"></a><span class="st">  </span><span class="kw">geom_point</span>(<span class="dt">size =</span> <span class="dv">2</span>) <span class="op">+</span></span>
<span id="cb733-8"><a href="example-16.html#cb733-8"></a><span class="st">  </span><span class="kw">labs</span>(<span class="dt">title =</span> <span class="st">&quot;Binary response with two features, linearly separable&quot;</span>)</span></code></pre></div>
<p><img src="data-sci_files/figure-html/unnamed-chunk-339-1.png" width="672" /></p>
<p>Specify a huge cost = 1e5 so that no support vectors violate the margin.</p>
<div class="sourceCode" id="cb734"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb734-1"><a href="example-16.html#cb734-1"></a>m2 &lt;-<span class="st"> </span><span class="kw">svm</span>(</span>
<span id="cb734-2"><a href="example-16.html#cb734-2"></a>  y <span class="op">~</span><span class="st"> </span>., </span>
<span id="cb734-3"><a href="example-16.html#cb734-3"></a>  <span class="dt">data =</span> train_data_<span class="dv">2</span>,</span>
<span id="cb734-4"><a href="example-16.html#cb734-4"></a>  <span class="dt">kernel =</span> <span class="st">&quot;linear&quot;</span>,</span>
<span id="cb734-5"><a href="example-16.html#cb734-5"></a>  <span class="dt">cost =</span> <span class="fl">1e5</span>,</span>
<span id="cb734-6"><a href="example-16.html#cb734-6"></a>  <span class="dt">scale =</span> <span class="ot">FALSE</span>  <span class="co"># do not standardize features</span></span>
<span id="cb734-7"><a href="example-16.html#cb734-7"></a>)</span>
<span id="cb734-8"><a href="example-16.html#cb734-8"></a><span class="kw">plot</span>(m2, train_data_<span class="dv">2</span>)</span></code></pre></div>
<p><img src="data-sci_files/figure-html/unnamed-chunk-340-1.png" width="672" /></p>
<div class="sourceCode" id="cb735"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb735-1"><a href="example-16.html#cb735-1"></a><span class="kw">summary</span>(m2)</span></code></pre></div>
<pre><code>## 
## Call:
## svm(formula = y ~ ., data = train_data_2, kernel = &quot;linear&quot;, cost = 100000, 
##     scale = FALSE)
## 
## 
## Parameters:
##    SVM-Type:  C-classification 
##  SVM-Kernel:  linear 
##        cost:  100000 
## 
## Number of Support Vectors:  3
## 
##  ( 1 2 )
## 
## 
## Number of Classes:  2 
## 
## Levels: 
##  -1 1</code></pre>
<p>This model will have very low bias, but very high variance. To fit an SVM, use a different kernel. You can use <code>kernal = c("polynomial", "radial", "sigmoid")</code>. For a polynomial model, also specify the polynomial degree. For a radial model, include the gamma value.</p>
<div class="sourceCode" id="cb737"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb737-1"><a href="example-16.html#cb737-1"></a><span class="kw">set.seed</span>(<span class="dv">1</span>)</span>
<span id="cb737-2"><a href="example-16.html#cb737-2"></a>m3_tune &lt;-<span class="st"> </span><span class="kw">tune</span>(</span>
<span id="cb737-3"><a href="example-16.html#cb737-3"></a>  svm,</span>
<span id="cb737-4"><a href="example-16.html#cb737-4"></a>  y <span class="op">~</span><span class="st"> </span>.,</span>
<span id="cb737-5"><a href="example-16.html#cb737-5"></a>  <span class="dt">data =</span> train_data,</span>
<span id="cb737-6"><a href="example-16.html#cb737-6"></a>  <span class="dt">kernel =</span><span class="st">&quot;polynomial&quot;</span>,</span>
<span id="cb737-7"><a href="example-16.html#cb737-7"></a>  <span class="dt">ranges =</span> <span class="kw">list</span>(</span>
<span id="cb737-8"><a href="example-16.html#cb737-8"></a>    <span class="dt">cost =</span> <span class="kw">c</span>(<span class="fl">0.001</span>, <span class="fl">0.01</span>, <span class="fl">0.1</span>, <span class="dv">1</span>, <span class="dv">5</span>, <span class="dv">10</span>, <span class="dv">100</span>),</span>
<span id="cb737-9"><a href="example-16.html#cb737-9"></a>    <span class="dt">degree =</span> <span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>)</span>
<span id="cb737-10"><a href="example-16.html#cb737-10"></a>  )</span>
<span id="cb737-11"><a href="example-16.html#cb737-11"></a>)</span>
<span id="cb737-12"><a href="example-16.html#cb737-12"></a><span class="kw">summary</span>(m3_tune)</span></code></pre></div>
<pre><code>## 
## Parameter tuning of &#39;svm&#39;:
## 
## - sampling method: 10-fold cross validation 
## 
## - best parameters:
##  cost degree
##     1      1
## 
## - best performance: 0.1 
## 
## - Detailed performance results:
##       cost degree error dispersion
## 1    0.001      1  0.55       0.44
## 2    0.010      1  0.55       0.44
## 3    0.100      1  0.30       0.26
## 4    1.000      1  0.10       0.21
## 5    5.000      1  0.10       0.21
## 6   10.000      1  0.15       0.24
## 7  100.000      1  0.15       0.24
## 8    0.001      2  0.70       0.42
## 9    0.010      2  0.70       0.42
## 10   0.100      2  0.70       0.42
## 11   1.000      2  0.65       0.24
## 12   5.000      2  0.50       0.33
## 13  10.000      2  0.50       0.33
## 14 100.000      2  0.50       0.33
## 15   0.001      3  0.65       0.34
## 16   0.010      3  0.65       0.34
## 17   0.100      3  0.50       0.33
## 18   1.000      3  0.40       0.32
## 19   5.000      3  0.35       0.34
## 20  10.000      3  0.35       0.34
## 21 100.000      3  0.35       0.34</code></pre>
<p>The lowest cross-validation error rate is 0.10 with cost = 1, polynomial degree 1.</p>
<div class="sourceCode" id="cb739"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb739-1"><a href="example-16.html#cb739-1"></a>m3_best &lt;-<span class="st"> </span>m3_tune<span class="op">$</span>best.model</span>
<span id="cb739-2"><a href="example-16.html#cb739-2"></a><span class="kw">summary</span>(m3_best)</span></code></pre></div>
<pre><code>## 
## Call:
## best.tune(method = svm, train.x = y ~ ., data = train_data, ranges = list(cost = c(0.001, 
##     0.01, 0.1, 1, 5, 10, 100), degree = c(1, 2, 3)), kernel = &quot;polynomial&quot;)
## 
## 
## Parameters:
##    SVM-Type:  C-classification 
##  SVM-Kernel:  polynomial 
##        cost:  1 
##      degree:  1 
##      coef.0:  0 
## 
## Number of Support Vectors:  12
## 
##  ( 6 6 )
## 
## 
## Number of Classes:  2 
## 
## Levels: 
##  -1 1</code></pre>
<p>There are 12 support vectors, 6 in each class. This is a pretty wide margin.</p>
<div class="sourceCode" id="cb741"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb741-1"><a href="example-16.html#cb741-1"></a><span class="kw">plot</span>(m3_best, train_data)</span></code></pre></div>
<p><img src="data-sci_files/figure-html/unnamed-chunk-343-1.png" width="672" /></p>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="support-vector-machines-1.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="using-caret.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="assets/gitbook-2.6.7/js/app.min.js"></script>
<script src="assets/gitbook-2.6.7/js/lunr.js"></script>
<script src="assets/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="assets/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="assets/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="assets/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="assets/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="assets/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="assets/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["data-sci.pdf", "data-sci.epub"],
"toc": {
"collapse": "subsection"
},
"toolbar": {
"position": "static"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
